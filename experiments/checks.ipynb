{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import experiment_utils as eu\n",
    "import sys\n",
    "sys.path.append('../')\n",
    "from data_processing.stl10 import get_stl10\n",
    "import importlib\n",
    "import config as conf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "varliables target: \n",
      " [<tf.Variable 'res_net18_1/conv2d_20/kernel:0' shape=(7, 7, 3, 64) dtype=float32, numpy=\n",
      "array([[[[ 7.13101402e-03, -1.08212642e-02,  1.75425187e-02, ...,\n",
      "          -3.01801339e-02, -3.75212952e-02,  1.48176067e-02],\n",
      "         [-4.04120348e-02, -3.41520049e-02, -1.55382063e-02, ...,\n",
      "           2.18393765e-02,  2.26096027e-02,  2.23434456e-02],\n",
      "         [-1.96427219e-02,  2.04371326e-02, -1.81615800e-02, ...,\n",
      "           9.32507962e-03, -2.59556733e-02,  3.86325084e-02]],\n",
      "\n",
      "        [[ 3.78599763e-02, -3.02022733e-02,  1.68009736e-02, ...,\n",
      "          -3.21607664e-03, -2.59746723e-02, -2.19756402e-02],\n",
      "         [ 7.17030466e-03, -1.77399572e-02,  3.10802460e-03, ...,\n",
      "          -1.27667766e-02,  4.18871231e-02, -1.65146962e-02],\n",
      "         [-7.09977001e-04, -2.98420079e-02,  1.42942630e-02, ...,\n",
      "          -1.77808851e-03, -1.60246324e-02, -3.42210755e-03]],\n",
      "\n",
      "        [[-1.23124570e-04, -1.88492872e-02, -3.72549556e-02, ...,\n",
      "          -2.63853688e-02,  4.02253829e-02,  2.29878537e-02],\n",
      "         [ 3.64062302e-02,  1.36432387e-02, -3.25683355e-02, ...,\n",
      "          -4.40409407e-03, -3.47604677e-02,  2.56156810e-02],\n",
      "         [-3.88959348e-02,  2.15015076e-02, -6.93776086e-03, ...,\n",
      "          -3.96137834e-02,  3.39317434e-02, -7.21246004e-03]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ 6.67049363e-03,  1.95088126e-02,  3.95760201e-02, ...,\n",
      "           2.50639804e-02,  1.83889642e-02,  2.21824460e-02],\n",
      "         [ 4.13407609e-02,  2.69506015e-02,  3.58489156e-03, ...,\n",
      "           8.39349627e-03,  4.07006107e-02,  1.61308497e-02],\n",
      "         [-2.25098282e-02,  2.64734514e-02,  6.13682717e-03, ...,\n",
      "          -3.65332551e-02, -2.78339162e-02, -2.89794505e-02]],\n",
      "\n",
      "        [[-3.20381671e-03, -2.03635041e-02, -3.95143367e-02, ...,\n",
      "          -3.45325507e-02,  3.66599374e-02,  1.75350159e-02],\n",
      "         [ 2.42412575e-02,  1.95464026e-02, -9.15202126e-03, ...,\n",
      "          -8.50952789e-03,  4.26085331e-02,  1.10792965e-02],\n",
      "         [ 3.94177660e-02,  3.91286947e-02,  3.67498137e-02, ...,\n",
      "          -3.06423008e-03,  3.78266387e-02, -7.86946714e-03]],\n",
      "\n",
      "        [[ 8.76715034e-03, -1.12937763e-02,  9.91707481e-03, ...,\n",
      "          -1.17515326e-02,  1.95387676e-02,  3.78127843e-02],\n",
      "         [ 8.12271982e-03,  3.38196866e-02,  2.33276151e-02, ...,\n",
      "          -4.62096930e-03, -3.96856926e-02,  3.78269888e-02],\n",
      "         [-4.33394685e-03,  4.34827060e-03,  4.24487516e-02, ...,\n",
      "           3.80326696e-02,  1.63070858e-04, -5.50082698e-03]]],\n",
      "\n",
      "\n",
      "       [[[-3.47547494e-02,  3.25202309e-02,  1.28924586e-02, ...,\n",
      "           2.98780203e-02,  3.57940122e-02, -3.72272208e-02],\n",
      "         [ 2.48089284e-02,  2.43487768e-02, -3.13978642e-04, ...,\n",
      "          -2.52195615e-02, -3.08751799e-02,  6.78688288e-03],\n",
      "         [ 2.03377008e-03,  1.03195272e-02,  3.52969654e-02, ...,\n",
      "           2.08835043e-02,  4.18647677e-02, -4.59444895e-03]],\n",
      "\n",
      "        [[-3.59242409e-03,  1.97414644e-02, -1.28405094e-02, ...,\n",
      "           8.91629606e-04, -3.88961919e-02, -2.15766542e-02],\n",
      "         [-2.86231413e-02,  1.70123950e-02,  1.74284428e-02, ...,\n",
      "           2.80150361e-02,  3.01659070e-02,  1.54656917e-03],\n",
      "         [-3.69576514e-02,  1.84608512e-02, -3.45254876e-02, ...,\n",
      "          -1.26429684e-02, -3.55093069e-02, -5.11084124e-03]],\n",
      "\n",
      "        [[ 2.74638012e-02,  2.06986926e-02, -2.53573749e-02, ...,\n",
      "          -7.73933902e-03,  2.98151933e-02, -9.53365862e-03],\n",
      "         [-2.82651819e-02,  6.39904290e-04, -1.68328173e-02, ...,\n",
      "           2.76077613e-02,  2.43809931e-02,  4.06443961e-02],\n",
      "         [-3.99668925e-02,  3.81951444e-02,  2.42319070e-02, ...,\n",
      "          -3.39572467e-02, -3.60467918e-02, -1.62312537e-02]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ 2.76238844e-03,  2.07430534e-02,  4.12101336e-02, ...,\n",
      "           1.67605095e-02,  4.13533524e-02, -1.85114779e-02],\n",
      "         [-1.87202729e-02, -3.04016434e-02, -3.27830873e-02, ...,\n",
      "           1.19394511e-02, -1.42315291e-02,  2.53763422e-03],\n",
      "         [ 2.41053589e-02,  2.82969270e-02, -4.15511318e-02, ...,\n",
      "          -3.01430337e-02,  2.44024880e-02,  3.71855497e-03]],\n",
      "\n",
      "        [[ 1.21732876e-02, -2.02994645e-02,  3.09055559e-02, ...,\n",
      "           6.71332330e-03, -1.03027746e-03, -8.94542783e-04],\n",
      "         [-1.95995346e-02,  4.13375683e-02,  4.01609130e-02, ...,\n",
      "          -1.00411512e-02,  2.23586969e-02, -2.96498910e-02],\n",
      "         [-1.38378441e-02, -1.21142324e-02,  3.90902534e-03, ...,\n",
      "          -9.45233181e-03, -3.54913585e-02,  2.48322003e-02]],\n",
      "\n",
      "        [[-3.24067362e-02, -3.45371999e-02,  3.56788673e-02, ...,\n",
      "           3.92161161e-02, -1.50196329e-02,  2.47762166e-02],\n",
      "         [-6.74628466e-03, -3.98744307e-02,  2.58093216e-02, ...,\n",
      "          -2.04644911e-02,  1.97311491e-03,  1.97267104e-02],\n",
      "         [ 1.27702616e-02, -3.73570211e-02,  4.21535261e-02, ...,\n",
      "           1.69939995e-02,  4.98308614e-03,  3.65407877e-02]]],\n",
      "\n",
      "\n",
      "       [[[-1.53500400e-02,  3.23145427e-02, -2.49542668e-03, ...,\n",
      "           4.22394536e-02,  3.36713679e-02,  1.17104501e-03],\n",
      "         [-1.46855637e-02, -1.17682591e-02,  4.15048338e-02, ...,\n",
      "           1.16125084e-02,  2.75200494e-02,  4.08728085e-02],\n",
      "         [ 8.65544006e-03, -3.64310555e-02,  3.33957039e-02, ...,\n",
      "          -3.33037116e-02, -8.82178545e-04, -4.20036577e-02]],\n",
      "\n",
      "        [[ 2.74350531e-02, -3.64915580e-02,  2.82889605e-03, ...,\n",
      "           3.85234617e-02,  4.10984121e-02,  2.71605607e-02],\n",
      "         [ 2.11940072e-02, -3.56144831e-02, -1.80770829e-02, ...,\n",
      "           4.24862094e-02,  2.56988518e-02, -2.25337092e-02],\n",
      "         [ 1.78068206e-02, -4.07614075e-02,  1.73783489e-02, ...,\n",
      "          -3.12426426e-02,  3.51526849e-02, -3.35757807e-02]],\n",
      "\n",
      "        [[-9.96473804e-03,  3.91022153e-02, -1.03402585e-02, ...,\n",
      "           1.41976587e-02, -1.52285676e-02,  3.40174921e-02],\n",
      "         [-6.30958006e-03, -6.58566132e-03, -3.29612866e-02, ...,\n",
      "          -2.76959315e-03, -3.70432772e-02, -3.61948460e-02],\n",
      "         [ 3.92324403e-02, -1.34930722e-02,  1.07035004e-02, ...,\n",
      "           2.08097510e-02, -8.52647796e-03,  1.28980130e-02]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-3.91051657e-02,  1.57251656e-02,  1.40185170e-02, ...,\n",
      "          -2.85992809e-02, -3.13960873e-02, -3.99553441e-02],\n",
      "         [-5.47215343e-04, -8.39132443e-03,  4.74562496e-03, ...,\n",
      "          -2.75723562e-02, -3.76537181e-02, -2.94637270e-02],\n",
      "         [ 3.41445990e-02,  3.13108675e-02, -3.50412391e-02, ...,\n",
      "          -2.75675133e-02, -2.10919194e-02,  2.59605721e-02]],\n",
      "\n",
      "        [[ 2.43907683e-02,  1.35299899e-02,  3.00194882e-02, ...,\n",
      "          -6.75095618e-03,  3.54271047e-02,  4.12263684e-02],\n",
      "         [-1.29491705e-02,  2.08396260e-02, -3.96805331e-02, ...,\n",
      "           1.48929991e-02,  9.85780731e-03,  3.06779183e-02],\n",
      "         [-2.92295925e-02, -2.46250741e-02, -1.51645206e-02, ...,\n",
      "          -1.56463496e-02,  1.63932443e-02, -3.38301584e-02]],\n",
      "\n",
      "        [[ 3.00400332e-03, -6.74891472e-03, -3.90735082e-02, ...,\n",
      "          -2.47798897e-02, -1.58364177e-02,  4.10443023e-02],\n",
      "         [ 1.58525519e-02, -1.19190868e-02, -2.47765556e-02, ...,\n",
      "          -3.97792794e-02,  8.13473016e-04,  3.26163247e-02],\n",
      "         [ 1.67673193e-02, -2.87776999e-02, -5.87720424e-04, ...,\n",
      "           4.75388020e-03, -5.04392758e-03, -1.42645091e-04]]],\n",
      "\n",
      "\n",
      "       ...,\n",
      "\n",
      "\n",
      "       [[[ 4.20583673e-02,  3.01374756e-02,  1.82637796e-02, ...,\n",
      "          -1.51868910e-02,  2.91640684e-03,  3.89426090e-02],\n",
      "         [-4.03944142e-02, -3.28816436e-02,  4.87981737e-03, ...,\n",
      "          -3.60454433e-02,  1.26602948e-02,  4.24325131e-02],\n",
      "         [ 2.61022635e-02, -1.09476596e-02, -2.83462815e-02, ...,\n",
      "          -1.73107311e-02,  1.50254406e-02, -3.83181535e-02]],\n",
      "\n",
      "        [[-2.45620552e-02, -4.02634442e-02,  4.68438491e-03, ...,\n",
      "           1.88163742e-02,  8.85841623e-03,  1.38776675e-02],\n",
      "         [-4.00706716e-02, -2.26858296e-02,  6.58422709e-03, ...,\n",
      "           9.84834880e-03,  2.99581103e-02,  1.82675198e-02],\n",
      "         [-1.98561102e-02, -2.45682001e-02,  2.10083686e-02, ...,\n",
      "           1.97329447e-02, -4.10844274e-02,  1.05754733e-02]],\n",
      "\n",
      "        [[ 4.01205979e-02,  3.22526433e-02,  3.23281102e-02, ...,\n",
      "           2.88815014e-02,  3.25217359e-02, -3.97448167e-02],\n",
      "         [ 2.04929821e-02, -3.38292718e-02,  9.65131074e-03, ...,\n",
      "          -5.26074320e-03,  2.86822878e-02, -2.93838158e-02],\n",
      "         [ 3.22043039e-02,  8.05434957e-03,  9.03505087e-03, ...,\n",
      "          -4.15183417e-02,  1.98278539e-02,  4.17107157e-02]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-2.64686625e-02,  2.87653469e-02, -7.07453489e-03, ...,\n",
      "          -5.64917922e-04, -2.40542758e-02, -2.97390297e-03],\n",
      "         [-4.10348810e-02, -4.56769392e-03,  3.65203992e-03, ...,\n",
      "           4.80152667e-05,  2.61816494e-02, -3.52828130e-02],\n",
      "         [-1.65748633e-02, -3.08584869e-02,  3.77456732e-02, ...,\n",
      "          -2.99475715e-02,  8.45648348e-03, -1.64087769e-02]],\n",
      "\n",
      "        [[ 2.01938413e-02,  1.89789236e-02,  1.41299516e-03, ...,\n",
      "          -3.13229077e-02,  1.70665383e-02, -8.87246057e-03],\n",
      "         [ 2.90823318e-02,  1.67742372e-02,  1.69162117e-02, ...,\n",
      "           8.68058577e-03,  4.19726595e-03,  1.59534588e-02],\n",
      "         [-4.05622162e-02, -9.96779650e-03,  3.65776941e-03, ...,\n",
      "          -3.82404253e-02,  1.97634585e-02,  3.52151431e-02]],\n",
      "\n",
      "        [[-3.82830426e-02,  3.50902379e-02,  4.17778268e-02, ...,\n",
      "          -1.16743855e-02,  4.09557484e-02, -5.18579781e-03],\n",
      "         [-4.19049971e-02,  3.10807563e-02,  4.95995209e-03, ...,\n",
      "          -3.53952534e-02, -4.73793969e-03, -6.20992854e-03],\n",
      "         [-3.12617160e-02, -3.66645940e-02,  3.04177962e-02, ...,\n",
      "          -9.59615782e-03, -3.61137725e-02, -2.62609310e-02]]],\n",
      "\n",
      "\n",
      "       [[[-2.57520787e-02,  2.27990709e-02, -8.81446525e-03, ...,\n",
      "          -3.23190689e-02,  1.72652826e-02,  2.74502505e-02],\n",
      "         [ 1.86223313e-02,  2.96096671e-02,  2.43938752e-02, ...,\n",
      "           6.35137782e-03,  3.59608866e-02,  3.16688605e-02],\n",
      "         [-2.96862982e-02,  1.99519098e-04, -2.56773382e-02, ...,\n",
      "          -1.45916007e-02,  1.04130954e-02,  1.50018446e-02]],\n",
      "\n",
      "        [[ 4.99289110e-03, -1.28110312e-02,  1.84626840e-02, ...,\n",
      "           1.84294581e-02, -2.07948089e-02, -2.14223303e-02],\n",
      "         [-1.44811329e-02, -1.02497600e-02, -4.26030867e-02, ...,\n",
      "          -8.13426077e-03, -6.07912615e-03, -2.61306893e-02],\n",
      "         [ 2.14198418e-02,  3.89530510e-02,  1.94858275e-02, ...,\n",
      "           3.21563073e-02,  3.43465693e-02, -3.33450660e-02]],\n",
      "\n",
      "        [[-3.80292162e-03,  3.31955031e-03,  3.17107029e-02, ...,\n",
      "          -2.81886347e-02, -3.34584489e-02, -2.76477076e-02],\n",
      "         [ 3.89724337e-02, -9.65673104e-03,  1.11485347e-02, ...,\n",
      "          -4.16816846e-02, -3.07353400e-02,  4.10573073e-02],\n",
      "         [-3.30810286e-02,  3.66631486e-02,  1.59828328e-02, ...,\n",
      "          -1.99782792e-02, -2.96473019e-02, -2.24610791e-03]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ 3.22475508e-02,  4.18080054e-02,  1.14449523e-02, ...,\n",
      "          -3.47400717e-02,  1.54927485e-02,  2.49295793e-02],\n",
      "         [ 9.26967338e-03, -4.07343768e-02, -2.56637204e-02, ...,\n",
      "           8.24218616e-03, -2.28472613e-02, -2.35181097e-02],\n",
      "         [ 2.98406556e-03, -1.27670709e-02,  2.39385329e-02, ...,\n",
      "          -6.21494278e-03,  3.45945321e-02, -9.38831270e-03]],\n",
      "\n",
      "        [[-3.52453440e-02,  2.16765534e-02,  9.06633213e-03, ...,\n",
      "          -1.69636663e-02,  2.93664671e-02,  3.96157689e-02],\n",
      "         [-1.58579126e-02, -3.05471830e-02, -4.23690975e-02, ...,\n",
      "           4.13405336e-02,  3.03107537e-02, -5.41032478e-03],\n",
      "         [-7.34181330e-03, -1.84423216e-02, -1.27516277e-02, ...,\n",
      "           2.13425122e-02,  2.65056677e-02,  1.71017013e-02]],\n",
      "\n",
      "        [[-4.82118875e-03, -1.41834095e-02,  9.71187279e-03, ...,\n",
      "           3.19421403e-02,  1.72721706e-02, -1.29066575e-02],\n",
      "         [-4.68792394e-03, -1.35397874e-02, -7.49890134e-03, ...,\n",
      "          -4.08083834e-02, -2.67106108e-02,  1.63112655e-02],\n",
      "         [-2.24277377e-02,  3.82437222e-02, -1.56593025e-02, ...,\n",
      "          -2.18373686e-02, -1.06787831e-02,  7.38304108e-04]]],\n",
      "\n",
      "\n",
      "       [[[-2.91132778e-02, -3.21103893e-02,  1.44388042e-02, ...,\n",
      "          -3.73977832e-02, -2.05862802e-02,  2.33266819e-02],\n",
      "         [-3.31146866e-02, -6.84726238e-03,  1.01052709e-02, ...,\n",
      "           3.52157243e-02,  2.19117440e-02, -2.12329216e-02],\n",
      "         [ 5.04934788e-03, -1.68675203e-02,  3.03108655e-02, ...,\n",
      "           1.97397042e-02, -9.39945132e-03, -3.38008255e-03]],\n",
      "\n",
      "        [[-5.84701449e-03,  2.01883540e-03, -5.43106347e-04, ...,\n",
      "           3.31467278e-02,  2.97410823e-02, -4.11931425e-03],\n",
      "         [ 3.02150436e-02, -1.73606426e-02,  3.72378007e-02, ...,\n",
      "          -3.86786126e-02,  1.32307485e-02,  4.16639224e-02],\n",
      "         [-3.47952619e-02,  1.80612653e-02,  2.44711339e-03, ...,\n",
      "           1.23071298e-03,  1.52795315e-02, -1.45289265e-02]],\n",
      "\n",
      "        [[-2.42348462e-02, -1.92057900e-02, -2.41175704e-02, ...,\n",
      "          -4.23555821e-02,  1.21538490e-02, -4.06973958e-02],\n",
      "         [ 4.13807742e-02,  5.41315973e-03,  2.28532963e-02, ...,\n",
      "          -1.05655156e-02, -2.46428717e-02,  9.04703885e-03],\n",
      "         [ 1.41743682e-02, -2.73071565e-02, -1.40941124e-02, ...,\n",
      "           3.83207798e-02, -9.53525677e-03, -9.42527130e-03]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ 3.44715342e-02,  2.46890318e-02, -3.17989886e-02, ...,\n",
      "          -4.16075364e-02, -3.75229456e-02,  1.04505718e-02],\n",
      "         [-2.28275172e-02,  3.59973721e-02, -1.44186635e-02, ...,\n",
      "          -3.55098881e-02,  8.43284652e-03, -3.21464427e-02],\n",
      "         [-1.93996299e-02, -1.02542713e-03, -7.00398162e-03, ...,\n",
      "          -1.21190846e-02,  1.91750303e-02, -2.46285386e-02]],\n",
      "\n",
      "        [[-2.46425048e-02, -5.32234460e-03, -4.09885831e-02, ...,\n",
      "           2.52022855e-02,  1.40943788e-02, -3.54728512e-02],\n",
      "         [ 2.45294161e-02, -4.10618000e-02, -1.66610610e-02, ...,\n",
      "           1.56642646e-02, -1.58044137e-02, -2.16169953e-02],\n",
      "         [-2.59972699e-02, -3.97078991e-02,  3.43767516e-02, ...,\n",
      "          -3.59548889e-02, -1.56261027e-03, -1.02698803e-02]],\n",
      "\n",
      "        [[ 1.73656568e-02,  2.76894122e-03, -1.35305114e-02, ...,\n",
      "          -2.93505676e-02,  2.94069834e-02,  2.62025036e-02],\n",
      "         [-3.25824730e-02, -4.04176340e-02,  3.73083316e-02, ...,\n",
      "           3.80438976e-02, -2.20599007e-02, -3.34370025e-02],\n",
      "         [-5.04342839e-03,  5.85555285e-03, -3.52551900e-02, ...,\n",
      "          -1.87125057e-03,  1.88130885e-03, -8.27860460e-03]]]],\n",
      "      dtype=float32)>, <tf.Variable 'res_net18_1/conv2d_20/bias:0' shape=(64,) dtype=float32, numpy=\n",
      "array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32)>, <tf.Variable 'res_net18_1/batch_normalization_22/gamma:0' shape=(64,) dtype=float32, numpy=\n",
      "array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32)>, <tf.Variable 'res_net18_1/batch_normalization_22/beta:0' shape=(64,) dtype=float32, numpy=\n",
      "array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32)>, <tf.Variable 'res_net18_1/batch_normalization_22/moving_mean:0' shape=(64,) dtype=float32, numpy=\n",
      "array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32)>, <tf.Variable 'res_net18_1/batch_normalization_22/moving_variance:0' shape=(64,) dtype=float32, numpy=\n",
      "array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32)>, <tf.Variable 'basic_block_8/conv2d_21/kernel:0' shape=(3, 3, 64, 64) dtype=float32, numpy=\n",
      "array([[[[ 0.03188237, -0.01184898,  0.03633366, ...,  0.06557354,\n",
      "           0.04352143, -0.04578689],\n",
      "         [-0.03434483, -0.05072434,  0.04377227, ..., -0.00048555,\n",
      "          -0.05085438, -0.03737141],\n",
      "         [ 0.0637745 , -0.05295659, -0.06666687, ...,  0.06121331,\n",
      "           0.00609913,  0.07172897],\n",
      "         ...,\n",
      "         [-0.04543198, -0.02610337,  0.00839263, ..., -0.02035102,\n",
      "           0.04619119,  0.03597544],\n",
      "         [ 0.04555253, -0.0703997 ,  0.01073167, ..., -0.06696323,\n",
      "           0.03427211,  0.00906362],\n",
      "         [-0.00208122,  0.00407662,  0.06042498, ..., -0.01971065,\n",
      "           0.03613894, -0.02940864]],\n",
      "\n",
      "        [[-0.04789992, -0.06970302, -0.05171277, ..., -0.06315046,\n",
      "           0.00264199, -0.05041125],\n",
      "         [ 0.05483875,  0.03474639,  0.06844357, ..., -0.06352399,\n",
      "          -0.06935043, -0.0222231 ],\n",
      "         [-0.0186438 , -0.02231061, -0.02026595, ...,  0.04331838,\n",
      "           0.05220071, -0.0026801 ],\n",
      "         ...,\n",
      "         [-0.01238567,  0.03065194,  0.03399953, ..., -0.03541248,\n",
      "           0.04816183, -0.0389779 ],\n",
      "         [-0.00960816,  0.02032517,  0.02346531, ...,  0.01757394,\n",
      "           0.02463043,  0.06198379],\n",
      "         [ 0.06237509,  0.06473072,  0.04130813, ..., -0.03092922,\n",
      "          -0.03245939, -0.00359064]],\n",
      "\n",
      "        [[ 0.02779134,  0.04073782, -0.01635824, ..., -0.05320329,\n",
      "          -0.03286043,  0.04566346],\n",
      "         [ 0.01266902, -0.02439015,  0.02116392, ..., -0.00227128,\n",
      "          -0.0189181 ,  0.04445118],\n",
      "         [-0.03481153, -0.01487951,  0.04090691, ..., -0.07121808,\n",
      "          -0.03974845, -0.06446927],\n",
      "         ...,\n",
      "         [-0.0425065 , -0.03534478,  0.01868758, ..., -0.00133537,\n",
      "           0.00519171, -0.02563705],\n",
      "         [-0.06432956,  0.02672318,  0.00813884, ...,  0.06690302,\n",
      "          -0.00099684, -0.06590821],\n",
      "         [ 0.03181268, -0.04493169,  0.03578318, ..., -0.00337818,\n",
      "          -0.01886235, -0.03375258]]],\n",
      "\n",
      "\n",
      "       [[[ 0.03134749, -0.06426398, -0.00349324, ..., -0.06777919,\n",
      "           0.03424277,  0.03576305],\n",
      "         [-0.009446  , -0.0563124 , -0.06827407, ...,  0.01411963,\n",
      "          -0.02049565,  0.01096662],\n",
      "         [-0.01600143,  0.0602378 , -0.03220103, ..., -0.06905281,\n",
      "           0.06833689, -0.04918579],\n",
      "         ...,\n",
      "         [ 0.07114194, -0.01480609, -0.03328829, ...,  0.01246761,\n",
      "           0.06828518, -0.03187442],\n",
      "         [-0.03368183, -0.06276689,  0.07213151, ...,  0.03570514,\n",
      "           0.05923511, -0.01329606],\n",
      "         [-0.04644375, -0.01856035, -0.05816742, ...,  0.03194276,\n",
      "          -0.03143187, -0.06234554]],\n",
      "\n",
      "        [[-0.031671  , -0.00447283, -0.03334682, ...,  0.03152134,\n",
      "          -0.05942725,  0.01791303],\n",
      "         [-0.04262858, -0.04115019, -0.05992891, ...,  0.06508762,\n",
      "          -0.01501799, -0.01440616],\n",
      "         [ 0.04628134,  0.04568946, -0.05993033, ...,  0.01448533,\n",
      "           0.03154533,  0.04930185],\n",
      "         ...,\n",
      "         [-0.02955399,  0.04990347,  0.01036745, ..., -0.01697335,\n",
      "          -0.05064768,  0.02518457],\n",
      "         [-0.04532274,  0.05133656, -0.00151125, ...,  0.03612037,\n",
      "          -0.0593882 ,  0.04150094],\n",
      "         [-0.04888341,  0.07210228, -0.04138231, ..., -0.06860752,\n",
      "          -0.05198799,  0.01529864]],\n",
      "\n",
      "        [[ 0.05327812,  0.03392842, -0.04724932, ...,  0.01422386,\n",
      "          -0.01681075, -0.07102335],\n",
      "         [-0.06496196, -0.05523865,  0.01889043, ..., -0.05475254,\n",
      "           0.03164406, -0.0550833 ],\n",
      "         [ 0.03341345,  0.00569431, -0.03659551, ...,  0.00697476,\n",
      "          -0.05193584,  0.01282337],\n",
      "         ...,\n",
      "         [ 0.03730759, -0.00955885,  0.03008057, ..., -0.053897  ,\n",
      "           0.05333489, -0.06142265],\n",
      "         [ 0.0247484 ,  0.03899428,  0.05239651, ..., -0.07000162,\n",
      "           0.04642285,  0.01835819],\n",
      "         [-0.04324006, -0.03327622,  0.06023176, ..., -0.06302975,\n",
      "          -0.02319795, -0.06903116]]],\n",
      "\n",
      "\n",
      "       [[[-0.00206733,  0.042668  ,  0.03613979, ..., -0.0702662 ,\n",
      "          -0.02847423, -0.02892   ],\n",
      "         [ 0.06938988, -0.00752318,  0.04015902, ...,  0.01979683,\n",
      "           0.0604898 , -0.03723732],\n",
      "         [ 0.0604613 ,  0.05616152,  0.05488183, ..., -0.06360926,\n",
      "           0.03456717,  0.03679504],\n",
      "         ...,\n",
      "         [ 0.0173947 ,  0.04678375,  0.06880625, ...,  0.00412358,\n",
      "           0.03796763,  0.03451897],\n",
      "         [-0.06791533, -0.04845316,  0.00501835, ...,  0.0370845 ,\n",
      "          -0.06388474,  0.04739459],\n",
      "         [ 0.00368172, -0.02543793,  0.00846999, ..., -0.06311176,\n",
      "          -0.02027851, -0.00702044]],\n",
      "\n",
      "        [[ 0.00809792, -0.06764693, -0.0541461 , ...,  0.03459697,\n",
      "           0.03045682,  0.01263657],\n",
      "         [ 0.00952865, -0.01990645, -0.0057599 , ..., -0.01989983,\n",
      "           0.05929644, -0.0510282 ],\n",
      "         [-0.00519982,  0.01753927,  0.0496452 , ...,  0.03796431,\n",
      "          -0.05582481, -0.03743065],\n",
      "         ...,\n",
      "         [ 0.00375799,  0.04007786, -0.01016537, ...,  0.03131251,\n",
      "          -0.02712704,  0.06453201],\n",
      "         [ 0.04551429,  0.05723648,  0.04988116, ..., -0.05739293,\n",
      "          -0.01181335,  0.0061248 ],\n",
      "         [ 0.06195243,  0.0364323 ,  0.05300748, ..., -0.02957986,\n",
      "           0.01858884, -0.07088429]],\n",
      "\n",
      "        [[-0.03458146,  0.00880421, -0.03810039, ..., -0.06834815,\n",
      "          -0.06905575,  0.04359678],\n",
      "         [-0.04871365, -0.03553712,  0.05073984, ..., -0.02400916,\n",
      "           0.04477609, -0.04755413],\n",
      "         [-0.06121831,  0.01436975, -0.05968643, ..., -0.04476752,\n",
      "           0.06981342,  0.00591694],\n",
      "         ...,\n",
      "         [-0.0398477 , -0.00559504, -0.01607428, ...,  0.06665234,\n",
      "          -0.01371044, -0.04718732],\n",
      "         [ 0.05751984,  0.03101181, -0.07113326, ...,  0.01259636,\n",
      "          -0.05057906, -0.02689142],\n",
      "         [-0.06717899, -0.02925926, -0.00077871, ...,  0.04639722,\n",
      "           0.0713532 ,  0.02646701]]]], dtype=float32)>, <tf.Variable 'basic_block_8/conv2d_21/bias:0' shape=(64,) dtype=float32, numpy=\n",
      "array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32)>, <tf.Variable 'basic_block_8/batch_normalization_23/gamma:0' shape=(64,) dtype=float32, numpy=\n",
      "array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32)>, <tf.Variable 'basic_block_8/batch_normalization_23/beta:0' shape=(64,) dtype=float32, numpy=\n",
      "array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32)>, <tf.Variable 'basic_block_8/conv2d_22/kernel:0' shape=(3, 3, 64, 64) dtype=float32, numpy=\n",
      "array([[[[ 5.97504675e-02,  6.47657663e-02, -1.08118355e-03, ...,\n",
      "          -5.38331121e-02,  2.67343968e-02,  1.44158676e-02],\n",
      "         [-6.37892038e-02, -5.80204278e-03,  2.47601420e-03, ...,\n",
      "          -9.84862074e-03,  1.72681659e-02, -5.64349964e-02],\n",
      "         [-2.22854428e-02, -8.07227194e-03,  4.05529216e-02, ...,\n",
      "           1.95617974e-02,  6.54792339e-02, -5.80234230e-02],\n",
      "         ...,\n",
      "         [ 2.53752246e-02,  5.64838797e-02, -3.79882753e-03, ...,\n",
      "           7.01712966e-02,  5.69178909e-02, -6.10781014e-02],\n",
      "         [ 5.01573011e-02,  3.54021788e-04, -4.02863957e-02, ...,\n",
      "           5.32608479e-02, -4.10737097e-02, -7.16603696e-02],\n",
      "         [ 2.60655284e-02, -3.26180123e-02,  3.21391225e-03, ...,\n",
      "           2.84250751e-02,  5.25161400e-02,  2.19228044e-02]],\n",
      "\n",
      "        [[ 3.45142409e-02, -6.89467192e-02, -3.71854976e-02, ...,\n",
      "          -8.99428874e-03, -3.37532535e-02, -2.66111791e-02],\n",
      "         [-2.85328887e-02,  7.14895129e-02,  1.61570683e-02, ...,\n",
      "           4.97563928e-03,  5.24090827e-02, -6.49798363e-02],\n",
      "         [ 5.23565449e-02, -3.56950127e-02,  1.43447891e-02, ...,\n",
      "          -1.51744485e-03,  4.37173471e-02,  6.55339509e-02],\n",
      "         ...,\n",
      "         [-4.18214276e-02, -3.67588624e-02,  4.74131554e-02, ...,\n",
      "           2.52979025e-02,  4.45466414e-02,  6.51104152e-02],\n",
      "         [-5.54255843e-02,  5.79089075e-02,  2.86364928e-02, ...,\n",
      "           5.60357720e-02,  1.90973803e-02,  6.71538413e-02],\n",
      "         [ 5.48384339e-02,  1.80242509e-02,  1.76915824e-02, ...,\n",
      "          -6.57151714e-02, -5.81048727e-02, -3.50382775e-02]],\n",
      "\n",
      "        [[ 3.56713682e-02,  6.89953715e-02, -1.09272040e-02, ...,\n",
      "           1.34269968e-02, -6.18048981e-02, -9.29727405e-03],\n",
      "         [-2.77821757e-02,  2.50900313e-02,  3.42032835e-02, ...,\n",
      "          -2.21723132e-02, -1.59306638e-02, -5.89452498e-02],\n",
      "         [ 1.88943446e-02,  4.36130390e-02, -3.29830498e-03, ...,\n",
      "          -2.00497359e-03,  2.38227844e-02, -5.97439706e-03],\n",
      "         ...,\n",
      "         [-2.85321847e-02, -2.62727961e-02,  3.95374894e-02, ...,\n",
      "          -1.95904821e-03, -6.42775223e-02,  3.40791047e-03],\n",
      "         [ 2.35633254e-02, -2.90531069e-02,  3.91766392e-02, ...,\n",
      "          -9.37092304e-03,  5.77586740e-02,  2.63187215e-02],\n",
      "         [ 3.53716314e-02, -1.94469914e-02,  3.08324024e-02, ...,\n",
      "           4.31083478e-02, -2.22743787e-02,  4.44380604e-02]]],\n",
      "\n",
      "\n",
      "       [[[ 6.79712445e-02,  6.65895790e-02,  5.04425615e-02, ...,\n",
      "           2.00315267e-02,  2.40755714e-02,  5.85777462e-02],\n",
      "         [-3.01851332e-03,  3.63481492e-02, -3.13675404e-02, ...,\n",
      "          -2.86144130e-02, -5.86460494e-02,  5.10054529e-02],\n",
      "         [-4.47027534e-02,  2.61698142e-02,  6.99983686e-02, ...,\n",
      "           5.42322546e-03,  3.76576707e-02,  5.85136265e-02],\n",
      "         ...,\n",
      "         [ 9.10001993e-03, -1.99017562e-02, -5.19912913e-02, ...,\n",
      "           2.04170570e-02, -5.31648546e-02, -1.99021697e-02],\n",
      "         [-1.24536827e-02,  6.09201938e-03,  2.39487663e-02, ...,\n",
      "           3.84063423e-02,  3.41031104e-02, -2.68794596e-03],\n",
      "         [ 5.12343645e-03,  1.52982622e-02, -2.43325382e-02, ...,\n",
      "          -6.70766234e-02,  4.45029885e-02, -4.89342511e-02]],\n",
      "\n",
      "        [[ 6.96679950e-02,  2.57332548e-02, -4.40470576e-02, ...,\n",
      "           4.39991355e-02, -4.28769514e-02,  1.91264749e-02],\n",
      "         [-7.02977628e-02,  3.32309678e-02,  2.99153812e-02, ...,\n",
      "          -2.58323997e-02,  9.91506875e-03, -5.10904193e-03],\n",
      "         [-6.59368932e-04,  6.13646507e-02,  8.08035582e-03, ...,\n",
      "           3.84926796e-02,  2.03318298e-02,  4.08569723e-02],\n",
      "         ...,\n",
      "         [ 3.37374434e-02,  3.97381485e-02,  6.19855672e-02, ...,\n",
      "           2.26866603e-02,  3.47320735e-02, -4.78226319e-02],\n",
      "         [-2.39954665e-02, -5.68060651e-02,  1.89714059e-02, ...,\n",
      "          -6.75744042e-02, -1.20012090e-02,  7.10695386e-02],\n",
      "         [-5.20436466e-03, -6.99305907e-02,  4.02046964e-02, ...,\n",
      "          -3.66088897e-02, -2.76962295e-02,  3.33099812e-02]],\n",
      "\n",
      "        [[-5.42603657e-02, -7.14486092e-02,  5.76258451e-02, ...,\n",
      "          -6.64364249e-02,  1.25327483e-02,  4.65733111e-02],\n",
      "         [ 5.61666787e-02, -1.27654634e-02, -6.47531077e-02, ...,\n",
      "          -1.99473202e-02, -3.08298916e-02,  2.41031274e-02],\n",
      "         [-1.09709799e-04, -4.88249958e-03, -3.44917700e-02, ...,\n",
      "           2.34737173e-02,  2.15395615e-02, -5.90516701e-02],\n",
      "         ...,\n",
      "         [ 4.92919758e-02, -4.74757552e-02,  8.30433518e-03, ...,\n",
      "           5.01750559e-02,  6.15058690e-02, -3.76700088e-02],\n",
      "         [-1.39899552e-03, -4.49770242e-02,  4.95060682e-02, ...,\n",
      "           5.80224097e-02,  1.27790719e-02, -1.55010819e-03],\n",
      "         [-5.90757057e-02, -1.65548772e-02,  3.72934490e-02, ...,\n",
      "           3.45483422e-03, -3.91559377e-02, -2.39577889e-03]]],\n",
      "\n",
      "\n",
      "       [[[ 1.33677199e-02,  5.75567484e-02, -1.79484487e-05, ...,\n",
      "          -1.35268122e-02,  1.51555315e-02,  2.10702121e-02],\n",
      "         [-5.24040908e-02,  5.76164760e-02,  5.98993748e-02, ...,\n",
      "          -1.79165192e-02,  6.64268583e-02,  4.06569242e-03],\n",
      "         [-3.90011817e-02,  5.90511821e-02, -4.65580150e-02, ...,\n",
      "          -2.27557458e-02,  2.67001987e-03,  3.51961255e-02],\n",
      "         ...,\n",
      "         [-6.13918230e-02,  6.58679754e-02,  6.72581345e-02, ...,\n",
      "           1.82069987e-02, -2.54035667e-02,  3.54499072e-02],\n",
      "         [ 6.68664426e-02,  9.06167179e-03, -6.61321655e-02, ...,\n",
      "          -4.39918749e-02,  4.17275131e-02, -2.43786350e-02],\n",
      "         [-7.01240450e-03, -7.85127282e-04, -3.61758433e-02, ...,\n",
      "          -6.68075681e-03,  1.09565258e-02,  6.60061687e-02]],\n",
      "\n",
      "        [[ 6.59274086e-02, -2.60821693e-02,  6.49233758e-02, ...,\n",
      "           6.23051375e-02, -5.59181646e-02, -4.74618152e-02],\n",
      "         [ 2.27598026e-02, -2.03851201e-02, -5.59596866e-02, ...,\n",
      "           1.96636766e-02,  4.69048582e-02, -1.75259188e-02],\n",
      "         [ 1.01302043e-02,  3.19002569e-03, -5.61115146e-03, ...,\n",
      "          -1.08655356e-02, -1.01151839e-02, -4.63460386e-03],\n",
      "         ...,\n",
      "         [ 3.94691452e-02, -5.97550645e-02,  3.41080353e-02, ...,\n",
      "           4.13535163e-02,  5.33306599e-02, -8.02841038e-03],\n",
      "         [ 1.64640769e-02, -5.36207855e-02,  2.11972073e-02, ...,\n",
      "           3.85064632e-03,  6.35946840e-02,  3.95145863e-02],\n",
      "         [ 8.09410214e-03,  5.50705940e-03,  3.36802788e-02, ...,\n",
      "           3.69877741e-02,  1.61191970e-02, -4.48017791e-02]],\n",
      "\n",
      "        [[-1.07460767e-02, -1.67183205e-02, -2.38120556e-05, ...,\n",
      "           4.69904840e-02,  2.13391632e-02, -1.76278315e-02],\n",
      "         [-4.90954444e-02,  4.18115482e-02,  2.21799687e-02, ...,\n",
      "           4.40006852e-02,  3.86337712e-02,  1.22918934e-03],\n",
      "         [-4.77937460e-02, -1.63715780e-02,  6.88092411e-02, ...,\n",
      "          -5.08074425e-02,  6.03589714e-02,  5.86237311e-02],\n",
      "         ...,\n",
      "         [-1.06850751e-02,  5.34343123e-02,  6.39038086e-02, ...,\n",
      "           1.14696994e-02,  1.36758685e-02,  2.04989538e-02],\n",
      "         [ 4.73245978e-04,  3.85121107e-02, -4.26261872e-02, ...,\n",
      "           4.78745624e-02, -3.88380140e-02,  4.86207753e-03],\n",
      "         [-1.05293058e-02,  6.91453516e-02, -4.50744331e-02, ...,\n",
      "          -4.58855405e-02, -3.72324176e-02,  3.37342136e-02]]]],\n",
      "      dtype=float32)>, <tf.Variable 'basic_block_8/conv2d_22/bias:0' shape=(64,) dtype=float32, numpy=\n",
      "array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32)>, <tf.Variable 'basic_block_8/batch_normalization_24/gamma:0' shape=(64,) dtype=float32, numpy=\n",
      "array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32)>, <tf.Variable 'basic_block_8/batch_normalization_24/beta:0' shape=(64,) dtype=float32, numpy=\n",
      "array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32)>, <tf.Variable 'basic_block_8/batch_normalization_23/moving_mean:0' shape=(64,) dtype=float32, numpy=\n",
      "array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32)>, <tf.Variable 'basic_block_8/batch_normalization_23/moving_variance:0' shape=(64,) dtype=float32, numpy=\n",
      "array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32)>, <tf.Variable 'basic_block_8/batch_normalization_24/moving_mean:0' shape=(64,) dtype=float32, numpy=\n",
      "array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32)>, <tf.Variable 'basic_block_8/batch_normalization_24/moving_variance:0' shape=(64,) dtype=float32, numpy=\n",
      "array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32)>, <tf.Variable 'basic_block_9/conv2d_23/kernel:0' shape=(3, 3, 64, 64) dtype=float32, numpy=\n",
      "array([[[[-0.06832818, -0.00826627,  0.06778559, ..., -0.06955147,\n",
      "           0.04609822, -0.063101  ],\n",
      "         [-0.05120016, -0.00954285, -0.06408378, ..., -0.03804749,\n",
      "          -0.03378965, -0.05876379],\n",
      "         [-0.02345393,  0.05744116,  0.01459698, ...,  0.0219897 ,\n",
      "          -0.07179452,  0.05771643],\n",
      "         ...,\n",
      "         [ 0.03275957,  0.05022497, -0.03093665, ..., -0.02174667,\n",
      "          -0.01771304, -0.02864406],\n",
      "         [-0.02797114, -0.00706826,  0.04202949, ..., -0.04398385,\n",
      "           0.03916745, -0.04099907],\n",
      "         [ 0.01564531, -0.05741399, -0.02250677, ...,  0.07010834,\n",
      "           0.04114663, -0.02365547]],\n",
      "\n",
      "        [[ 0.01158568,  0.06398113, -0.06658573, ..., -0.06880561,\n",
      "          -0.00778946,  0.05693668],\n",
      "         [-0.00767279, -0.01475077, -0.05740457, ..., -0.02383092,\n",
      "           0.06420881, -0.0110101 ],\n",
      "         [ 0.00463874,  0.03316634,  0.06345865, ..., -0.05942477,\n",
      "           0.03077868,  0.06308867],\n",
      "         ...,\n",
      "         [-0.06872109,  0.00897049,  0.05737659, ...,  0.04892959,\n",
      "          -0.01932467, -0.01422599],\n",
      "         [-0.02690966, -0.01686647, -0.0611324 , ...,  0.04414023,\n",
      "          -0.02551868, -0.04351684],\n",
      "         [ 0.00073958,  0.00649286,  0.01234945, ...,  0.01459689,\n",
      "           0.06420559, -0.04846832]],\n",
      "\n",
      "        [[ 0.06251822,  0.01770261, -0.02324274, ...,  0.03291869,\n",
      "          -0.02345752,  0.03278207],\n",
      "         [-0.02839188, -0.00523227,  0.03936251, ..., -0.04973073,\n",
      "           0.03312682,  0.05955178],\n",
      "         [-0.06645206,  0.04463165, -0.00231978, ...,  0.0316733 ,\n",
      "           0.00012545,  0.05366719],\n",
      "         ...,\n",
      "         [-0.03929276,  0.04822987, -0.00117329, ..., -0.05098569,\n",
      "           0.00532006, -0.0368626 ],\n",
      "         [ 0.02187528,  0.03192063,  0.02872843, ...,  0.04957185,\n",
      "          -0.06917537,  0.06648748],\n",
      "         [-0.05679972, -0.01406745,  0.04279892, ...,  0.02488708,\n",
      "          -0.01665254, -0.00952304]]],\n",
      "\n",
      "\n",
      "       [[[-0.02651723, -0.02123317, -0.01214641, ..., -0.05563226,\n",
      "          -0.01406012, -0.01660106],\n",
      "         [ 0.03581958, -0.02484861, -0.05538955, ...,  0.02188957,\n",
      "          -0.05959223,  0.01320177],\n",
      "         [ 0.06379017, -0.06949985, -0.05707636, ..., -0.05887209,\n",
      "          -0.0553332 , -0.05171157],\n",
      "         ...,\n",
      "         [ 0.05884925, -0.05971586,  0.04527332, ..., -0.06634537,\n",
      "          -0.01652841,  0.04664808],\n",
      "         [ 0.0020372 , -0.06961033,  0.00864748, ..., -0.02573513,\n",
      "          -0.06234437, -0.02164821],\n",
      "         [ 0.04754871,  0.02459325, -0.05891722, ..., -0.04268324,\n",
      "          -0.04958555,  0.01779253]],\n",
      "\n",
      "        [[-0.05900976, -0.05961322,  0.03392144, ...,  0.01049684,\n",
      "           0.03998095, -0.01700843],\n",
      "         [ 0.02164817,  0.05955769,  0.04352944, ..., -0.02813298,\n",
      "           0.01735628,  0.01905152],\n",
      "         [ 0.05408661, -0.05621902, -0.00567479, ...,  0.05222683,\n",
      "          -0.05571565, -0.05883272],\n",
      "         ...,\n",
      "         [-0.00318117, -0.05875082, -0.03113551, ..., -0.02193541,\n",
      "          -0.00968759,  0.03452314],\n",
      "         [ 0.0091455 ,  0.00105659,  0.05570017, ..., -0.05867511,\n",
      "           0.03452424,  0.02608883],\n",
      "         [ 0.05664781,  0.01437596, -0.0256794 , ..., -0.02627006,\n",
      "          -0.01720905, -0.03665999]],\n",
      "\n",
      "        [[-0.05861279,  0.00337018, -0.06653799, ...,  0.00498269,\n",
      "          -0.06180641,  0.06834915],\n",
      "         [-0.00953588,  0.02968495,  0.00900505, ..., -0.06235774,\n",
      "           0.05803846,  0.04727612],\n",
      "         [ 0.00950496, -0.03169957,  0.0203546 , ..., -0.00412812,\n",
      "          -0.06350697, -0.02962537],\n",
      "         ...,\n",
      "         [-0.02620284,  0.0440564 , -0.04329624, ...,  0.02015168,\n",
      "           0.06363122,  0.01493947],\n",
      "         [-0.02676082, -0.03735968, -0.0562385 , ...,  0.01576858,\n",
      "          -0.0333078 ,  0.02525581],\n",
      "         [ 0.01551511,  0.07134625,  0.05773401, ...,  0.01616871,\n",
      "          -0.03493736, -0.06684226]]],\n",
      "\n",
      "\n",
      "       [[[ 0.03950807,  0.01151958, -0.03463116, ..., -0.03645869,\n",
      "           0.06805409, -0.04487035],\n",
      "         [ 0.01581749,  0.02599865,  0.0503975 , ..., -0.02104581,\n",
      "           0.05289385,  0.01304672],\n",
      "         [-0.02952341,  0.01268324, -0.02260564, ...,  0.01169127,\n",
      "           0.00795443,  0.05171487],\n",
      "         ...,\n",
      "         [-0.06699583, -0.00356817,  0.03385957, ...,  0.03633699,\n",
      "          -0.00761164, -0.02423754],\n",
      "         [ 0.0252197 ,  0.01206709,  0.05317925, ...,  0.04025718,\n",
      "           0.03748131, -0.06215925],\n",
      "         [ 0.05499569, -0.03569334, -0.04106171, ..., -0.06780759,\n",
      "           0.02669811,  0.00643893]],\n",
      "\n",
      "        [[ 0.06051973, -0.04936704,  0.0101348 , ..., -0.04574636,\n",
      "          -0.06428706,  0.05092008],\n",
      "         [ 0.02591972,  0.00759409,  0.00071226, ...,  0.00616886,\n",
      "          -0.06964681, -0.03428064],\n",
      "         [-0.03335228,  0.00315897,  0.03859883, ..., -0.03543209,\n",
      "           0.04360545, -0.021184  ],\n",
      "         ...,\n",
      "         [-0.05891471, -0.04824718, -0.0148787 , ...,  0.0657704 ,\n",
      "           0.05373263,  0.00037376],\n",
      "         [-0.00403608,  0.02017254, -0.05910604, ..., -0.01532753,\n",
      "          -0.01395857,  0.02480061],\n",
      "         [-0.02206063,  0.02353057, -0.01003313, ...,  0.03872698,\n",
      "          -0.04850534,  0.04458045]],\n",
      "\n",
      "        [[-0.05606413,  0.05991969,  0.0683167 , ...,  0.0096259 ,\n",
      "          -0.00254565, -0.05823041],\n",
      "         [ 0.01190709,  0.06301269, -0.03667996, ..., -0.00535966,\n",
      "          -0.05371492,  0.05966792],\n",
      "         [ 0.03104948, -0.01783099,  0.01379914, ...,  0.00147686,\n",
      "          -0.06177016, -0.0328512 ],\n",
      "         ...,\n",
      "         [-0.06310648,  0.06843553, -0.06809002, ..., -0.0107858 ,\n",
      "           0.06070383,  0.00723523],\n",
      "         [ 0.03782433,  0.04826666, -0.02739809, ...,  0.03390859,\n",
      "           0.04388165,  0.02319222],\n",
      "         [ 0.03657954, -0.04758018, -0.02359702, ...,  0.04183826,\n",
      "           0.05032021, -0.03350156]]]], dtype=float32)>, <tf.Variable 'basic_block_9/conv2d_23/bias:0' shape=(64,) dtype=float32, numpy=\n",
      "array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32)>, <tf.Variable 'basic_block_9/batch_normalization_25/gamma:0' shape=(64,) dtype=float32, numpy=\n",
      "array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32)>, <tf.Variable 'basic_block_9/batch_normalization_25/beta:0' shape=(64,) dtype=float32, numpy=\n",
      "array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32)>, <tf.Variable 'basic_block_9/conv2d_24/kernel:0' shape=(3, 3, 64, 64) dtype=float32, numpy=\n",
      "array([[[[ 0.06724288,  0.05753542, -0.03081621, ..., -0.05468142,\n",
      "          -0.01737431, -0.00232568],\n",
      "         [-0.03671113, -0.01954997,  0.05970572, ..., -0.0378653 ,\n",
      "           0.01757175,  0.00420479],\n",
      "         [ 0.01571354, -0.0554186 , -0.02348222, ...,  0.05157933,\n",
      "          -0.03061577, -0.07104892],\n",
      "         ...,\n",
      "         [-0.01628284,  0.04251786, -0.00553622, ...,  0.06899668,\n",
      "           0.01597845, -0.0136307 ],\n",
      "         [-0.02211405,  0.01832639,  0.02094915, ..., -0.01921016,\n",
      "          -0.04075609, -0.02027823],\n",
      "         [ 0.01469163, -0.02303991, -0.0698536 , ..., -0.01159196,\n",
      "          -0.03610712,  0.03122727]],\n",
      "\n",
      "        [[-0.04273201, -0.04137172,  0.0530576 , ..., -0.03174019,\n",
      "          -0.06977557,  0.04563697],\n",
      "         [ 0.0238682 , -0.06329545,  0.03671347, ...,  0.05500224,\n",
      "           0.01932576,  0.0513508 ],\n",
      "         [ 0.02222925, -0.01902004,  0.06997815, ...,  0.01344076,\n",
      "          -0.03682514,  0.05356461],\n",
      "         ...,\n",
      "         [ 0.06897643, -0.01867864, -0.01742368, ..., -0.06692789,\n",
      "          -0.0064913 ,  0.0141945 ],\n",
      "         [-0.06541474, -0.02875072, -0.03406163, ...,  0.05779214,\n",
      "          -0.02537537,  0.05497144],\n",
      "         [-0.07088153,  0.07015499,  0.0572567 , ..., -0.05873557,\n",
      "          -0.04274555, -0.00082835]],\n",
      "\n",
      "        [[ 0.01571123, -0.07143619, -0.0661846 , ..., -0.05965889,\n",
      "           0.03999446, -0.00101379],\n",
      "         [-0.00083836, -0.00197292, -0.04079204, ...,  0.04441699,\n",
      "          -0.00290912, -0.01417284],\n",
      "         [ 0.00323816, -0.04485887,  0.06520173, ...,  0.01953805,\n",
      "           0.0256718 ,  0.02503692],\n",
      "         ...,\n",
      "         [-0.00311776, -0.06067365,  0.06564316, ..., -0.01446857,\n",
      "           0.04975771,  0.02741064],\n",
      "         [-0.00637498, -0.00922637, -0.03989237, ...,  0.00200514,\n",
      "          -0.03798764, -0.02764325],\n",
      "         [-0.04129951,  0.02440919,  0.01297569, ..., -0.03182549,\n",
      "           0.06278634, -0.05420154]]],\n",
      "\n",
      "\n",
      "       [[[ 0.00397065,  0.03602961,  0.02549502, ..., -0.07074769,\n",
      "           0.0155303 , -0.00214672],\n",
      "         [-0.03578072,  0.03701588,  0.04857942, ..., -0.00210264,\n",
      "          -0.05916138,  0.03375898],\n",
      "         [ 0.02695479, -0.02698364,  0.03067169, ...,  0.0458311 ,\n",
      "          -0.02589928, -0.0636141 ],\n",
      "         ...,\n",
      "         [ 0.0637729 , -0.07128494,  0.04022662, ..., -0.05422328,\n",
      "           0.04838707,  0.00108395],\n",
      "         [ 0.05214663,  0.00212296,  0.04276849, ...,  0.03202752,\n",
      "           0.06753233,  0.04080422],\n",
      "         [ 0.07119638,  0.06190996,  0.05583289, ..., -0.06876512,\n",
      "          -0.06385413, -0.05719048]],\n",
      "\n",
      "        [[ 0.01298992, -0.05393527,  0.05706388, ...,  0.07031932,\n",
      "          -0.06425808, -0.05185798],\n",
      "         [-0.04815405,  0.02483689, -0.05238451, ...,  0.07138531,\n",
      "          -0.02741088, -0.03019562],\n",
      "         [ 0.04196796, -0.04811962, -0.01664332, ..., -0.06281836,\n",
      "          -0.0451005 , -0.06437457],\n",
      "         ...,\n",
      "         [ 0.0394939 , -0.01402258, -0.01708638, ...,  0.01690874,\n",
      "          -0.03338142,  0.06818309],\n",
      "         [-0.07131068, -0.05381856, -0.03051842, ...,  0.00101421,\n",
      "          -0.02732679,  0.00966744],\n",
      "         [-0.01976553, -0.03610184, -0.01850038, ..., -0.03938556,\n",
      "          -0.03130425,  0.03357295]],\n",
      "\n",
      "        [[ 0.02074955,  0.00875166,  0.02478016, ..., -0.01026152,\n",
      "          -0.05253057,  0.07140572],\n",
      "         [ 0.04389368,  0.04221366, -0.02277846, ...,  0.06148756,\n",
      "           0.03182817, -0.06896948],\n",
      "         [-0.0496766 ,  0.06221707, -0.04989138, ...,  0.05696376,\n",
      "           0.02759905,  0.05704917],\n",
      "         ...,\n",
      "         [ 0.06079911, -0.04608599,  0.05003651, ..., -0.02675012,\n",
      "          -0.02765086, -0.03988358],\n",
      "         [ 0.0061297 ,  0.00324085,  0.0154654 , ...,  0.05222091,\n",
      "          -0.0459612 ,  0.05535634],\n",
      "         [-0.03340257, -0.03017847, -0.02820363, ..., -0.05882221,\n",
      "           0.06517154,  0.02642678]]],\n",
      "\n",
      "\n",
      "       [[[ 0.03377748,  0.03610375,  0.01188895, ...,  0.01636464,\n",
      "          -0.02594713, -0.03652974],\n",
      "         [-0.00443687,  0.06060214,  0.0603793 , ..., -0.06745494,\n",
      "           0.01603986,  0.01319674],\n",
      "         [ 0.06430589, -0.04801497,  0.01621503, ..., -0.06482386,\n",
      "           0.02961357,  0.05198202],\n",
      "         ...,\n",
      "         [-0.01725371,  0.05587058, -0.0578209 , ..., -0.03312618,\n",
      "           0.03657145, -0.04132912],\n",
      "         [ 0.01525485,  0.05900925, -0.03735342, ...,  0.01610658,\n",
      "          -0.00773931,  0.00035653],\n",
      "         [ 0.02293588, -0.02767242,  0.05571547, ..., -0.00947612,\n",
      "          -0.0187283 ,  0.00082589]],\n",
      "\n",
      "        [[ 0.00886086,  0.02296959, -0.02180031, ...,  0.00765418,\n",
      "           0.06731705, -0.04425425],\n",
      "         [-0.06790019, -0.0008109 ,  0.04424581, ..., -0.02170124,\n",
      "           0.02877811, -0.02315552],\n",
      "         [-0.0555435 ,  0.01531127,  0.03459621, ..., -0.04451402,\n",
      "          -0.03815275, -0.05050353],\n",
      "         ...,\n",
      "         [ 0.05689482, -0.05873878,  0.03226702, ..., -0.04490235,\n",
      "          -0.06912718, -0.03907092],\n",
      "         [-0.0681801 , -0.05264033,  0.04832162, ..., -0.0478029 ,\n",
      "          -0.04188681,  0.0563661 ],\n",
      "         [-0.01160491, -0.05704904, -0.03027646, ..., -0.02123971,\n",
      "          -0.06702869, -0.04380524]],\n",
      "\n",
      "        [[-0.00721364,  0.01563957, -0.01270669, ..., -0.03567246,\n",
      "          -0.01240711, -0.04299614],\n",
      "         [ 0.06747958,  0.03521798, -0.01438207, ...,  0.03165611,\n",
      "           0.05484949,  0.04934161],\n",
      "         [ 0.00018827,  0.00053637, -0.04512985, ..., -0.00543408,\n",
      "          -0.01624661, -0.02657967],\n",
      "         ...,\n",
      "         [-0.02126481, -0.00804994,  0.05724526, ..., -0.06938607,\n",
      "           0.03891525, -0.04356094],\n",
      "         [ 0.03948659, -0.02460371,  0.05296344, ..., -0.04186357,\n",
      "           0.06943226,  0.00269662],\n",
      "         [-0.04105877, -0.03668527, -0.03785124, ...,  0.01623768,\n",
      "          -0.02532762,  0.03750776]]]], dtype=float32)>, <tf.Variable 'basic_block_9/conv2d_24/bias:0' shape=(64,) dtype=float32, numpy=\n",
      "array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32)>, <tf.Variable 'basic_block_9/batch_normalization_26/gamma:0' shape=(64,) dtype=float32, numpy=\n",
      "array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32)>, <tf.Variable 'basic_block_9/batch_normalization_26/beta:0' shape=(64,) dtype=float32, numpy=\n",
      "array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32)>, <tf.Variable 'basic_block_9/batch_normalization_25/moving_mean:0' shape=(64,) dtype=float32, numpy=\n",
      "array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32)>, <tf.Variable 'basic_block_9/batch_normalization_25/moving_variance:0' shape=(64,) dtype=float32, numpy=\n",
      "array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32)>, <tf.Variable 'basic_block_9/batch_normalization_26/moving_mean:0' shape=(64,) dtype=float32, numpy=\n",
      "array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32)>, <tf.Variable 'basic_block_9/batch_normalization_26/moving_variance:0' shape=(64,) dtype=float32, numpy=\n",
      "array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32)>, <tf.Variable 'basic_block_10/conv2d_25/kernel:0' shape=(3, 3, 64, 128) dtype=float32, numpy=\n",
      "array([[[[-0.02423785,  0.00372644, -0.03588967, ...,  0.0348735 ,\n",
      "           0.04842368,  0.05188225],\n",
      "         [ 0.0319124 ,  0.05339162, -0.00467528, ..., -0.03579303,\n",
      "          -0.04400004, -0.0359074 ],\n",
      "         [-0.00618999, -0.00878891,  0.03138127, ...,  0.05354673,\n",
      "           0.00419559,  0.04897134],\n",
      "         ...,\n",
      "         [-0.05537181,  0.00057184, -0.04475258, ...,  0.00702891,\n",
      "          -0.00881794,  0.02800217],\n",
      "         [-0.0394058 ,  0.03982259, -0.05880442, ...,  0.01926779,\n",
      "          -0.03320846, -0.05677303],\n",
      "         [-0.00531657, -0.04450617, -0.02247925, ...,  0.05037977,\n",
      "           0.02925875,  0.03520222]],\n",
      "\n",
      "        [[-0.01268818,  0.01094541, -0.01370972, ..., -0.02946335,\n",
      "          -0.03099892,  0.04049532],\n",
      "         [ 0.00106917, -0.00428435, -0.01553449, ...,  0.03895954,\n",
      "           0.0384415 ,  0.04778088],\n",
      "         [ 0.01784546, -0.05206586, -0.01283249, ...,  0.02905549,\n",
      "           0.01629105, -0.00259772],\n",
      "         ...,\n",
      "         [-0.01501546,  0.05675762, -0.02505906, ...,  0.03037891,\n",
      "           0.04467004,  0.04101568],\n",
      "         [-0.00362197, -0.00460259, -0.0544831 , ..., -0.04142872,\n",
      "           0.01120489,  0.02767709],\n",
      "         [ 0.04899931,  0.03423673,  0.01195512, ..., -0.0390836 ,\n",
      "          -0.03240573,  0.01494474]],\n",
      "\n",
      "        [[ 0.0469888 , -0.00277079, -0.02794514, ...,  0.02599989,\n",
      "           0.04890634, -0.04172276],\n",
      "         [-0.01021061,  0.00315594,  0.04894863, ...,  0.04760555,\n",
      "          -0.05855742,  0.01942806],\n",
      "         [-0.00194119,  0.05529267,  0.04368726, ..., -0.05032885,\n",
      "           0.02394748,  0.00505248],\n",
      "         ...,\n",
      "         [-0.00059823, -0.00772587,  0.05149002, ...,  0.05584723,\n",
      "           0.05317668, -0.05069883],\n",
      "         [ 0.04213252, -0.00020138,  0.00897751, ...,  0.02230975,\n",
      "          -0.01554615, -0.00734045],\n",
      "         [ 0.05836141, -0.02753093, -0.04270341, ...,  0.03826689,\n",
      "          -0.02498114,  0.01784698]]],\n",
      "\n",
      "\n",
      "       [[[-0.02035507, -0.01174794, -0.04194988, ...,  0.04724608,\n",
      "           0.03757334,  0.04617506],\n",
      "         [ 0.05255653,  0.03041169, -0.05820502, ...,  0.0157667 ,\n",
      "          -0.02017031,  0.0514749 ],\n",
      "         [-0.00745913,  0.01104015, -0.04629887, ...,  0.0294476 ,\n",
      "           0.03126692, -0.04429569],\n",
      "         ...,\n",
      "         [-0.04637961, -0.01015206,  0.01135106, ..., -0.01866417,\n",
      "           0.00638125, -0.04908686],\n",
      "         [-0.02295008, -0.03357375, -0.03746672, ..., -0.04097533,\n",
      "           0.01626933, -0.034676  ],\n",
      "         [-0.05751113,  0.04164886,  0.00401234, ...,  0.02525407,\n",
      "          -0.00125093,  0.03803727]],\n",
      "\n",
      "        [[-0.03132647,  0.05156785, -0.02947208, ...,  0.00707259,\n",
      "          -0.05387771, -0.03096955],\n",
      "         [-0.01158113,  0.00615164, -0.01900262, ..., -0.0312184 ,\n",
      "           0.02247449,  0.01776636],\n",
      "         [-0.01380172,  0.01755314,  0.02964915, ...,  0.05412336,\n",
      "          -0.05631635, -0.01966354],\n",
      "         ...,\n",
      "         [ 0.02495563, -0.05406458, -0.02066362, ...,  0.01072795,\n",
      "           0.00545795, -0.02932045],\n",
      "         [-0.02097469,  0.02665008,  0.00931069, ...,  0.01243887,\n",
      "          -0.03758617, -0.04962242],\n",
      "         [-0.01706902, -0.04066935, -0.00330677, ..., -0.02835259,\n",
      "           0.04284981, -0.02088677]],\n",
      "\n",
      "        [[-0.05179415, -0.01521432,  0.05805467, ...,  0.03065696,\n",
      "           0.04333356,  0.01927787],\n",
      "         [-0.01303028,  0.03466984, -0.03015231, ...,  0.00451541,\n",
      "          -0.00379903, -0.03624831],\n",
      "         [-0.03328669,  0.04421289, -0.01880367, ...,  0.02806157,\n",
      "           0.04045044,  0.02041506],\n",
      "         ...,\n",
      "         [ 0.03085822, -0.0406734 ,  0.00703319, ...,  0.02560876,\n",
      "          -0.00126006,  0.01723688],\n",
      "         [-0.05519905,  0.00839176, -0.00319795, ..., -0.00461567,\n",
      "          -0.04728289,  0.03752164],\n",
      "         [-0.00729974,  0.01092625, -0.01098577, ...,  0.0274058 ,\n",
      "          -0.0057771 , -0.04511428]]],\n",
      "\n",
      "\n",
      "       [[[-0.04254795,  0.00835418,  0.04944688, ..., -0.04267793,\n",
      "           0.04143595,  0.01698737],\n",
      "         [ 0.02118931,  0.03250803,  0.05712489, ...,  0.05245389,\n",
      "           0.03634913,  0.05191406],\n",
      "         [ 0.00714   , -0.04077435,  0.05609506, ...,  0.05186345,\n",
      "           0.03620327, -0.04111462],\n",
      "         ...,\n",
      "         [ 0.00280482,  0.01917926, -0.03664663, ..., -0.0281768 ,\n",
      "           0.03086137, -0.01973269],\n",
      "         [ 0.03624851, -0.03074236, -0.01930237, ...,  0.04534021,\n",
      "          -0.02398365,  0.04594526],\n",
      "         [-0.02686561,  0.03881411,  0.03926916, ...,  0.0519972 ,\n",
      "           0.02154915,  0.0305058 ]],\n",
      "\n",
      "        [[ 0.0523917 ,  0.01430098, -0.00505942, ...,  0.0246419 ,\n",
      "           0.00999708,  0.05672048],\n",
      "         [ 0.02897253, -0.04627687,  0.01509522, ...,  0.02885123,\n",
      "          -0.04772642, -0.02237981],\n",
      "         [-0.03146532,  0.02094167, -0.0152376 , ..., -0.016211  ,\n",
      "           0.05697392,  0.05888248],\n",
      "         ...,\n",
      "         [ 0.04600943, -0.02640733, -0.04383821, ..., -0.05888279,\n",
      "           0.01685249,  0.03302063],\n",
      "         [ 0.03692938,  0.05157788, -0.02019856, ...,  0.00046405,\n",
      "           0.05287611, -0.03962404],\n",
      "         [ 0.05825254, -0.0260792 ,  0.01612711, ...,  0.02028449,\n",
      "          -0.02031796,  0.04911992]],\n",
      "\n",
      "        [[ 0.04538232, -0.00982654,  0.02021528, ..., -0.05574384,\n",
      "           0.01134029,  0.01484824],\n",
      "         [ 0.03100659, -0.04659549, -0.04644052, ...,  0.04230237,\n",
      "          -0.01515983, -0.05718636],\n",
      "         [ 0.00261541, -0.00801154,  0.01508327, ..., -0.04399915,\n",
      "           0.0343259 , -0.02457633],\n",
      "         ...,\n",
      "         [-0.01891534, -0.00721043,  0.05858162, ...,  0.04472369,\n",
      "          -0.05018182, -0.03983772],\n",
      "         [ 0.04015442,  0.00258474,  0.02747038, ..., -0.04103421,\n",
      "           0.0067316 , -0.0369219 ],\n",
      "         [-0.04846205,  0.044354  ,  0.04615337, ...,  0.03563057,\n",
      "          -0.0252174 , -0.00878214]]]], dtype=float32)>, <tf.Variable 'basic_block_10/conv2d_25/bias:0' shape=(128,) dtype=float32, numpy=\n",
      "array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32)>, <tf.Variable 'basic_block_10/batch_normalization_27/gamma:0' shape=(128,) dtype=float32, numpy=\n",
      "array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32)>, <tf.Variable 'basic_block_10/batch_normalization_27/beta:0' shape=(128,) dtype=float32, numpy=\n",
      "array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32)>, <tf.Variable 'basic_block_10/conv2d_26/kernel:0' shape=(3, 3, 128, 128) dtype=float32, numpy=\n",
      "array([[[[-0.0475037 , -0.0143135 , -0.02629622, ..., -0.01259234,\n",
      "           0.03429164, -0.02269187],\n",
      "         [-0.01116606, -0.04039685, -0.01316831, ..., -0.03460902,\n",
      "          -0.01098729, -0.01735969],\n",
      "         [-0.03971896, -0.01792971,  0.00689171, ...,  0.00679211,\n",
      "           0.03409303,  0.04600868],\n",
      "         ...,\n",
      "         [-0.02038037,  0.0435116 , -0.04042173, ...,  0.00264898,\n",
      "           0.02568066,  0.04149395],\n",
      "         [ 0.03597821, -0.01252736, -0.04427023, ..., -0.01389271,\n",
      "          -0.04435372, -0.00479001],\n",
      "         [ 0.03395423, -0.02526525,  0.02054056, ..., -0.03552821,\n",
      "          -0.00651695, -0.02104021]],\n",
      "\n",
      "        [[ 0.04640631, -0.02137418,  0.03105836, ...,  0.00673141,\n",
      "           0.00804625, -0.02227779],\n",
      "         [-0.04097673,  0.04782394, -0.03147511, ..., -0.03558735,\n",
      "           0.00301787, -0.04126731],\n",
      "         [ 0.00089166,  0.01858635,  0.04177228, ...,  0.00646235,\n",
      "          -0.05026437,  0.03541773],\n",
      "         ...,\n",
      "         [ 0.04989371,  0.02752523, -0.03629778, ..., -0.03699932,\n",
      "           0.00634345, -0.01680446],\n",
      "         [-0.00120518, -0.00883811, -0.03140812, ..., -0.03953986,\n",
      "          -0.02179757,  0.00261837],\n",
      "         [-0.03476945, -0.04699409,  0.03112253, ..., -0.00804104,\n",
      "           0.01438259,  0.04059837]],\n",
      "\n",
      "        [[-0.05025388,  0.00935912,  0.01205316, ...,  0.03335846,\n",
      "           0.03200895, -0.04609595],\n",
      "         [-0.05065534, -0.01455748, -0.01534687, ...,  0.00600004,\n",
      "           0.02115514, -0.02207771],\n",
      "         [-0.00590775,  0.01589281, -0.04451065, ...,  0.03516308,\n",
      "           0.0002177 , -0.04124893],\n",
      "         ...,\n",
      "         [-0.0027245 ,  0.03898744, -0.00944567, ..., -0.02090014,\n",
      "           0.04731716, -0.02656868],\n",
      "         [-0.00236531,  0.0074338 ,  0.02060308, ...,  0.0289983 ,\n",
      "           0.0191296 ,  0.02183351],\n",
      "         [-0.0398467 , -0.01047742, -0.00711264, ...,  0.00522373,\n",
      "           0.0137874 , -0.03730723]]],\n",
      "\n",
      "\n",
      "       [[[ 0.04036999,  0.01749124,  0.02858216, ...,  0.0232287 ,\n",
      "          -0.03866766,  0.03698055],\n",
      "         [-0.02944566, -0.01876989, -0.03235733, ...,  0.02155319,\n",
      "          -0.02665641,  0.03191061],\n",
      "         [ 0.04851459,  0.02580355, -0.00534316, ...,  0.01170617,\n",
      "          -0.02109512, -0.036502  ],\n",
      "         ...,\n",
      "         [-0.04875191, -0.01297384,  0.02680233, ..., -0.01298395,\n",
      "          -0.02100982,  0.03953716],\n",
      "         [ 0.01546782, -0.00778313,  0.04497216, ...,  0.01525263,\n",
      "          -0.02204461, -0.02933316],\n",
      "         [ 0.02893051,  0.0430995 ,  0.03098433, ...,  0.01213147,\n",
      "          -0.03037481,  0.00813796]],\n",
      "\n",
      "        [[ 0.03296728, -0.01422446, -0.00548242, ...,  0.04168876,\n",
      "           0.00487317,  0.04767786],\n",
      "         [ 0.01474468,  0.01495444, -0.01419165, ..., -0.03453312,\n",
      "          -0.04709894, -0.04342072],\n",
      "         [ 0.0183823 ,  0.02989335, -0.03176943, ..., -0.00467269,\n",
      "           0.02188967, -0.01101694],\n",
      "         ...,\n",
      "         [ 0.04194089,  0.01673426, -0.02404327, ...,  0.03733224,\n",
      "          -0.04453473,  0.03885729],\n",
      "         [ 0.02109982, -0.01760815,  0.02098527, ...,  0.04113939,\n",
      "          -0.0014074 , -0.03666759],\n",
      "         [ 0.04353267, -0.00651778, -0.04247281, ..., -0.01821564,\n",
      "          -0.01642948,  0.03677617]],\n",
      "\n",
      "        [[-0.04003286, -0.04378214,  0.04910508, ..., -0.02980655,\n",
      "          -0.00308836,  0.02958685],\n",
      "         [ 0.01780799,  0.03693049, -0.00832931, ...,  0.01273451,\n",
      "           0.00576008,  0.04640009],\n",
      "         [ 0.01258049, -0.02049014, -0.04634696, ...,  0.05004784,\n",
      "          -0.01934803,  0.007872  ],\n",
      "         ...,\n",
      "         [ 0.04279961,  0.04894637, -0.03517167, ...,  0.00572416,\n",
      "          -0.044783  , -0.0216329 ],\n",
      "         [ 0.01060671,  0.03745659,  0.0457071 , ...,  0.01891869,\n",
      "          -0.00179615,  0.0003656 ],\n",
      "         [ 0.00611013, -0.02593109,  0.01742785, ..., -0.04417175,\n",
      "          -0.02491383, -0.00667575]]],\n",
      "\n",
      "\n",
      "       [[[-0.03490525,  0.00293215,  0.01067957, ...,  0.00463651,\n",
      "           0.00460023,  0.02193792],\n",
      "         [ 0.01706215, -0.03673578,  0.0240877 , ...,  0.04150345,\n",
      "           0.02456612,  0.00452356],\n",
      "         [-0.02368186,  0.02592094, -0.03893188, ..., -0.02023425,\n",
      "           0.03588443,  0.02948895],\n",
      "         ...,\n",
      "         [-0.0023786 , -0.01751521,  0.02137476, ..., -0.00691638,\n",
      "          -0.02811531,  0.04867197],\n",
      "         [-0.02612869, -0.04610199, -0.02559225, ...,  0.02505945,\n",
      "           0.01477255, -0.02038997],\n",
      "         [-0.01823856, -0.00105426, -0.03788843, ..., -0.02201662,\n",
      "          -0.00772411, -0.02196503]],\n",
      "\n",
      "        [[-0.05005335, -0.02000352,  0.02253946, ..., -0.00961198,\n",
      "          -0.00398747, -0.02214022],\n",
      "         [ 0.03087007, -0.04229563, -0.03317825, ...,  0.04057295,\n",
      "           0.01985613, -0.01755479],\n",
      "         [ 0.04442042,  0.00635817, -0.02266998, ...,  0.02162328,\n",
      "           0.03223069, -0.0011933 ],\n",
      "         ...,\n",
      "         [ 0.012451  , -0.04916068, -0.01550023, ...,  0.00035161,\n",
      "          -0.04282216, -0.02543584],\n",
      "         [-0.02386684, -0.02445403,  0.02247301, ...,  0.03106977,\n",
      "           0.03724758, -0.04764292],\n",
      "         [-0.03297372,  0.03590389,  0.00396495, ..., -0.03055228,\n",
      "           0.01378439, -0.04043773]],\n",
      "\n",
      "        [[-0.0132131 , -0.01233307, -0.03136687, ...,  0.03531316,\n",
      "          -0.02228807, -0.03775034],\n",
      "         [ 0.03994972,  0.00479138,  0.02777333, ...,  0.0435684 ,\n",
      "          -0.0461016 , -0.0448533 ],\n",
      "         [-0.0425915 ,  0.01048734,  0.01480301, ...,  0.03847938,\n",
      "          -0.03070559, -0.04362981],\n",
      "         ...,\n",
      "         [ 0.0174389 , -0.02167108, -0.00209869, ...,  0.02041314,\n",
      "          -0.04534272,  0.04876062],\n",
      "         [-0.03251898,  0.03159758, -0.00780802, ...,  0.0149548 ,\n",
      "           0.0496487 ,  0.03008861],\n",
      "         [-0.03452298, -0.03445124,  0.01515243, ..., -0.00349834,\n",
      "           0.02157309,  0.04314296]]]], dtype=float32)>, <tf.Variable 'basic_block_10/conv2d_26/bias:0' shape=(128,) dtype=float32, numpy=\n",
      "array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32)>, <tf.Variable 'basic_block_10/batch_normalization_28/gamma:0' shape=(128,) dtype=float32, numpy=\n",
      "array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32)>, <tf.Variable 'basic_block_10/batch_normalization_28/beta:0' shape=(128,) dtype=float32, numpy=\n",
      "array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32)>, <tf.Variable 'conv2d_27/kernel:0' shape=(1, 1, 64, 128) dtype=float32, numpy=\n",
      "array([[[[-0.14945833,  0.16933   ,  0.03469436, ...,  0.12303807,\n",
      "           0.0467419 ,  0.17034836],\n",
      "         [ 0.04305077,  0.07248279,  0.12422445, ..., -0.05971968,\n",
      "          -0.13010155,  0.13886653],\n",
      "         [ 0.17336884,  0.06242011, -0.07057018, ..., -0.02056611,\n",
      "          -0.15436953, -0.07041213],\n",
      "         ...,\n",
      "         [ 0.02394459,  0.17253216, -0.07797812, ..., -0.05860022,\n",
      "          -0.05561268, -0.13687687],\n",
      "         [ 0.122216  ,  0.12180476,  0.10617314, ...,  0.12263502,\n",
      "           0.04559143,  0.05765449],\n",
      "         [-0.00649069, -0.04238498,  0.106813  , ...,  0.15414555,\n",
      "          -0.07067891,  0.06098893]]]], dtype=float32)>, <tf.Variable 'conv2d_27/bias:0' shape=(128,) dtype=float32, numpy=\n",
      "array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32)>, <tf.Variable 'batch_normalization_29/gamma:0' shape=(128,) dtype=float32, numpy=\n",
      "array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32)>, <tf.Variable 'batch_normalization_29/beta:0' shape=(128,) dtype=float32, numpy=\n",
      "array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32)>, <tf.Variable 'basic_block_10/batch_normalization_27/moving_mean:0' shape=(128,) dtype=float32, numpy=\n",
      "array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32)>, <tf.Variable 'basic_block_10/batch_normalization_27/moving_variance:0' shape=(128,) dtype=float32, numpy=\n",
      "array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32)>, <tf.Variable 'basic_block_10/batch_normalization_28/moving_mean:0' shape=(128,) dtype=float32, numpy=\n",
      "array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32)>, <tf.Variable 'basic_block_10/batch_normalization_28/moving_variance:0' shape=(128,) dtype=float32, numpy=\n",
      "array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32)>, <tf.Variable 'batch_normalization_29/moving_mean:0' shape=(128,) dtype=float32, numpy=\n",
      "array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32)>, <tf.Variable 'batch_normalization_29/moving_variance:0' shape=(128,) dtype=float32, numpy=\n",
      "array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32)>, <tf.Variable 'basic_block_11/conv2d_28/kernel:0' shape=(3, 3, 128, 128) dtype=float32, numpy=\n",
      "array([[[[-0.04679478,  0.03612667, -0.0058298 , ..., -0.02965752,\n",
      "           0.03813958, -0.01095729],\n",
      "         [ 0.02655797, -0.00731388, -0.01478798, ..., -0.04759214,\n",
      "          -0.0410067 ,  0.01191445],\n",
      "         [-0.01341264,  0.03535848, -0.03927359, ..., -0.03700244,\n",
      "           0.0450945 , -0.04224059],\n",
      "         ...,\n",
      "         [-0.03174384, -0.05086822, -0.02944223, ...,  0.04028486,\n",
      "           0.00795287, -0.01971764],\n",
      "         [-0.01985101, -0.03513299,  0.02119236, ..., -0.02156685,\n",
      "          -0.04961897,  0.00226513],\n",
      "         [ 0.04311025, -0.04184241, -0.04350141, ..., -0.0187742 ,\n",
      "          -0.05023818,  0.00386744]],\n",
      "\n",
      "        [[ 0.05077963,  0.01222931,  0.0357075 , ...,  0.01220687,\n",
      "          -0.02873486, -0.02288798],\n",
      "         [-0.03270826, -0.02110881, -0.03387626, ...,  0.04255033,\n",
      "          -0.04165264,  0.04019212],\n",
      "         [-0.0223381 ,  0.04478156,  0.0110527 , ...,  0.03331289,\n",
      "           0.00039078, -0.00553246],\n",
      "         ...,\n",
      "         [-0.03405017, -0.01073286,  0.04217836, ..., -0.0013787 ,\n",
      "          -0.03229922,  0.02791901],\n",
      "         [ 0.03025332,  0.01049872, -0.03388358, ...,  0.03521883,\n",
      "          -0.02782843,  0.01498903],\n",
      "         [-0.03085391,  0.04823287, -0.03167263, ..., -0.02232159,\n",
      "          -0.04425943,  0.01899859]],\n",
      "\n",
      "        [[ 0.0033991 ,  0.00236753, -0.04268489, ...,  0.00290687,\n",
      "          -0.04898116, -0.02200563],\n",
      "         [ 0.03118772, -0.00720374, -0.01809499, ..., -0.03630775,\n",
      "           0.03679625, -0.00330968],\n",
      "         [-0.01303196,  0.00956917,  0.00488074, ..., -0.03821184,\n",
      "           0.02890228,  0.00432304],\n",
      "         ...,\n",
      "         [-0.00599216, -0.01855946,  0.03006906, ..., -0.00611872,\n",
      "          -0.05003871,  0.03732783],\n",
      "         [-0.00836868,  0.01812973,  0.0036263 , ...,  0.00217824,\n",
      "          -0.01013049,  0.02165991],\n",
      "         [-0.00553647,  0.01711434,  0.002433  , ..., -0.01590911,\n",
      "          -0.0370662 ,  0.02289843]]],\n",
      "\n",
      "\n",
      "       [[[-0.01198184, -0.05025984,  0.01963319, ..., -0.00365661,\n",
      "           0.04576668,  0.00034568],\n",
      "         [-0.02772349, -0.01714364,  0.04129427, ...,  0.04723593,\n",
      "          -0.01042497,  0.03065619],\n",
      "         [ 0.00878601,  0.00741282,  0.04673048, ..., -0.02598774,\n",
      "           0.02422575,  0.04609871],\n",
      "         ...,\n",
      "         [-0.03293408,  0.04644319,  0.00110621, ..., -0.03286554,\n",
      "          -0.01330282, -0.05054255],\n",
      "         [-0.02841546, -0.00246372,  0.02044293, ..., -0.03887419,\n",
      "          -0.00630631,  0.01443671],\n",
      "         [-0.01442922,  0.03227698,  0.00554509, ..., -0.00299267,\n",
      "          -0.0485995 ,  0.03001646]],\n",
      "\n",
      "        [[-0.01602484, -0.03797332, -0.00738716, ..., -0.01178832,\n",
      "          -0.0273629 ,  0.04961264],\n",
      "         [ 0.01053741, -0.02519612, -0.04608965, ...,  0.03017604,\n",
      "           0.04506963,  0.04739251],\n",
      "         [-0.04843676,  0.01839428,  0.00881143, ...,  0.02983011,\n",
      "          -0.00130245, -0.00450951],\n",
      "         ...,\n",
      "         [-0.04752782, -0.01182911, -0.02410448, ..., -0.03662924,\n",
      "           0.04337551, -0.02703332],\n",
      "         [ 0.0086356 , -0.01217374,  0.0366542 , ...,  0.02408069,\n",
      "           0.01571816, -0.04806018],\n",
      "         [-0.0270905 , -0.04717438, -0.00609476, ..., -0.03021026,\n",
      "          -0.00824813,  0.02780222]],\n",
      "\n",
      "        [[ 0.00954781,  0.02081694,  0.04643662, ...,  0.02921227,\n",
      "          -0.00884746, -0.02118745],\n",
      "         [ 0.01310254, -0.03139679,  0.00687722, ...,  0.04455655,\n",
      "           0.00116339, -0.03314847],\n",
      "         [ 0.04495246, -0.012537  , -0.00332028, ..., -0.0047617 ,\n",
      "           0.02245919, -0.00253301],\n",
      "         ...,\n",
      "         [ 0.00447157, -0.01502043, -0.01875182, ..., -0.00547782,\n",
      "           0.04557417, -0.04054802],\n",
      "         [-0.04203415, -0.01308307,  0.01366294, ...,  0.02313235,\n",
      "           0.01889978,  0.03545076],\n",
      "         [-0.01270783,  0.02088186, -0.04319919, ..., -0.00818805,\n",
      "          -0.04627621, -0.02327288]]],\n",
      "\n",
      "\n",
      "       [[[ 0.02691296,  0.0443203 ,  0.0325771 , ..., -0.04125777,\n",
      "          -0.02516828, -0.01692659],\n",
      "         [ 0.0098771 , -0.02211156,  0.02293443, ...,  0.00670697,\n",
      "           0.01320855, -0.02916358],\n",
      "         [ 0.02005563,  0.04793071,  0.03730507, ..., -0.04031872,\n",
      "          -0.04431237,  0.01044335],\n",
      "         ...,\n",
      "         [ 0.01529788, -0.01674274, -0.03077984, ...,  0.05030355,\n",
      "           0.02953551,  0.02209651],\n",
      "         [ 0.04693543,  0.0338368 , -0.04958965, ..., -0.03877576,\n",
      "           0.00392106, -0.04731186],\n",
      "         [-0.01871971,  0.01336414, -0.04925682, ..., -0.03369397,\n",
      "          -0.03196151, -0.00948313]],\n",
      "\n",
      "        [[-0.04528698, -0.01122165, -0.01239282, ..., -0.04533287,\n",
      "           0.01990856, -0.01194821],\n",
      "         [ 0.01484563,  0.02881588, -0.04810074, ..., -0.00357115,\n",
      "          -0.00992369,  0.04904755],\n",
      "         [-0.0183203 , -0.01526962,  0.0438541 , ...,  0.01070742,\n",
      "           0.00232471, -0.00384278],\n",
      "         ...,\n",
      "         [-0.01303096, -0.03342588, -0.01727283, ..., -0.04948848,\n",
      "           0.03234283,  0.01894636],\n",
      "         [-0.01300006, -0.01503309, -0.01846395, ...,  0.01202551,\n",
      "          -0.01461279,  0.02851158],\n",
      "         [-0.00307119,  0.0444659 ,  0.01070809, ...,  0.02255901,\n",
      "          -0.02267093,  0.00854003]],\n",
      "\n",
      "        [[-0.00300509, -0.03080433, -0.02119499, ..., -0.00037208,\n",
      "           0.0505491 ,  0.00572607],\n",
      "         [ 0.04441883, -0.03072216,  0.03357599, ...,  0.02351356,\n",
      "           0.05045819,  0.00037055],\n",
      "         [ 0.00061856, -0.00752157, -0.03412188, ...,  0.03216811,\n",
      "           0.04553026, -0.0056451 ],\n",
      "         ...,\n",
      "         [ 0.00337911,  0.01721863,  0.04921947, ..., -0.0306212 ,\n",
      "          -0.0041183 ,  0.01701733],\n",
      "         [ 0.03268301,  0.03501304,  0.02551047, ...,  0.00438042,\n",
      "           0.01424953,  0.00497389],\n",
      "         [ 0.00371373,  0.01362923, -0.01084745, ...,  0.04136568,\n",
      "          -0.04091507, -0.01047121]]]], dtype=float32)>, <tf.Variable 'basic_block_11/conv2d_28/bias:0' shape=(128,) dtype=float32, numpy=\n",
      "array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32)>, <tf.Variable 'basic_block_11/batch_normalization_30/gamma:0' shape=(128,) dtype=float32, numpy=\n",
      "array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32)>, <tf.Variable 'basic_block_11/batch_normalization_30/beta:0' shape=(128,) dtype=float32, numpy=\n",
      "array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32)>, <tf.Variable 'basic_block_11/conv2d_29/kernel:0' shape=(3, 3, 128, 128) dtype=float32, numpy=\n",
      "array([[[[ 3.53110507e-02,  3.86901349e-02,  2.86658481e-03, ...,\n",
      "          -2.39902735e-03,  2.65286788e-02,  2.09546834e-02],\n",
      "         [ 9.11523029e-03, -4.71680090e-02, -3.93785089e-02, ...,\n",
      "          -3.13221850e-02, -4.60747667e-02,  1.73299387e-03],\n",
      "         [ 3.77979949e-02,  2.52050757e-02,  3.54647040e-02, ...,\n",
      "           3.12422216e-02, -4.19678837e-02,  3.34440395e-02],\n",
      "         ...,\n",
      "         [-2.18449086e-02,  4.13605832e-02, -4.87025306e-02, ...,\n",
      "          -3.57349440e-02, -2.96436604e-02, -1.86702386e-02],\n",
      "         [ 4.73300256e-02, -1.80986337e-02,  1.63086280e-02, ...,\n",
      "          -1.42038241e-03,  1.61431581e-02,  3.64640951e-02],\n",
      "         [-4.10237052e-02,  1.69813633e-03,  5.01463711e-02, ...,\n",
      "           4.90111783e-02,  2.04998124e-02,  1.87200643e-02]],\n",
      "\n",
      "        [[-2.02556998e-02,  9.42029804e-03,  8.62916932e-03, ...,\n",
      "           3.98808494e-02,  1.39719546e-02, -2.75349673e-02],\n",
      "         [-3.19039971e-02,  4.94614616e-03, -2.47290246e-02, ...,\n",
      "           1.52806714e-02,  4.36966047e-02, -1.98556334e-02],\n",
      "         [ 1.34432614e-02, -1.83049701e-02,  2.05234811e-03, ...,\n",
      "           4.82133031e-03, -2.32680291e-02,  3.49931344e-02],\n",
      "         ...,\n",
      "         [-2.35894620e-02,  4.52047363e-02, -4.50952277e-02, ...,\n",
      "          -3.08617335e-02, -2.00191662e-02,  1.97040141e-02],\n",
      "         [ 4.29017842e-03,  6.55847415e-03, -2.58493870e-02, ...,\n",
      "           2.84304991e-02,  2.96323448e-02,  1.76012963e-02],\n",
      "         [-1.34466514e-02,  3.63357030e-02,  1.87083483e-02, ...,\n",
      "          -1.57667920e-02,  5.04373983e-02,  4.77295667e-02]],\n",
      "\n",
      "        [[ 2.09630504e-02, -1.93388872e-02,  3.64795104e-02, ...,\n",
      "           1.10142753e-02, -1.56091228e-02, -4.45185751e-02],\n",
      "         [ 1.88437253e-02, -3.77952717e-02,  1.54530555e-02, ...,\n",
      "           1.60075724e-02, -4.34539020e-02,  2.28505507e-02],\n",
      "         [-4.25474197e-02, -3.85730192e-02, -3.13638076e-02, ...,\n",
      "           5.27378544e-03, -3.09193581e-02,  8.67664441e-03],\n",
      "         ...,\n",
      "         [-5.11742011e-03, -3.60955037e-02, -1.32913701e-02, ...,\n",
      "          -4.80148941e-04,  3.87955084e-03, -1.67324282e-02],\n",
      "         [-4.62219603e-02, -3.64684165e-02,  7.31249526e-03, ...,\n",
      "           3.64855304e-02,  5.01277074e-02,  4.42582332e-02],\n",
      "         [-1.34279393e-02,  2.54361033e-02, -1.00305825e-02, ...,\n",
      "           4.01277691e-02,  1.71079412e-02, -1.48892514e-02]]],\n",
      "\n",
      "\n",
      "       [[[ 2.89169922e-02, -4.47325557e-02,  8.00472125e-03, ...,\n",
      "           3.77279148e-02, -5.06554022e-02, -5.03786653e-02],\n",
      "         [-5.24410978e-03,  4.76318300e-02, -1.59318708e-02, ...,\n",
      "          -2.97377463e-02, -2.63498276e-02, -1.45189799e-02],\n",
      "         [ 2.89921090e-02, -4.60830033e-02,  1.84295550e-02, ...,\n",
      "           2.88502797e-02, -1.71252117e-02,  2.57045403e-02],\n",
      "         ...,\n",
      "         [ 4.56200093e-02,  1.65257230e-03,  4.84992117e-02, ...,\n",
      "          -3.99546996e-02, -2.24989932e-02, -7.88605958e-03],\n",
      "         [ 4.34317440e-03,  3.95538658e-03, -4.61843051e-02, ...,\n",
      "          -4.88853604e-02,  1.47375464e-02,  1.32173821e-02],\n",
      "         [-4.61161956e-02, -4.97521050e-02,  2.34133601e-02, ...,\n",
      "          -4.31489199e-02, -3.16133946e-02,  2.96645630e-02]],\n",
      "\n",
      "        [[ 4.50929478e-02,  1.17507055e-02, -8.68123025e-04, ...,\n",
      "          -4.36164886e-02,  1.50540024e-02, -1.41297430e-02],\n",
      "         [-2.19562724e-02,  4.04188260e-02,  3.99339199e-02, ...,\n",
      "          -9.11266357e-03, -1.62352100e-02, -3.06617375e-02],\n",
      "         [-1.88978799e-02,  1.47955939e-02,  9.39854607e-03, ...,\n",
      "           4.26163599e-02,  2.55035460e-02, -3.14816311e-02],\n",
      "         ...,\n",
      "         [ 4.79463488e-03,  2.93082260e-02, -1.95911378e-02, ...,\n",
      "          -8.72239470e-05, -5.22266328e-03, -1.62169598e-02],\n",
      "         [ 6.43029809e-03,  2.05391645e-03,  2.96160430e-02, ...,\n",
      "           4.23059016e-02,  2.93226391e-02,  1.67368725e-02],\n",
      "         [ 4.85160127e-02,  1.34767890e-02,  4.62785587e-02, ...,\n",
      "           3.70952189e-02, -1.51447915e-02, -2.24494636e-02]],\n",
      "\n",
      "        [[ 4.71087322e-02, -4.92318571e-02,  3.19824740e-02, ...,\n",
      "          -4.84572873e-02, -4.55762818e-02,  5.06691970e-02],\n",
      "         [-4.89534438e-02,  3.01715285e-02, -1.20882727e-02, ...,\n",
      "           1.44539028e-02,  2.80670598e-02,  3.97055149e-02],\n",
      "         [ 3.39876115e-02,  2.45241150e-02, -1.77815557e-04, ...,\n",
      "          -4.50212955e-02,  3.60930189e-02,  1.58550218e-02],\n",
      "         ...,\n",
      "         [ 2.33754739e-02, -1.51566043e-02,  4.23926115e-02, ...,\n",
      "           2.54043862e-02, -2.59521566e-02,  4.56107780e-02],\n",
      "         [ 3.41678634e-02, -3.02294530e-02, -5.04689813e-02, ...,\n",
      "          -1.35660321e-02,  1.33088380e-02,  1.27522126e-02],\n",
      "         [ 2.38262117e-02, -1.21331178e-02,  3.30679193e-02, ...,\n",
      "          -3.41024101e-02,  2.95300931e-02, -9.41920280e-03]]],\n",
      "\n",
      "\n",
      "       [[[ 3.98349315e-02, -3.09757851e-02,  9.53899696e-03, ...,\n",
      "          -4.21885401e-02, -2.96879113e-02,  3.26364487e-03],\n",
      "         [ 4.59761918e-03,  3.31253447e-02, -1.85946599e-02, ...,\n",
      "           9.86854732e-03, -1.46545321e-02, -1.63550302e-02],\n",
      "         [-1.35393403e-02,  1.07082836e-02, -2.94971839e-03, ...,\n",
      "           1.72927827e-02, -1.55441761e-02,  1.02390125e-02],\n",
      "         ...,\n",
      "         [-2.66279951e-02,  3.01365852e-02,  3.72072905e-02, ...,\n",
      "           3.11958939e-02, -2.43112780e-02, -4.89857234e-02],\n",
      "         [ 2.82810479e-02,  4.57351953e-02,  2.60085762e-02, ...,\n",
      "           1.30871534e-02,  4.58645225e-02, -2.68114209e-02],\n",
      "         [ 2.05936283e-02,  2.33477056e-02,  4.69254926e-02, ...,\n",
      "           1.66873261e-02,  3.92841771e-02,  5.08412719e-02]],\n",
      "\n",
      "        [[-2.70563290e-02,  2.23842897e-02,  1.68329477e-02, ...,\n",
      "          -1.81680322e-02,  9.87591967e-03, -7.44828954e-03],\n",
      "         [-4.67225723e-02, -1.72432996e-02,  4.57925126e-02, ...,\n",
      "           3.25176269e-02,  2.09338516e-02,  4.25090268e-03],\n",
      "         [ 3.47279161e-02,  1.37061551e-02, -3.87942828e-02, ...,\n",
      "           1.74344704e-03,  4.10110652e-02, -1.79272592e-02],\n",
      "         ...,\n",
      "         [ 4.42594066e-02,  1.09237544e-02,  1.76107734e-02, ...,\n",
      "          -3.32506523e-02, -4.09088396e-02,  2.18813494e-02],\n",
      "         [ 5.83816692e-03,  4.78018373e-02,  1.25013068e-02, ...,\n",
      "           2.22669877e-02, -4.23019454e-02,  6.80809841e-03],\n",
      "         [ 1.42402798e-02, -2.98163909e-02, -3.96282673e-02, ...,\n",
      "          -4.51284386e-02,  3.08402628e-03,  4.34195325e-02]],\n",
      "\n",
      "        [[-2.00307369e-03, -1.76356137e-02,  3.22133973e-02, ...,\n",
      "          -2.74664685e-02, -3.95561755e-02,  3.55522111e-02],\n",
      "         [-3.77787128e-02, -2.53407918e-02,  4.94313799e-02, ...,\n",
      "          -1.95602775e-02,  4.96495068e-02,  3.30401510e-02],\n",
      "         [-1.58879943e-02, -5.51432371e-04,  2.21021101e-02, ...,\n",
      "          -4.20245305e-02,  4.60847691e-02,  4.50351872e-02],\n",
      "         ...,\n",
      "         [ 2.78857350e-02, -2.34136134e-02,  2.70981416e-02, ...,\n",
      "          -2.30721459e-02,  2.53449380e-02,  1.64227635e-02],\n",
      "         [ 3.07287723e-02,  7.09217787e-03, -6.02545962e-03, ...,\n",
      "          -2.89401934e-02, -4.60468568e-02, -2.74681970e-02],\n",
      "         [-4.36167084e-02, -3.90006900e-02,  5.01295701e-02, ...,\n",
      "          -5.10029495e-05,  4.64921445e-02, -3.24069224e-02]]]],\n",
      "      dtype=float32)>, <tf.Variable 'basic_block_11/conv2d_29/bias:0' shape=(128,) dtype=float32, numpy=\n",
      "array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32)>, <tf.Variable 'basic_block_11/batch_normalization_31/gamma:0' shape=(128,) dtype=float32, numpy=\n",
      "array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32)>, <tf.Variable 'basic_block_11/batch_normalization_31/beta:0' shape=(128,) dtype=float32, numpy=\n",
      "array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32)>, <tf.Variable 'basic_block_11/batch_normalization_30/moving_mean:0' shape=(128,) dtype=float32, numpy=\n",
      "array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32)>, <tf.Variable 'basic_block_11/batch_normalization_30/moving_variance:0' shape=(128,) dtype=float32, numpy=\n",
      "array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32)>, <tf.Variable 'basic_block_11/batch_normalization_31/moving_mean:0' shape=(128,) dtype=float32, numpy=\n",
      "array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32)>, <tf.Variable 'basic_block_11/batch_normalization_31/moving_variance:0' shape=(128,) dtype=float32, numpy=\n",
      "array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32)>, <tf.Variable 'basic_block_12/conv2d_30/kernel:0' shape=(3, 3, 128, 256) dtype=float32, numpy=\n",
      "array([[[[-1.79297924e-02,  3.23982872e-02,  3.75593193e-02, ...,\n",
      "           1.20181739e-02,  1.27442665e-02, -3.50643098e-02],\n",
      "         [ 4.80833650e-03, -9.59092379e-03,  3.09685655e-02, ...,\n",
      "          -4.11051176e-02, -3.40647101e-02, -1.32139530e-02],\n",
      "         [-3.20636146e-02, -2.15334892e-02, -3.44471559e-02, ...,\n",
      "           2.37674508e-02,  7.79873133e-03, -7.40564987e-03],\n",
      "         ...,\n",
      "         [-1.28847361e-02,  2.69478448e-02,  2.67046429e-02, ...,\n",
      "           4.29177284e-03, -3.03463265e-02,  2.84290314e-03],\n",
      "         [-1.90183818e-02, -3.00519876e-02, -6.73319027e-03, ...,\n",
      "          -2.15132646e-02, -6.58347085e-03,  1.29615068e-02],\n",
      "         [ 4.03680392e-02, -2.29826570e-03, -2.35679857e-02, ...,\n",
      "          -1.57626346e-03,  3.69511880e-02,  3.62348370e-02]],\n",
      "\n",
      "        [[ 1.83065347e-02, -2.24160850e-02,  3.39649506e-02, ...,\n",
      "          -3.30338888e-02,  1.67318769e-02,  1.18024535e-02],\n",
      "         [ 1.35223381e-02,  1.28514282e-02,  3.74842435e-04, ...,\n",
      "          -1.23191383e-02, -1.46759562e-02, -2.69349627e-02],\n",
      "         [-1.55302286e-02,  1.32083893e-02, -3.75314653e-02, ...,\n",
      "           2.12910362e-02,  4.09635901e-02,  3.22268717e-02],\n",
      "         ...,\n",
      "         [-3.51761281e-02, -1.19912438e-02,  3.95763069e-02, ...,\n",
      "          -7.78162479e-03, -2.86677480e-02,  3.40606980e-02],\n",
      "         [ 9.00857523e-03, -3.56896631e-02,  3.77445035e-02, ...,\n",
      "           1.33427680e-02,  3.56682278e-02,  3.27594355e-02],\n",
      "         [-2.49665789e-02, -3.09694521e-02,  4.22655419e-03, ...,\n",
      "           2.22497620e-02,  3.83375399e-02,  1.17662549e-02]],\n",
      "\n",
      "        [[-7.01485202e-03, -1.33642163e-02, -2.75672264e-02, ...,\n",
      "           3.48871686e-02, -2.96261422e-02,  2.10005790e-04],\n",
      "         [ 3.90490368e-02, -2.08873302e-04,  3.65664475e-02, ...,\n",
      "          -1.48031320e-02,  3.17512043e-02, -1.17046647e-02],\n",
      "         [ 3.32613103e-02,  2.23226584e-02,  1.73764341e-02, ...,\n",
      "          -3.75771634e-02,  1.24979801e-02,  6.67596981e-03],\n",
      "         ...,\n",
      "         [ 6.92578033e-03,  2.56802924e-02, -2.45035198e-02, ...,\n",
      "          -1.51489973e-02, -2.17398889e-02, -1.85364783e-02],\n",
      "         [ 4.05799262e-02, -3.02835815e-02, -1.54551677e-02, ...,\n",
      "           1.24748759e-02,  5.41648269e-03,  3.97280864e-02],\n",
      "         [ 1.41416602e-02, -1.05362050e-02, -2.38551497e-02, ...,\n",
      "          -2.09803693e-02, -4.52477857e-03, -2.63060741e-02]]],\n",
      "\n",
      "\n",
      "       [[[-3.66177373e-02,  3.27241607e-02, -4.01698574e-02, ...,\n",
      "           3.83467264e-02,  3.50249521e-02, -1.56961754e-03],\n",
      "         [-3.99534591e-02,  1.02454014e-02,  2.22064443e-02, ...,\n",
      "           4.11100425e-02,  1.98784359e-02, -9.25211236e-03],\n",
      "         [ 1.13027804e-02,  4.78053093e-03,  6.62752986e-03, ...,\n",
      "           1.99613087e-02, -4.33583930e-03,  1.59110241e-02],\n",
      "         ...,\n",
      "         [ 1.21975951e-02,  2.02619620e-02,  3.30456682e-02, ...,\n",
      "           4.07405086e-02, -3.33938636e-02, -2.17421651e-02],\n",
      "         [ 2.64661647e-02, -3.27780657e-02,  1.60799734e-02, ...,\n",
      "           2.08234787e-03,  3.71212102e-02, -2.20941305e-02],\n",
      "         [-2.52657346e-02, -7.50957802e-03,  3.88555117e-02, ...,\n",
      "           2.85537317e-02,  9.93469357e-03, -3.28599289e-03]],\n",
      "\n",
      "        [[ 1.94351748e-03, -2.00011209e-03, -1.08235776e-02, ...,\n",
      "          -2.99000926e-02,  1.03107691e-02, -3.91942486e-02],\n",
      "         [ 4.04496863e-03,  1.98134668e-02,  1.76917911e-02, ...,\n",
      "          -2.00083852e-02, -2.19700634e-02, -3.59958336e-02],\n",
      "         [-3.41765881e-02,  2.38570571e-03,  4.08631004e-02, ...,\n",
      "          -1.59094539e-02,  3.27139385e-02, -1.57989264e-02],\n",
      "         ...,\n",
      "         [-3.61490957e-02,  5.63381240e-03, -8.43622163e-03, ...,\n",
      "          -1.47095621e-02, -2.17912793e-02, -1.34803280e-02],\n",
      "         [-1.88388433e-02, -1.31443739e-02, -2.18392517e-02, ...,\n",
      "          -4.10627201e-03, -3.18559818e-02,  1.58393495e-02],\n",
      "         [-1.59812868e-02,  1.89053826e-02, -3.47526297e-02, ...,\n",
      "          -3.84334028e-02,  2.61900164e-02,  3.07781287e-02]],\n",
      "\n",
      "        [[-1.99126489e-02, -1.52420811e-02,  3.82562354e-03, ...,\n",
      "           3.67831774e-02, -3.37617323e-02, -3.71488929e-03],\n",
      "         [-1.76804177e-02,  3.24335806e-02,  1.26583502e-03, ...,\n",
      "          -2.35709250e-02,  1.30610578e-02,  6.44475222e-07],\n",
      "         [-3.05577107e-02, -1.12729874e-02,  2.51228921e-02, ...,\n",
      "           2.96285748e-03,  9.31045413e-03, -3.37179899e-02],\n",
      "         ...,\n",
      "         [-5.59698790e-04, -2.06983387e-02, -1.74180157e-02, ...,\n",
      "           1.90235265e-02, -3.83536331e-02, -1.71853714e-02],\n",
      "         [-2.78766640e-02,  3.78784537e-03, -1.59402564e-03, ...,\n",
      "           2.05847919e-02, -2.60181241e-02, -4.06632088e-02],\n",
      "         [ 8.07911158e-03, -1.53162293e-02,  2.16710605e-02, ...,\n",
      "           5.97034767e-03,  2.09052898e-02, -3.83232348e-02]]],\n",
      "\n",
      "\n",
      "       [[[ 8.78655910e-03, -1.79764144e-02, -3.29788439e-02, ...,\n",
      "          -2.74240188e-02,  3.41328122e-02,  2.10356712e-03],\n",
      "         [-2.55188458e-02,  5.26657701e-03,  1.33097954e-02, ...,\n",
      "           3.80193703e-02,  2.71611400e-02, -3.34692225e-02],\n",
      "         [ 4.79901955e-03, -3.51032838e-02,  1.10590160e-02, ...,\n",
      "           4.84764576e-04, -2.60098875e-02, -9.04703140e-03],\n",
      "         ...,\n",
      "         [ 1.25240870e-02, -1.90984011e-02,  3.05588283e-02, ...,\n",
      "           2.00447142e-02, -6.04118034e-03,  1.00678690e-02],\n",
      "         [-4.01504152e-02,  2.81073861e-02, -3.87947857e-02, ...,\n",
      "           3.07847373e-02, -4.82369214e-04, -3.06480527e-02],\n",
      "         [ 2.55648904e-02,  1.37137063e-02, -1.21170282e-03, ...,\n",
      "           1.67461932e-02, -1.86766684e-02,  1.11920349e-02]],\n",
      "\n",
      "        [[-9.22247767e-03,  3.15556712e-02,  9.51237604e-03, ...,\n",
      "          -7.49515370e-03,  2.63441373e-02,  2.95888595e-02],\n",
      "         [-1.36243217e-02, -3.53855118e-02,  1.02058463e-02, ...,\n",
      "           3.53750698e-02, -2.82421913e-02,  2.61317529e-02],\n",
      "         [ 8.91305879e-03, -2.66274810e-03, -3.18897329e-02, ...,\n",
      "           2.05003209e-02,  3.21650617e-02,  3.59286703e-02],\n",
      "         ...,\n",
      "         [-4.10364531e-02,  2.13686712e-02,  1.44347847e-02, ...,\n",
      "           1.95822231e-02,  1.22396648e-02, -7.80867413e-03],\n",
      "         [ 8.36579874e-03, -3.43276933e-03, -1.42676830e-02, ...,\n",
      "          -1.53725557e-02, -1.52977817e-02, -4.06372361e-02],\n",
      "         [ 7.28875399e-04, -4.35829163e-04, -9.81271267e-03, ...,\n",
      "           1.87253542e-02, -3.15399729e-02, -3.90386581e-02]],\n",
      "\n",
      "        [[ 4.02800627e-02, -4.10457253e-02,  3.16788368e-02, ...,\n",
      "           3.64680402e-02, -2.32372191e-02,  3.40217464e-02],\n",
      "         [ 6.74472377e-03,  5.25395200e-03, -3.86766121e-02, ...,\n",
      "          -1.51604898e-02, -1.94998793e-02,  1.95784681e-02],\n",
      "         [-2.05752365e-02, -2.25177705e-02,  5.40565699e-04, ...,\n",
      "           1.99238472e-02, -1.66944265e-02, -3.51111107e-02],\n",
      "         ...,\n",
      "         [ 2.58776434e-02,  9.79261473e-03, -1.36487186e-02, ...,\n",
      "          -2.30155885e-02, -3.56593058e-02,  3.15645635e-02],\n",
      "         [ 3.98811214e-02,  1.43132992e-02,  1.29517615e-02, ...,\n",
      "           2.81723626e-02, -9.96679068e-03, -3.09654977e-02],\n",
      "         [-2.96466053e-02,  1.86377876e-02,  2.41734572e-02, ...,\n",
      "           2.39971317e-02, -2.42580678e-02,  9.83107090e-03]]]],\n",
      "      dtype=float32)>, <tf.Variable 'basic_block_12/conv2d_30/bias:0' shape=(256,) dtype=float32, numpy=\n",
      "array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0.], dtype=float32)>, <tf.Variable 'basic_block_12/batch_normalization_32/gamma:0' shape=(256,) dtype=float32, numpy=\n",
      "array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1.], dtype=float32)>, <tf.Variable 'basic_block_12/batch_normalization_32/beta:0' shape=(256,) dtype=float32, numpy=\n",
      "array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0.], dtype=float32)>, <tf.Variable 'basic_block_12/conv2d_31/kernel:0' shape=(3, 3, 256, 256) dtype=float32, numpy=\n",
      "array([[[[ 0.01326066,  0.01097598, -0.01113579, ...,  0.01538663,\n",
      "          -0.02769392, -0.03424105],\n",
      "         [ 0.03572837,  0.01746584, -0.02827378, ..., -0.0167403 ,\n",
      "           0.00895209, -0.02159664],\n",
      "         [ 0.00212499, -0.01308511, -0.02144978, ...,  0.00388285,\n",
      "           0.02799322, -0.01479064],\n",
      "         ...,\n",
      "         [-0.02057844,  0.02899751,  0.01424242, ...,  0.03419743,\n",
      "           0.0205022 , -0.00308901],\n",
      "         [ 0.01439686, -0.00089433, -0.00095328, ...,  0.00481095,\n",
      "          -0.00781607,  0.03550719],\n",
      "         [ 0.03469992, -0.02101058, -0.00810983, ..., -0.00712864,\n",
      "           0.00260441,  0.02363342]],\n",
      "\n",
      "        [[-0.03424674,  0.03112388, -0.00899082, ...,  0.02305905,\n",
      "           0.01662215,  0.00375327],\n",
      "         [-0.03388552, -0.01072973,  0.00965018, ..., -0.01725432,\n",
      "          -0.01511615,  0.0077028 ],\n",
      "         [-0.00992897,  0.01712554, -0.00022077, ..., -0.00054731,\n",
      "          -0.00037046, -0.00754467],\n",
      "         ...,\n",
      "         [-0.00253308,  0.00762993,  0.00761817, ...,  0.00398828,\n",
      "           0.02709023, -0.02441859],\n",
      "         [-0.02836962, -0.01248225,  0.02562952, ...,  0.01154672,\n",
      "          -0.02423707, -0.01288828],\n",
      "         [-0.01603924,  0.01953248, -0.02833368, ..., -0.01808862,\n",
      "          -0.0183759 , -0.01425944]],\n",
      "\n",
      "        [[ 0.00705539,  0.01625025,  0.00169533, ...,  0.00930905,\n",
      "           0.01144799,  0.03548329],\n",
      "         [-0.00707567, -0.00744535, -0.03558401, ..., -0.02723512,\n",
      "          -0.00318643, -0.01893061],\n",
      "         [-0.02330909, -0.03200103, -0.01005072, ...,  0.00117286,\n",
      "          -0.02349554, -0.03050705],\n",
      "         ...,\n",
      "         [-0.02107537, -0.00583927, -0.00180832, ..., -0.03422419,\n",
      "           0.0053198 ,  0.00798044],\n",
      "         [ 0.01498529,  0.01365736, -0.02078235, ...,  0.02987553,\n",
      "          -0.01405916, -0.00620689],\n",
      "         [-0.00964999,  0.02472959,  0.03148638, ...,  0.01626915,\n",
      "           0.00955082,  0.00103566]]],\n",
      "\n",
      "\n",
      "       [[[ 0.0261683 , -0.00015425,  0.01347788, ..., -0.01492031,\n",
      "          -0.02483825,  0.03185894],\n",
      "         [-0.01616035,  0.01544685, -0.02806906, ..., -0.02983717,\n",
      "          -0.0337485 , -0.01212662],\n",
      "         [ 0.01822855,  0.03169011, -0.03158687, ..., -0.00909344,\n",
      "          -0.01085852, -0.02297612],\n",
      "         ...,\n",
      "         [ 0.01456411,  0.02289808, -0.00873808, ..., -0.01102235,\n",
      "          -0.00712668,  0.02671061],\n",
      "         [ 0.00928401,  0.02567258, -0.01664438, ..., -0.03121413,\n",
      "           0.03077943, -0.02610152],\n",
      "         [-0.0216597 ,  0.02708616,  0.0309992 , ...,  0.02467805,\n",
      "          -0.00198327,  0.02688657]],\n",
      "\n",
      "        [[ 0.00212876,  0.00012205, -0.03352474, ..., -0.02095529,\n",
      "           0.00056513,  0.00692536],\n",
      "         [-0.00192373, -0.02929365, -0.03475301, ...,  0.03160781,\n",
      "           0.01679612, -0.01366526],\n",
      "         [ 0.03201867,  0.00382708, -0.01611277, ...,  0.00453444,\n",
      "          -0.00900946,  0.0186255 ],\n",
      "         ...,\n",
      "         [-0.00686337,  0.03131101, -0.01764867, ..., -0.03268241,\n",
      "          -0.02878403,  0.02251991],\n",
      "         [-0.02364648,  0.03557488, -0.0348442 , ..., -0.0099919 ,\n",
      "           0.02306955, -0.03250467],\n",
      "         [ 0.01788169,  0.02757673,  0.00300968, ...,  0.00293206,\n",
      "           0.00851814,  0.00204479]],\n",
      "\n",
      "        [[ 0.01639697,  0.00509368,  0.02259585, ...,  0.00489213,\n",
      "          -0.00802806, -0.00179518],\n",
      "         [ 0.03193009, -0.01937271,  0.00578782, ..., -0.02112907,\n",
      "           0.01614539, -0.01758048],\n",
      "         [-0.02954048, -0.03177197, -0.00061463, ..., -0.02675535,\n",
      "          -0.00934067, -0.0169431 ],\n",
      "         ...,\n",
      "         [-0.0197247 , -0.0018267 , -0.00732093, ..., -0.03373504,\n",
      "           0.0256348 ,  0.03351022],\n",
      "         [-0.02030684,  0.01073601, -0.03119654, ...,  0.02503547,\n",
      "           0.03184699,  0.02677837],\n",
      "         [-0.03327906,  0.01116311,  0.02270209, ...,  0.00112772,\n",
      "          -0.01347733, -0.03252656]]],\n",
      "\n",
      "\n",
      "       [[[-0.02426179,  0.0143093 ,  0.00335406, ..., -0.01397975,\n",
      "          -0.01177336, -0.01441435],\n",
      "         [ 0.0276048 ,  0.03227661,  0.00233166, ...,  0.02467316,\n",
      "           0.00680868, -0.00188344],\n",
      "         [ 0.03005201,  0.03044371, -0.03104926, ..., -0.01877578,\n",
      "           0.01829942, -0.0056465 ],\n",
      "         ...,\n",
      "         [-0.02793833,  0.01545304, -0.0093691 , ...,  0.00015578,\n",
      "          -0.02680749,  0.00744247],\n",
      "         [ 0.02874617,  0.02593363,  0.00165642, ..., -0.01454458,\n",
      "          -0.02108652,  0.00288034],\n",
      "         [-0.03494561, -0.0290289 , -0.01732946, ..., -0.0143397 ,\n",
      "          -0.03569041, -0.00640514]],\n",
      "\n",
      "        [[ 0.00385974, -0.01543449, -0.01381309, ..., -0.03209478,\n",
      "          -0.03120248,  0.02390465],\n",
      "         [-0.00956955,  0.03116529,  0.00398577, ...,  0.03540875,\n",
      "          -0.03525771, -0.01791396],\n",
      "         [ 0.00629738, -0.01429833, -0.03020648, ..., -0.02515522,\n",
      "           0.02071482,  0.01125071],\n",
      "         ...,\n",
      "         [ 0.01740012, -0.0114838 , -0.00846605, ..., -0.02348116,\n",
      "          -0.01938436,  0.01831555],\n",
      "         [ 0.00983036,  0.01644499, -0.00848408, ..., -0.01337022,\n",
      "           0.03009036, -0.0345794 ],\n",
      "         [ 0.03121464, -0.0045736 ,  0.01807853, ..., -0.03118379,\n",
      "           0.01862079, -0.00683079]],\n",
      "\n",
      "        [[ 0.02159313,  0.01850181, -0.02451656, ..., -0.02808897,\n",
      "           0.0136188 ,  0.02566416],\n",
      "         [-0.02071241, -0.03364921,  0.01750273, ..., -0.00618545,\n",
      "           0.00508654,  0.02426358],\n",
      "         [ 0.03343197,  0.03466411, -0.03577875, ..., -0.01979846,\n",
      "          -0.00149078, -0.01916049],\n",
      "         ...,\n",
      "         [-0.00556314, -0.01327144, -0.02421216, ...,  0.03324579,\n",
      "          -0.03379843, -0.03260176],\n",
      "         [-0.01136986,  0.0307988 ,  0.02276162, ...,  0.02758197,\n",
      "           0.03148728, -0.01148526],\n",
      "         [ 0.01200181,  0.01041172, -0.03500381, ..., -0.02384344,\n",
      "          -0.03591324,  0.01794415]]]], dtype=float32)>, <tf.Variable 'basic_block_12/conv2d_31/bias:0' shape=(256,) dtype=float32, numpy=\n",
      "array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0.], dtype=float32)>, <tf.Variable 'basic_block_12/batch_normalization_33/gamma:0' shape=(256,) dtype=float32, numpy=\n",
      "array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1.], dtype=float32)>, <tf.Variable 'basic_block_12/batch_normalization_33/beta:0' shape=(256,) dtype=float32, numpy=\n",
      "array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0.], dtype=float32)>, <tf.Variable 'conv2d_32/kernel:0' shape=(1, 1, 128, 256) dtype=float32, numpy=\n",
      "array([[[[ 0.12066895, -0.06831008, -0.02603969, ...,  0.0096198 ,\n",
      "          -0.07591298, -0.00823322],\n",
      "         [ 0.09058899, -0.05870292,  0.07013994, ..., -0.0611352 ,\n",
      "          -0.03237468, -0.09788015],\n",
      "         [ 0.08333862, -0.00575349, -0.00335938, ..., -0.04080704,\n",
      "           0.09566164, -0.02900657],\n",
      "         ...,\n",
      "         [-0.03467378, -0.06207955,  0.10588637, ...,  0.02522627,\n",
      "          -0.0335449 , -0.05681908],\n",
      "         [ 0.0672445 , -0.04346955,  0.09053171, ...,  0.05165038,\n",
      "           0.03150767, -0.02490792],\n",
      "         [-0.11044917, -0.06595722, -0.03109342, ...,  0.12349167,\n",
      "          -0.11566722,  0.0272738 ]]]], dtype=float32)>, <tf.Variable 'conv2d_32/bias:0' shape=(256,) dtype=float32, numpy=\n",
      "array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0.], dtype=float32)>, <tf.Variable 'batch_normalization_34/gamma:0' shape=(256,) dtype=float32, numpy=\n",
      "array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1.], dtype=float32)>, <tf.Variable 'batch_normalization_34/beta:0' shape=(256,) dtype=float32, numpy=\n",
      "array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0.], dtype=float32)>, <tf.Variable 'basic_block_12/batch_normalization_32/moving_mean:0' shape=(256,) dtype=float32, numpy=\n",
      "array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0.], dtype=float32)>, <tf.Variable 'basic_block_12/batch_normalization_32/moving_variance:0' shape=(256,) dtype=float32, numpy=\n",
      "array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1.], dtype=float32)>, <tf.Variable 'basic_block_12/batch_normalization_33/moving_mean:0' shape=(256,) dtype=float32, numpy=\n",
      "array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0.], dtype=float32)>, <tf.Variable 'basic_block_12/batch_normalization_33/moving_variance:0' shape=(256,) dtype=float32, numpy=\n",
      "array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1.], dtype=float32)>, <tf.Variable 'batch_normalization_34/moving_mean:0' shape=(256,) dtype=float32, numpy=\n",
      "array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0.], dtype=float32)>, <tf.Variable 'batch_normalization_34/moving_variance:0' shape=(256,) dtype=float32, numpy=\n",
      "array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1.], dtype=float32)>, <tf.Variable 'basic_block_13/conv2d_33/kernel:0' shape=(3, 3, 256, 256) dtype=float32, numpy=\n",
      "array([[[[ 0.01069016,  0.03303237, -0.02148251, ..., -0.03491822,\n",
      "           0.01891766,  0.03082564],\n",
      "         [-0.01026942,  0.01632446, -0.00700308, ..., -0.02441362,\n",
      "           0.01886942,  0.02354242],\n",
      "         [-0.00539235,  0.02856146,  0.0056546 , ..., -0.02036842,\n",
      "          -0.00870703,  0.03216051],\n",
      "         ...,\n",
      "         [-0.03195171, -0.01872759, -0.00537579, ...,  0.02023921,\n",
      "          -0.01507508,  0.02588325],\n",
      "         [-0.00967356, -0.0078299 , -0.0125672 , ...,  0.00527347,\n",
      "           0.01357687, -0.01486601],\n",
      "         [-0.03204067, -0.00436695, -0.01527064, ...,  0.00191253,\n",
      "           0.02286059,  0.00623085]],\n",
      "\n",
      "        [[-0.0108818 , -0.00449328, -0.01169483, ..., -0.01891957,\n",
      "           0.02411033, -0.0084125 ],\n",
      "         [ 0.00610781,  0.02985454, -0.00271781, ..., -0.02217211,\n",
      "          -0.01910993, -0.01327311],\n",
      "         [ 0.01642611,  0.00764899, -0.03437679, ...,  0.0026699 ,\n",
      "          -0.02277844, -0.01119279],\n",
      "         ...,\n",
      "         [ 0.02503282,  0.03134166, -0.02109596, ..., -0.0225854 ,\n",
      "          -0.02703815,  0.01802207],\n",
      "         [ 0.02832357,  0.01786565,  0.00953294, ...,  0.02684012,\n",
      "          -0.03506506,  0.01290239],\n",
      "         [-0.01797421, -0.0227026 , -0.00222013, ...,  0.01971589,\n",
      "           0.01686316, -0.03572774]],\n",
      "\n",
      "        [[ 0.01401886, -0.03036622,  0.00451386, ..., -0.0336057 ,\n",
      "           0.00366493, -0.03548926],\n",
      "         [-0.03071501,  0.03056257, -0.01296426, ..., -0.0075466 ,\n",
      "          -0.01250863,  0.03368491],\n",
      "         [ 0.02989158, -0.00684129,  0.00133379, ...,  0.01840223,\n",
      "           0.0158927 , -0.0176684 ],\n",
      "         ...,\n",
      "         [ 0.00303658,  0.0169487 ,  0.02934635, ..., -0.009335  ,\n",
      "          -0.01354346, -0.0007497 ],\n",
      "         [-0.01400148,  0.00508818,  0.03180409, ...,  0.01962828,\n",
      "          -0.00535609,  0.03400932],\n",
      "         [-0.01653725, -0.03346532, -0.02152741, ..., -0.02185797,\n",
      "          -0.01463014,  0.0323196 ]]],\n",
      "\n",
      "\n",
      "       [[[ 0.0036185 , -0.02058617,  0.01326637, ..., -0.02328971,\n",
      "           0.00976865,  0.00293562],\n",
      "         [-0.01565751, -0.01085582,  0.00615586, ..., -0.01121363,\n",
      "           0.02187015,  0.02198531],\n",
      "         [ 0.02917521, -0.03111858,  0.004165  , ..., -0.02482693,\n",
      "           0.01403325,  0.00658546],\n",
      "         ...,\n",
      "         [ 0.01537208, -0.02586329,  0.02887093, ...,  0.02045162,\n",
      "           0.02360045, -0.0254538 ],\n",
      "         [-0.01128144,  0.00356224,  0.0057961 , ...,  0.01613822,\n",
      "           0.03306206,  0.01463168],\n",
      "         [-0.00508885,  0.02149186, -0.00815086, ...,  0.02286642,\n",
      "           0.0021045 ,  0.00598832]],\n",
      "\n",
      "        [[-0.01892253,  0.03012061, -0.01952107, ...,  0.03207844,\n",
      "           0.0131624 ,  0.01033375],\n",
      "         [ 0.0287885 , -0.00279202,  0.03181838, ..., -0.02439891,\n",
      "           0.00714904,  0.02647565],\n",
      "         [ 0.01812862,  0.03304433, -0.03155167, ...,  0.01816668,\n",
      "           0.00264676, -0.01503178],\n",
      "         ...,\n",
      "         [-0.02823675, -0.00563641, -0.00810204, ..., -0.00784514,\n",
      "          -0.00203236,  0.00748522],\n",
      "         [ 0.01621498,  0.00960178, -0.03398328, ..., -0.01514541,\n",
      "          -0.00754866,  0.02102119],\n",
      "         [ 0.00668826,  0.01210535, -0.01821804, ..., -0.00392178,\n",
      "           0.00104308, -0.01284813]],\n",
      "\n",
      "        [[-0.00348128, -0.02529547,  0.02399549, ...,  0.02388645,\n",
      "          -0.00559553,  0.00972863],\n",
      "         [-0.01274991, -0.0069507 ,  0.0019279 , ..., -0.02146713,\n",
      "          -0.02994936,  0.00526807],\n",
      "         [-0.00526907, -0.01675522,  0.03421778, ..., -0.03090732,\n",
      "           0.00536937, -0.01533423],\n",
      "         ...,\n",
      "         [ 0.020592  , -0.02339845,  0.03304025, ...,  0.00579373,\n",
      "           0.03271171, -0.0279838 ],\n",
      "         [ 0.01377865, -0.00099818, -0.01529749, ..., -0.0256816 ,\n",
      "           0.01974506, -0.00892416],\n",
      "         [-0.00244871, -0.03596815, -0.02681952, ..., -0.02594588,\n",
      "           0.0328104 ,  0.02093541]]],\n",
      "\n",
      "\n",
      "       [[[ 0.00322   , -0.0109629 , -0.02549737, ...,  0.00776541,\n",
      "           0.00495622,  0.01355704],\n",
      "         [-0.00905819,  0.01482371,  0.01589526, ..., -0.03543039,\n",
      "           0.00032061,  0.0132118 ],\n",
      "         [-0.01199349,  0.0115856 , -0.02736103, ...,  0.02904133,\n",
      "          -0.00331355, -0.02610233],\n",
      "         ...,\n",
      "         [-0.00431472,  0.03453137, -0.00900974, ...,  0.0336551 ,\n",
      "          -0.02854965, -0.02218905],\n",
      "         [-0.00241473,  0.0303859 , -0.00912006, ..., -0.02857785,\n",
      "          -0.02872305,  0.02011401],\n",
      "         [-0.03139234,  0.01738748, -0.03587219, ..., -0.01531562,\n",
      "          -0.01145767,  0.02891482]],\n",
      "\n",
      "        [[ 0.01803587,  0.03081453, -0.03084629, ..., -0.03597724,\n",
      "           0.0049472 ,  0.0308025 ],\n",
      "         [ 0.03260832,  0.01937037,  0.02829076, ...,  0.01113309,\n",
      "           0.01639869,  0.01415198],\n",
      "         [ 0.03536779,  0.02173202,  0.00447835, ...,  0.01653299,\n",
      "          -0.02799541,  0.02519313],\n",
      "         ...,\n",
      "         [-0.02475571, -0.00149207, -0.01811197, ..., -0.00820524,\n",
      "          -0.00075299, -0.02446709],\n",
      "         [-0.01542085,  0.0340353 ,  0.0260104 , ..., -0.03469959,\n",
      "          -0.00117707, -0.01211666],\n",
      "         [-0.02263534,  0.01436689,  0.00432728, ..., -0.00437552,\n",
      "           0.03306787, -0.01300247]],\n",
      "\n",
      "        [[-0.01892843,  0.02326592,  0.02027213, ..., -0.02950104,\n",
      "           0.0306334 ,  0.01955979],\n",
      "         [-0.0281079 , -0.03090434, -0.03241143, ..., -0.02141489,\n",
      "          -0.00244666,  0.02067105],\n",
      "         [-0.00421239, -0.01455729,  0.00323619, ..., -0.00896227,\n",
      "          -0.01982598,  0.03283667],\n",
      "         ...,\n",
      "         [ 0.02829438, -0.00871611,  0.00695512, ..., -0.01892733,\n",
      "          -0.01776233, -0.00707658],\n",
      "         [ 0.00409292, -0.0256527 ,  0.02285977, ...,  0.00915202,\n",
      "           0.00641031,  0.00143017],\n",
      "         [-0.01273876,  0.01171464,  0.01680071, ..., -0.02267233,\n",
      "           0.02340866,  0.02045017]]]], dtype=float32)>, <tf.Variable 'basic_block_13/conv2d_33/bias:0' shape=(256,) dtype=float32, numpy=\n",
      "array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0.], dtype=float32)>, <tf.Variable 'basic_block_13/batch_normalization_35/gamma:0' shape=(256,) dtype=float32, numpy=\n",
      "array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1.], dtype=float32)>, <tf.Variable 'basic_block_13/batch_normalization_35/beta:0' shape=(256,) dtype=float32, numpy=\n",
      "array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0.], dtype=float32)>, <tf.Variable 'basic_block_13/conv2d_34/kernel:0' shape=(3, 3, 256, 256) dtype=float32, numpy=\n",
      "array([[[[ 0.02168908, -0.03471548, -0.00740106, ..., -0.01779934,\n",
      "           0.01252352, -0.0033284 ],\n",
      "         [ 0.00069322,  0.0024136 , -0.01150901, ..., -0.01461496,\n",
      "          -0.00171455,  0.02656145],\n",
      "         [ 0.00941888, -0.03337662, -0.01148978, ...,  0.01301957,\n",
      "          -0.0304491 , -0.00928245],\n",
      "         ...,\n",
      "         [-0.01664941, -0.00093875, -0.00734212, ..., -0.01926537,\n",
      "           0.02366831, -0.02391103],\n",
      "         [ 0.00664295, -0.03027128, -0.0290427 , ...,  0.03190217,\n",
      "           0.02723788,  0.00733107],\n",
      "         [ 0.01790153, -0.0268423 ,  0.03280077, ..., -0.01389844,\n",
      "           0.00108229,  0.02019511]],\n",
      "\n",
      "        [[ 0.01265159, -0.01542285,  0.03082854, ...,  0.00492607,\n",
      "           0.00142376,  0.0207253 ],\n",
      "         [-0.0063498 ,  0.00569696, -0.01746102, ...,  0.0220794 ,\n",
      "           0.02815419, -0.01130527],\n",
      "         [ 0.02354901, -0.00263156,  0.03487401, ..., -0.00982814,\n",
      "           0.01350125, -0.0063092 ],\n",
      "         ...,\n",
      "         [-0.00555789,  0.00180778,  0.00191574, ...,  0.02910715,\n",
      "          -0.0016356 ,  0.03515916],\n",
      "         [-0.01617935,  0.02145309,  0.00556841, ..., -0.00930132,\n",
      "          -0.01897799, -0.00244475],\n",
      "         [-0.00795638,  0.01442499, -0.00499676, ..., -0.0304807 ,\n",
      "          -0.00429738, -0.00401032]],\n",
      "\n",
      "        [[ 0.03233476,  0.00204535, -0.01500583, ..., -0.02737718,\n",
      "          -0.03446979, -0.0032929 ],\n",
      "         [ 0.00207572, -0.0133876 , -0.03239546, ...,  0.00064146,\n",
      "           0.02047741, -0.0057721 ],\n",
      "         [ 0.02475649, -0.02517806, -0.00348016, ..., -0.0301709 ,\n",
      "           0.00571913, -0.00597411],\n",
      "         ...,\n",
      "         [ 0.02030605, -0.01095131,  0.02853848, ...,  0.02414856,\n",
      "           0.00547444,  0.00029657],\n",
      "         [ 0.01654835, -0.02082524,  0.02683728, ...,  0.02612984,\n",
      "           0.02830084, -0.03100313],\n",
      "         [ 0.02092412,  0.00561853, -0.03377507, ..., -0.01705225,\n",
      "           0.01142246,  0.02111049]]],\n",
      "\n",
      "\n",
      "       [[[-0.00991776, -0.02588202,  0.03224804, ...,  0.03164346,\n",
      "          -0.0161649 , -0.01654513],\n",
      "         [ 0.00124619,  0.00181351,  0.01189646, ..., -0.00104924,\n",
      "          -0.01819342, -0.00675597],\n",
      "         [-0.00853566, -0.01682364, -0.02153879, ..., -0.01119983,\n",
      "          -0.01153539,  0.02258821],\n",
      "         ...,\n",
      "         [ 0.02490573, -0.02304355, -0.03490392, ...,  0.00035173,\n",
      "           0.01992768, -0.02970199],\n",
      "         [ 0.01242472,  0.03537439, -0.0325846 , ..., -0.02181777,\n",
      "           0.01013396, -0.0004912 ],\n",
      "         [ 0.02131265, -0.02907249, -0.01697629, ..., -0.01019731,\n",
      "           0.00455206, -0.01448105]],\n",
      "\n",
      "        [[-0.02227076, -0.0037731 ,  0.00604223, ..., -0.00016288,\n",
      "           0.00899447,  0.01938009],\n",
      "         [ 0.00035097,  0.02393282,  0.00536315, ..., -0.01114911,\n",
      "          -0.00116474,  0.01945294],\n",
      "         [-0.02960426,  0.00559292, -0.02471836, ..., -0.01806061,\n",
      "          -0.03400948,  0.01345197],\n",
      "         ...,\n",
      "         [-0.00159786, -0.01107778,  0.006973  , ...,  0.00362946,\n",
      "           0.03588849, -0.01585872],\n",
      "         [-0.00994047, -0.00882812,  0.02502535, ...,  0.0274444 ,\n",
      "          -0.03556189,  0.03529432],\n",
      "         [ 0.0166612 , -0.01415852,  0.00416852, ..., -0.02082402,\n",
      "          -0.00021383, -0.00624904]],\n",
      "\n",
      "        [[-0.02565015,  0.02950304, -0.01551859, ..., -0.02904512,\n",
      "          -0.01881772, -0.00803995],\n",
      "         [-0.00882417,  0.0090436 , -0.0138667 , ..., -0.00724472,\n",
      "           0.01793178,  0.01184253],\n",
      "         [-0.03010297,  0.01409943, -0.02199098, ..., -0.00926918,\n",
      "          -0.03406908, -0.03215044],\n",
      "         ...,\n",
      "         [ 0.02717982, -0.02669516, -0.00078994, ..., -0.01279233,\n",
      "           0.02187118,  0.01300092],\n",
      "         [-0.01952851, -0.03136069, -0.01739905, ...,  0.01881209,\n",
      "           0.01658558,  0.02911609],\n",
      "         [-0.00972875,  0.01348327,  0.03101707, ...,  0.00244934,\n",
      "           0.02624918, -0.00075973]]],\n",
      "\n",
      "\n",
      "       [[[-0.01104749, -0.01826021,  0.0271846 , ...,  0.01493021,\n",
      "          -0.02562912,  0.03044166],\n",
      "         [ 0.02538986, -0.0219915 ,  0.00530581, ...,  0.0221375 ,\n",
      "          -0.01834247, -0.0258498 ],\n",
      "         [ 0.01782137, -0.00018121, -0.0280453 , ..., -0.01485071,\n",
      "          -0.00372047, -0.02724052],\n",
      "         ...,\n",
      "         [ 0.00974512, -0.03135838, -0.03286891, ...,  0.01892213,\n",
      "           0.03237226, -0.02057206],\n",
      "         [-0.02432743, -0.01292516,  0.01359901, ..., -0.01083177,\n",
      "           0.02570586, -0.02508   ],\n",
      "         [-0.03576634,  0.00085599,  0.03551831, ..., -0.0136524 ,\n",
      "          -0.00060506,  0.00532468]],\n",
      "\n",
      "        [[ 0.02348777, -0.03373735, -0.02437137, ..., -0.01865935,\n",
      "           0.00176633, -0.02741822],\n",
      "         [ 0.02374963, -0.01097868, -0.02284429, ...,  0.01671558,\n",
      "          -0.0214506 , -0.02751802],\n",
      "         [-0.02863674, -0.02887548, -0.00214276, ...,  0.025942  ,\n",
      "           0.01649768,  0.02727375],\n",
      "         ...,\n",
      "         [-0.00079029, -0.03217249, -0.00979733, ...,  0.02318704,\n",
      "          -0.03422681,  0.02480012],\n",
      "         [ 0.00678601,  0.01187813,  0.03122664, ..., -0.01843164,\n",
      "          -0.01751631, -0.01597143],\n",
      "         [-0.00678987,  0.01807815,  0.01027919, ...,  0.00904151,\n",
      "           0.02485701,  0.02008709]],\n",
      "\n",
      "        [[ 0.00408075,  0.0279442 ,  0.01755857, ...,  0.00305991,\n",
      "           0.02042642, -0.02426772],\n",
      "         [ 0.02489965, -0.00893734, -0.02202981, ...,  0.01803822,\n",
      "           0.01908579,  0.01935   ],\n",
      "         [-0.02070854,  0.02718608,  0.02677781, ..., -0.00135   ,\n",
      "          -0.01876273,  0.02783407],\n",
      "         ...,\n",
      "         [-0.03518043,  0.00011045,  0.03215411, ..., -0.01261785,\n",
      "          -0.02622032, -0.0159761 ],\n",
      "         [ 0.0107046 ,  0.02365555, -0.02350097, ..., -0.00465578,\n",
      "           0.00970775,  0.03056519],\n",
      "         [ 0.00055043, -0.03133543,  0.03603147, ...,  0.01678529,\n",
      "           0.03454381,  0.02622644]]]], dtype=float32)>, <tf.Variable 'basic_block_13/conv2d_34/bias:0' shape=(256,) dtype=float32, numpy=\n",
      "array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0.], dtype=float32)>, <tf.Variable 'basic_block_13/batch_normalization_36/gamma:0' shape=(256,) dtype=float32, numpy=\n",
      "array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1.], dtype=float32)>, <tf.Variable 'basic_block_13/batch_normalization_36/beta:0' shape=(256,) dtype=float32, numpy=\n",
      "array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0.], dtype=float32)>, <tf.Variable 'basic_block_13/batch_normalization_35/moving_mean:0' shape=(256,) dtype=float32, numpy=\n",
      "array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0.], dtype=float32)>, <tf.Variable 'basic_block_13/batch_normalization_35/moving_variance:0' shape=(256,) dtype=float32, numpy=\n",
      "array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1.], dtype=float32)>, <tf.Variable 'basic_block_13/batch_normalization_36/moving_mean:0' shape=(256,) dtype=float32, numpy=\n",
      "array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0.], dtype=float32)>, <tf.Variable 'basic_block_13/batch_normalization_36/moving_variance:0' shape=(256,) dtype=float32, numpy=\n",
      "array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1.], dtype=float32)>, <tf.Variable 'basic_block_14/conv2d_35/kernel:0' shape=(3, 3, 256, 512) dtype=float32, numpy=\n",
      "array([[[[-1.38947833e-02, -1.20017510e-02,  7.15869106e-03, ...,\n",
      "           2.68698949e-02,  1.92911197e-02,  1.78016871e-02],\n",
      "         [-1.18195210e-02, -1.03386715e-02, -2.16355585e-02, ...,\n",
      "          -5.92203997e-03,  1.18872803e-02,  8.94839503e-03],\n",
      "         [ 2.81323548e-02,  2.84976829e-02, -7.40015134e-03, ...,\n",
      "           9.46566276e-03,  2.09142622e-02,  1.88666768e-03],\n",
      "         ...,\n",
      "         [ 8.00991617e-03,  1.44258589e-02, -2.51796376e-02, ...,\n",
      "          -2.83836555e-02, -1.55752907e-02, -1.58743709e-02],\n",
      "         [ 1.40935984e-02, -1.95256080e-02, -1.13135632e-02, ...,\n",
      "          -2.31420472e-02,  3.95815261e-03,  2.88932435e-02],\n",
      "         [-1.35848485e-03, -6.04113936e-03, -1.60894170e-03, ...,\n",
      "           2.31181551e-03, -3.84653918e-03,  1.33709740e-02]],\n",
      "\n",
      "        [[-1.82965919e-02, -2.19663791e-03,  1.77080203e-02, ...,\n",
      "           5.74346446e-03,  1.95742995e-02,  2.53874566e-02],\n",
      "         [ 1.09125841e-02,  1.05761420e-02,  1.97547395e-02, ...,\n",
      "           2.15449128e-02, -9.43597406e-05, -9.28621739e-04],\n",
      "         [-9.34312679e-03,  2.77123787e-03,  2.92946603e-02, ...,\n",
      "           1.83859281e-03, -1.47288553e-02, -7.97611475e-03],\n",
      "         ...,\n",
      "         [-1.23928171e-02,  1.84878632e-02,  8.30367208e-06, ...,\n",
      "           1.88586768e-02, -2.32066810e-02,  6.62448071e-03],\n",
      "         [-1.25395451e-02, -2.60849167e-02, -2.18249094e-02, ...,\n",
      "           2.32054852e-03,  2.12322678e-02,  2.03305241e-02],\n",
      "         [ 9.77599807e-03, -1.61983334e-02,  1.45201199e-02, ...,\n",
      "          -2.69297324e-03, -1.51830157e-02, -4.04382870e-03]],\n",
      "\n",
      "        [[-1.47997392e-02, -2.09794641e-02,  1.79367978e-02, ...,\n",
      "           2.64858250e-02, -5.30210137e-03,  2.40861718e-02],\n",
      "         [ 6.68321736e-03, -7.04182498e-03,  5.81313111e-03, ...,\n",
      "          -1.99672710e-02, -1.86180007e-02, -9.21682082e-03],\n",
      "         [ 1.48937907e-02,  2.54077278e-03, -8.65816325e-03, ...,\n",
      "          -3.41237709e-03,  1.33221541e-02, -4.73770685e-03],\n",
      "         ...,\n",
      "         [-3.51814553e-03,  1.97020080e-02, -9.27813724e-03, ...,\n",
      "          -1.40863974e-02, -1.09659508e-04, -2.68441830e-02],\n",
      "         [-5.65473549e-03, -7.47505948e-03,  2.81692315e-02, ...,\n",
      "          -1.09873191e-02, -1.27464365e-02,  2.21843459e-03],\n",
      "         [-5.95449843e-03,  1.96764674e-02, -1.19692981e-02, ...,\n",
      "          -2.21862067e-02, -2.90679373e-02, -2.25935839e-02]]],\n",
      "\n",
      "\n",
      "       [[[ 2.80277673e-02,  3.30874696e-04,  2.86511052e-02, ...,\n",
      "           2.22278889e-02,  7.14465976e-03, -2.24832930e-02],\n",
      "         [-1.80969238e-02,  1.24845300e-02,  2.74421833e-02, ...,\n",
      "           2.81551350e-02,  2.13735607e-02, -2.34966520e-02],\n",
      "         [ 9.86621343e-03, -4.56516445e-03,  5.29100187e-03, ...,\n",
      "          -9.55254026e-03,  7.21667148e-03,  1.72796883e-02],\n",
      "         ...,\n",
      "         [-7.47170858e-03,  4.66688536e-03,  2.73955055e-03, ...,\n",
      "          -1.32343136e-02,  2.42571067e-02, -1.89283323e-02],\n",
      "         [ 1.82111282e-02, -1.63450744e-02, -2.21971013e-02, ...,\n",
      "           2.85282750e-02,  2.13689562e-02,  2.71358155e-03],\n",
      "         [-9.42546129e-03, -4.25107777e-03,  1.49244573e-02, ...,\n",
      "          -1.86744314e-02,  1.90353580e-02,  2.12333519e-02]],\n",
      "\n",
      "        [[-1.34708006e-02, -9.41780396e-03, -2.61857659e-02, ...,\n",
      "           9.14590992e-03, -3.37693840e-04, -7.96610489e-03],\n",
      "         [-2.15191692e-02, -2.10254248e-02,  7.70664401e-03, ...,\n",
      "           1.13385227e-02, -2.49761865e-02, -1.65790953e-02],\n",
      "         [ 1.74829010e-02, -1.66780278e-02,  1.77056883e-02, ...,\n",
      "          -1.25520136e-02,  5.52015565e-03,  1.11922156e-02],\n",
      "         ...,\n",
      "         [ 2.38347799e-04,  3.55189107e-03, -1.04665868e-02, ...,\n",
      "          -3.26097943e-03,  1.21559929e-02,  1.13934260e-02],\n",
      "         [-9.65430401e-03,  6.79340400e-03, -1.88541040e-02, ...,\n",
      "           3.94019671e-03, -8.77558440e-03,  2.61659008e-02],\n",
      "         [ 2.77881883e-03,  2.19068993e-02, -2.07614750e-02, ...,\n",
      "          -1.68828126e-02, -1.72100551e-02,  1.75190307e-02]],\n",
      "\n",
      "        [[ 2.70200726e-02,  1.83045436e-02, -2.22152602e-02, ...,\n",
      "          -2.24734638e-02, -2.43242923e-02, -1.21340081e-02],\n",
      "         [-4.89782915e-03, -1.80962905e-02,  2.64851376e-02, ...,\n",
      "          -1.29772183e-02, -2.22508609e-03, -5.02177514e-03],\n",
      "         [ 1.17883477e-02, -9.70135443e-03, -5.55986539e-03, ...,\n",
      "          -7.28825852e-03, -2.06803698e-02, -9.47527960e-03],\n",
      "         ...,\n",
      "         [ 2.34984942e-02,  2.60666739e-02, -2.09272262e-02, ...,\n",
      "           1.97696406e-02, -2.87854485e-03,  2.38353144e-02],\n",
      "         [-3.67192551e-03,  9.03979130e-03, -2.70915236e-02, ...,\n",
      "           5.42353280e-03,  2.38234159e-02, -2.28828583e-02],\n",
      "         [-1.39287049e-02,  2.38023642e-02, -1.23091843e-02, ...,\n",
      "          -1.06170159e-02,  2.85340566e-02,  6.79365732e-03]]],\n",
      "\n",
      "\n",
      "       [[[-2.64825802e-02,  2.38488149e-02, -1.58706196e-02, ...,\n",
      "          -7.43045472e-03,  2.55113337e-02,  2.59308126e-02],\n",
      "         [ 9.75210778e-03, -1.61352195e-03,  2.39128135e-02, ...,\n",
      "           1.63088068e-02, -2.68624201e-02,  9.91164707e-03],\n",
      "         [-2.64619477e-02,  1.77971516e-02,  2.29884367e-02, ...,\n",
      "           2.83151437e-02, -2.56376471e-02, -2.29805205e-02],\n",
      "         ...,\n",
      "         [ 1.92406587e-03, -1.42914709e-02, -6.70125149e-03, ...,\n",
      "          -9.33569483e-03, -7.18779862e-04,  1.69396754e-02],\n",
      "         [ 2.06002127e-02,  1.29804127e-02,  1.94945782e-02, ...,\n",
      "          -7.54647143e-03,  1.96412690e-02, -1.59885120e-02],\n",
      "         [-6.20969944e-03, -1.14617720e-02,  2.35160533e-02, ...,\n",
      "          -2.00563651e-02, -1.56454928e-02,  1.46893505e-02]],\n",
      "\n",
      "        [[-2.28591207e-02,  1.20680667e-02,  2.90240217e-02, ...,\n",
      "          -1.35334730e-02, -9.89447907e-03, -2.23022923e-02],\n",
      "         [ 8.96943919e-03,  4.07236256e-03, -2.84291059e-03, ...,\n",
      "           5.94177283e-03, -6.80048577e-03, -1.21258311e-02],\n",
      "         [ 1.20734628e-02,  8.80025327e-04,  2.44767610e-02, ...,\n",
      "          -2.20576655e-02, -2.90080048e-02, -2.48756390e-02],\n",
      "         ...,\n",
      "         [-2.42651142e-02, -1.44591294e-02,  2.48873793e-03, ...,\n",
      "          -2.94538420e-02, -2.13538688e-02,  2.15653609e-02],\n",
      "         [ 1.31360274e-02,  1.53100342e-02,  2.22786833e-02, ...,\n",
      "          -1.79712065e-02, -2.68801637e-02,  2.09977664e-03],\n",
      "         [-2.43175440e-02, -4.12113965e-03,  2.38879267e-02, ...,\n",
      "          -2.46970989e-02, -3.86818126e-03,  2.02345680e-02]],\n",
      "\n",
      "        [[ 9.29578952e-03,  1.65589340e-03, -9.60456394e-03, ...,\n",
      "          -1.94862541e-02, -1.56810991e-02, -2.78124716e-02],\n",
      "         [ 3.54273058e-03, -2.51248404e-02, -1.29513126e-02, ...,\n",
      "          -5.05524687e-03,  1.77892726e-02,  2.61448268e-02],\n",
      "         [-2.40073092e-02, -2.52284668e-03, -2.83466224e-02, ...,\n",
      "          -1.37889758e-03, -1.83698442e-02, -1.43544171e-02],\n",
      "         ...,\n",
      "         [-2.78068706e-03,  8.82982276e-03,  5.30526973e-03, ...,\n",
      "          -2.11085379e-03,  7.12310709e-03,  7.97490589e-03],\n",
      "         [-6.22469559e-03, -5.63053414e-04, -2.61051618e-02, ...,\n",
      "           5.76383434e-03, -2.83511039e-02,  7.52301700e-03],\n",
      "         [-2.07265560e-02, -7.78008997e-03,  1.81694664e-02, ...,\n",
      "           1.18428227e-02,  1.51786115e-02, -2.14625150e-04]]]],\n",
      "      dtype=float32)>, <tf.Variable 'basic_block_14/conv2d_35/bias:0' shape=(512,) dtype=float32, numpy=\n",
      "array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0.], dtype=float32)>, <tf.Variable 'basic_block_14/batch_normalization_37/gamma:0' shape=(512,) dtype=float32, numpy=\n",
      "array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1.], dtype=float32)>, <tf.Variable 'basic_block_14/batch_normalization_37/beta:0' shape=(512,) dtype=float32, numpy=\n",
      "array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0.], dtype=float32)>, <tf.Variable 'basic_block_14/conv2d_36/kernel:0' shape=(3, 3, 512, 512) dtype=float32, numpy=\n",
      "array([[[[-2.50395015e-02, -6.13550283e-03, -1.04470449e-02, ...,\n",
      "          -2.47721970e-02,  1.59331337e-02,  2.43235901e-02],\n",
      "         [ 2.04198658e-02, -1.20446458e-03, -1.07231624e-02, ...,\n",
      "           5.52762672e-03, -1.13687916e-02,  7.33429193e-03],\n",
      "         [ 1.49606206e-02,  1.68423131e-02,  2.37220414e-02, ...,\n",
      "           2.06324570e-02, -8.34636390e-03, -1.67448521e-02],\n",
      "         ...,\n",
      "         [-5.50674275e-03,  4.71401773e-03, -1.96247399e-02, ...,\n",
      "          -2.47678608e-02,  1.80864371e-02, -1.56009272e-02],\n",
      "         [ 8.37827101e-03, -8.56469013e-03,  8.85149091e-03, ...,\n",
      "          -1.61530413e-02,  2.08369605e-02, -7.56308064e-03],\n",
      "         [-8.36401805e-03,  2.43005492e-02, -1.26668438e-02, ...,\n",
      "           1.28225237e-02, -8.42742622e-03, -1.35310646e-02]],\n",
      "\n",
      "        [[ 1.10382326e-02, -1.65414549e-02, -1.19400769e-03, ...,\n",
      "           2.25305595e-02, -8.29972327e-04,  2.34782137e-02],\n",
      "         [ 2.12737396e-02, -1.92266423e-02, -1.80212818e-02, ...,\n",
      "          -2.69357860e-03, -2.51253005e-02,  2.52503008e-02],\n",
      "         [-5.56298904e-03,  2.09522359e-02, -9.69977491e-03, ...,\n",
      "           1.23856328e-02,  6.94558769e-03,  5.12211584e-03],\n",
      "         ...,\n",
      "         [-2.19074935e-02,  1.71011910e-02, -2.29816884e-04, ...,\n",
      "           1.11336038e-02,  2.45318078e-02, -1.99231654e-02],\n",
      "         [ 9.32798907e-03, -9.66083631e-03, -5.01164235e-03, ...,\n",
      "           1.65357068e-03, -3.16645764e-03, -2.93064117e-03],\n",
      "         [ 2.04231218e-02, -1.85563397e-02, -3.72304395e-03, ...,\n",
      "          -7.46270642e-03,  1.90900788e-02, -1.83438547e-02]],\n",
      "\n",
      "        [[ 2.14550979e-02, -1.59433074e-02,  3.27110291e-03, ...,\n",
      "          -8.43307003e-04,  5.16587310e-03,  7.08427280e-03],\n",
      "         [-1.14963986e-02,  1.42832138e-02, -2.14842930e-02, ...,\n",
      "           2.50385646e-02, -1.85233504e-02,  1.25092342e-02],\n",
      "         [ 1.82319582e-02,  1.05840303e-02,  1.71904266e-02, ...,\n",
      "          -7.87141733e-03, -9.17889923e-03,  1.44311264e-02],\n",
      "         ...,\n",
      "         [ 1.49449930e-02,  2.11530402e-02,  1.78007782e-02, ...,\n",
      "          -1.37995798e-02,  1.82366520e-02, -1.25122955e-02],\n",
      "         [-1.55385844e-02,  2.02265494e-02,  7.84715638e-03, ...,\n",
      "           1.96718611e-02, -1.50477514e-04,  1.80117171e-02],\n",
      "         [ 1.75531730e-02, -8.43175128e-03, -8.38360749e-03, ...,\n",
      "           1.48044452e-02, -2.13447940e-02,  1.87835135e-02]]],\n",
      "\n",
      "\n",
      "       [[[ 2.28197966e-02, -1.77483633e-03, -4.51652706e-03, ...,\n",
      "           1.71947107e-02,  2.39170939e-02,  2.38786153e-02],\n",
      "         [ 6.25077635e-03, -2.45173536e-02, -1.49290003e-02, ...,\n",
      "           1.91021878e-02, -1.47529598e-02,  1.18746832e-02],\n",
      "         [-1.59201175e-02,  1.15976660e-02, -3.22829373e-03, ...,\n",
      "           1.52843483e-02,  3.00208107e-04,  1.39492974e-02],\n",
      "         ...,\n",
      "         [-7.70875439e-03,  1.51213072e-02,  1.70846879e-02, ...,\n",
      "           2.41582952e-02, -1.63505208e-02, -7.70017691e-03],\n",
      "         [ 9.80712846e-03, -7.69594312e-03, -1.26917362e-02, ...,\n",
      "          -1.71674024e-02,  2.05695815e-03, -2.97424570e-03],\n",
      "         [ 3.85822728e-03,  1.05222426e-02, -1.91587284e-02, ...,\n",
      "           4.84664179e-03, -2.06287205e-02, -1.76523812e-02]],\n",
      "\n",
      "        [[ 1.98188424e-03, -1.28025450e-02, -2.20687706e-02, ...,\n",
      "          -2.53813490e-02, -1.79488733e-02, -2.37621702e-02],\n",
      "         [-8.69162567e-03,  5.43977134e-03,  1.86862759e-02, ...,\n",
      "           1.09079331e-02,  2.27746852e-02, -1.67653523e-03],\n",
      "         [ 5.29586896e-03,  3.87020595e-03, -1.37152281e-02, ...,\n",
      "          -9.17671248e-04, -6.38143532e-03, -1.18638873e-02],\n",
      "         ...,\n",
      "         [-1.98541209e-03, -1.98200271e-02,  9.98385251e-04, ...,\n",
      "           2.49162856e-02, -2.25123521e-02, -1.44120604e-02],\n",
      "         [ 7.88336992e-03, -1.32319517e-02,  3.29115428e-03, ...,\n",
      "          -2.13611163e-02,  3.00333090e-03, -9.60566476e-03],\n",
      "         [-9.51467082e-03, -1.20896474e-02, -1.43441092e-02, ...,\n",
      "           4.26858943e-03, -9.27466899e-05, -1.54599939e-02]],\n",
      "\n",
      "        [[-1.53713338e-02,  7.60804862e-04,  1.67960748e-02, ...,\n",
      "           4.36154194e-03,  2.06653960e-02,  2.09995098e-02],\n",
      "         [ 9.74938646e-03, -4.36010025e-03, -5.15360944e-03, ...,\n",
      "          -1.57297123e-02,  2.77994946e-03,  8.90876818e-03],\n",
      "         [-2.32087038e-02,  2.25116946e-02,  1.10551007e-02, ...,\n",
      "           1.16986819e-02,  2.53540128e-02,  2.44967416e-02],\n",
      "         ...,\n",
      "         [ 1.82618015e-03, -2.21144073e-02,  1.41698681e-02, ...,\n",
      "          -1.43787712e-02,  2.48635933e-03,  2.04399116e-02],\n",
      "         [ 1.54103218e-02, -1.97922252e-02,  8.75197351e-04, ...,\n",
      "           2.96462327e-03, -1.75827872e-02, -9.87324305e-03],\n",
      "         [-2.63269618e-03,  6.13352656e-03,  2.19438560e-02, ...,\n",
      "           2.74633989e-03, -1.51383467e-02, -1.04732523e-02]]],\n",
      "\n",
      "\n",
      "       [[[-2.17873473e-02, -2.24602297e-02, -3.65020707e-04, ...,\n",
      "          -2.20095739e-02, -1.55154243e-02,  2.15777345e-02],\n",
      "         [-8.05740431e-03, -3.26963142e-04, -2.05071084e-03, ...,\n",
      "           2.37896778e-02, -9.02547501e-03, -2.23616734e-02],\n",
      "         [ 8.52560997e-03,  2.43150033e-02,  6.14313781e-03, ...,\n",
      "          -1.33300405e-02, -2.28619203e-04, -9.07770731e-03],\n",
      "         ...,\n",
      "         [-2.07453333e-02, -8.69792327e-03, -5.27657196e-03, ...,\n",
      "          -9.56303254e-03, -2.35236157e-02,  1.69438981e-02],\n",
      "         [ 1.00741349e-02,  1.14068054e-02,  7.62344524e-03, ...,\n",
      "           2.17921250e-02,  4.98199649e-03,  1.14059076e-03],\n",
      "         [-2.50972398e-02, -2.37432979e-02,  1.26636848e-02, ...,\n",
      "           9.09305736e-03, -6.64324500e-03,  1.71955004e-02]],\n",
      "\n",
      "        [[ 3.08994111e-03,  5.73506951e-03,  1.66730508e-02, ...,\n",
      "          -8.47944990e-03, -1.93533450e-02, -1.53750097e-02],\n",
      "         [-1.18628033e-02, -5.97340986e-03,  2.51438729e-02, ...,\n",
      "           1.97120160e-02,  6.54825941e-03,  1.39411576e-02],\n",
      "         [-2.66239420e-03,  2.14539245e-02,  2.60578841e-03, ...,\n",
      "          -1.05991596e-02,  1.69066861e-02,  7.77192414e-03],\n",
      "         ...,\n",
      "         [-2.13718526e-02,  1.40810832e-02,  1.83044598e-02, ...,\n",
      "           2.91054789e-03, -1.25047155e-02, -1.45437270e-02],\n",
      "         [ 1.84959807e-02, -2.27574389e-02,  2.13545337e-02, ...,\n",
      "          -8.70204717e-03, -9.57080163e-03,  9.91217047e-03],\n",
      "         [ 8.11363757e-03,  2.14595348e-02, -3.98628227e-03, ...,\n",
      "          -8.52928497e-03,  6.70431182e-04,  1.27907060e-02]],\n",
      "\n",
      "        [[ 2.47686319e-02, -2.49490235e-02,  1.07684359e-02, ...,\n",
      "           1.95928551e-02, -1.83540024e-02, -5.52702509e-03],\n",
      "         [ 8.86902213e-03,  1.92444157e-02,  2.34929994e-02, ...,\n",
      "           9.90610570e-04, -3.39916348e-03, -2.27224901e-02],\n",
      "         [-1.89308412e-02, -1.31534161e-02, -2.08005905e-02, ...,\n",
      "          -2.28242874e-02, -2.18699295e-02,  2.47540437e-02],\n",
      "         ...,\n",
      "         [-1.86132938e-02, -2.43402664e-02, -9.29259136e-03, ...,\n",
      "           1.09322108e-02, -1.27836261e-02,  3.40814423e-03],\n",
      "         [-2.42260918e-02,  1.13567831e-02,  4.17441130e-04, ...,\n",
      "           1.86128728e-03,  1.16343200e-02, -1.88789479e-02],\n",
      "         [-1.77614316e-02,  2.48717889e-02,  3.50813568e-03, ...,\n",
      "          -4.12192941e-03,  1.03701465e-03, -2.34612972e-02]]]],\n",
      "      dtype=float32)>, <tf.Variable 'basic_block_14/conv2d_36/bias:0' shape=(512,) dtype=float32, numpy=\n",
      "array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0.], dtype=float32)>, <tf.Variable 'basic_block_14/batch_normalization_38/gamma:0' shape=(512,) dtype=float32, numpy=\n",
      "array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1.], dtype=float32)>, <tf.Variable 'basic_block_14/batch_normalization_38/beta:0' shape=(512,) dtype=float32, numpy=\n",
      "array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0.], dtype=float32)>, <tf.Variable 'conv2d_37/kernel:0' shape=(1, 1, 256, 512) dtype=float32, numpy=\n",
      "array([[[[-0.00430338, -0.02500577,  0.07403655, ...,  0.07363728,\n",
      "          -0.02657369, -0.02497852],\n",
      "         [-0.03935375,  0.01940464, -0.07743368, ...,  0.01836655,\n",
      "          -0.0252796 ,  0.02549431],\n",
      "         [ 0.05174173, -0.06108876, -0.05749472, ..., -0.07500301,\n",
      "           0.04186562, -0.06645268],\n",
      "         ...,\n",
      "         [ 0.08265621,  0.00628158, -0.06748503, ..., -0.04975615,\n",
      "           0.08491621, -0.07592881],\n",
      "         [-0.04619113, -0.02470808, -0.01700809, ...,  0.06014884,\n",
      "           0.03235105, -0.04422652],\n",
      "         [ 0.08492484, -0.00230383, -0.08511923, ..., -0.02463376,\n",
      "          -0.0025891 , -0.02521353]]]], dtype=float32)>, <tf.Variable 'conv2d_37/bias:0' shape=(512,) dtype=float32, numpy=\n",
      "array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0.], dtype=float32)>, <tf.Variable 'batch_normalization_39/gamma:0' shape=(512,) dtype=float32, numpy=\n",
      "array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1.], dtype=float32)>, <tf.Variable 'batch_normalization_39/beta:0' shape=(512,) dtype=float32, numpy=\n",
      "array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0.], dtype=float32)>, <tf.Variable 'basic_block_14/batch_normalization_37/moving_mean:0' shape=(512,) dtype=float32, numpy=\n",
      "array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0.], dtype=float32)>, <tf.Variable 'basic_block_14/batch_normalization_37/moving_variance:0' shape=(512,) dtype=float32, numpy=\n",
      "array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1.], dtype=float32)>, <tf.Variable 'basic_block_14/batch_normalization_38/moving_mean:0' shape=(512,) dtype=float32, numpy=\n",
      "array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0.], dtype=float32)>, <tf.Variable 'basic_block_14/batch_normalization_38/moving_variance:0' shape=(512,) dtype=float32, numpy=\n",
      "array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1.], dtype=float32)>, <tf.Variable 'batch_normalization_39/moving_mean:0' shape=(512,) dtype=float32, numpy=\n",
      "array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0.], dtype=float32)>, <tf.Variable 'batch_normalization_39/moving_variance:0' shape=(512,) dtype=float32, numpy=\n",
      "array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1.], dtype=float32)>, <tf.Variable 'basic_block_15/conv2d_38/kernel:0' shape=(3, 3, 512, 512) dtype=float32, numpy=\n",
      "array([[[[ 0.00910364, -0.00399083,  0.01305848, ..., -0.00063813,\n",
      "           0.02498429, -0.00927314],\n",
      "         [-0.01236252, -0.00506943, -0.00515654, ..., -0.02329216,\n",
      "           0.00943933, -0.00433911],\n",
      "         [-0.0113809 ,  0.01037698, -0.02390417, ..., -0.00220314,\n",
      "          -0.00885254,  0.01618823],\n",
      "         ...,\n",
      "         [ 0.02396721,  0.00918762, -0.02214568, ...,  0.00527293,\n",
      "           0.01894993, -0.02390684],\n",
      "         [ 0.01714721,  0.01688545, -0.00298726, ..., -0.02249965,\n",
      "           0.0028317 , -0.02531957],\n",
      "         [-0.00860142,  0.01804562, -0.00020753, ..., -0.0056582 ,\n",
      "          -0.01278169, -0.00834119]],\n",
      "\n",
      "        [[-0.00894921, -0.00578987, -0.02223393, ...,  0.00753424,\n",
      "          -0.00601593, -0.01199308],\n",
      "         [ 0.02069487,  0.00599554,  0.02017609, ...,  0.01683421,\n",
      "          -0.00825433,  0.02076596],\n",
      "         [ 0.02172064,  0.02096746, -0.00448141, ..., -0.01267957,\n",
      "          -0.00123955, -0.00068265],\n",
      "         ...,\n",
      "         [-0.01105127, -0.00672392, -0.00377219, ..., -0.00898262,\n",
      "          -0.0035182 ,  0.01934357],\n",
      "         [-0.01524745, -0.00594229, -0.01134853, ..., -0.0118258 ,\n",
      "           0.00287846,  0.00796325],\n",
      "         [-0.02340335,  0.00121545,  0.01986591, ...,  0.02135978,\n",
      "          -0.02278345,  0.00969301]],\n",
      "\n",
      "        [[-0.01563552, -0.01735982, -0.00314855, ...,  0.01399517,\n",
      "          -0.00834472, -0.01417638],\n",
      "         [-0.01008117,  0.01925086,  0.02014972, ..., -0.00644333,\n",
      "          -0.0138404 ,  0.01699136],\n",
      "         [-0.00378897, -0.00498531,  0.00796376, ...,  0.01200006,\n",
      "          -0.00894432, -0.01898948],\n",
      "         ...,\n",
      "         [ 0.00113071, -0.00068169,  0.00390408, ...,  0.01001642,\n",
      "          -0.00042016,  0.00821752],\n",
      "         [-0.01863366, -0.01178566, -0.01414834, ...,  0.00776159,\n",
      "           0.01897928, -0.02231218],\n",
      "         [-0.02480265,  0.00747866, -0.00957142, ..., -0.01809671,\n",
      "           0.01392575,  0.02005906]]],\n",
      "\n",
      "\n",
      "       [[[ 0.00625677,  0.0236766 , -0.02160827, ...,  0.00253548,\n",
      "          -0.00290793, -0.01177343],\n",
      "         [ 0.00421171,  0.01671779,  0.02269836, ...,  0.00593041,\n",
      "           0.01822029,  0.02046461],\n",
      "         [-0.00133085,  0.01574203,  0.02478863, ..., -0.02195841,\n",
      "           0.0231018 , -0.02429279],\n",
      "         ...,\n",
      "         [-0.0200268 , -0.0175823 , -0.01675225, ...,  0.01784746,\n",
      "          -0.0191936 ,  0.01364835],\n",
      "         [ 0.02551171,  0.00250536, -0.00672306, ...,  0.01478767,\n",
      "          -0.00870284,  0.00891417],\n",
      "         [ 0.02492906,  0.01743124, -0.01866497, ..., -0.00408831,\n",
      "          -0.02529502,  0.02550498]],\n",
      "\n",
      "        [[-0.01140634, -0.02135399,  0.01607619, ..., -0.01363261,\n",
      "          -0.01638008,  0.01197659],\n",
      "         [-0.02083506, -0.00758009, -0.01862603, ..., -0.02159104,\n",
      "          -0.00028013, -0.00836314],\n",
      "         [-0.01851581,  0.0183841 , -0.02445154, ...,  0.01942272,\n",
      "          -0.00078512, -0.01684993],\n",
      "         ...,\n",
      "         [ 0.02048771,  0.00158036, -0.01617016, ...,  0.00569545,\n",
      "          -0.01017582,  0.00092719],\n",
      "         [-0.01189413,  0.0139594 ,  0.01385782, ...,  0.02327151,\n",
      "          -0.00576748, -0.01646735],\n",
      "         [-0.01056281, -0.00982358, -0.00563475, ...,  0.01964361,\n",
      "          -0.01296823, -0.01935102]],\n",
      "\n",
      "        [[-0.01140627,  0.0153719 , -0.00218368, ...,  0.02238752,\n",
      "          -0.02101784, -0.01294725],\n",
      "         [ 0.01181098, -0.02199632,  0.0105263 , ...,  0.02089042,\n",
      "           0.01132652,  0.00723768],\n",
      "         [-0.01638959, -0.02215183, -0.01178332, ..., -0.02134576,\n",
      "           0.02416455,  0.01185023],\n",
      "         ...,\n",
      "         [ 0.01617652, -0.00680501,  0.01194283, ..., -0.01505833,\n",
      "          -0.01980584,  0.01897251],\n",
      "         [-0.00096078, -0.02328194, -0.0189997 , ...,  0.00856031,\n",
      "           0.01971737,  0.01401495],\n",
      "         [ 0.01545589, -0.01191438,  0.00712458, ..., -0.02227488,\n",
      "          -0.00677966,  0.00066275]]],\n",
      "\n",
      "\n",
      "       [[[ 0.02201976, -0.00912206, -0.01861705, ...,  0.02120927,\n",
      "          -0.01188539,  0.00824765],\n",
      "         [-0.00451425, -0.01153776,  0.00814166, ...,  0.00362222,\n",
      "          -0.02076221,  0.0001332 ],\n",
      "         [-0.00548975,  0.01037793, -0.00811809, ...,  0.01086509,\n",
      "          -0.01393037,  0.02425913],\n",
      "         ...,\n",
      "         [-0.02051759,  0.0026137 ,  0.02113592, ...,  0.0203175 ,\n",
      "          -0.00659235, -0.00694081],\n",
      "         [-0.01833211,  0.01876284, -0.02098586, ..., -0.00229581,\n",
      "          -0.01712411, -0.00043572],\n",
      "         [ 0.01380428,  0.01548797,  0.02215081, ...,  0.01449923,\n",
      "          -0.00977529, -0.02158389]],\n",
      "\n",
      "        [[-0.00234421,  0.00248541,  0.00972237, ...,  0.01793939,\n",
      "           0.01351983, -0.00180104],\n",
      "         [ 0.01406331, -0.00956028, -0.01261992, ..., -0.022769  ,\n",
      "           0.0220429 ,  0.01808809],\n",
      "         [ 0.02166237,  0.02474045,  0.02148754, ...,  0.00289173,\n",
      "          -0.02333235,  0.00645208],\n",
      "         ...,\n",
      "         [ 0.02272578, -0.01862163, -0.01333977, ..., -0.01600613,\n",
      "          -0.01367434,  0.01362597],\n",
      "         [-0.00598296,  0.01956005,  0.0078635 , ...,  0.01804968,\n",
      "          -0.0145156 , -0.00846869],\n",
      "         [-0.02195473, -0.01758678,  0.01428682, ...,  0.00593059,\n",
      "           0.01230108,  0.00310731]],\n",
      "\n",
      "        [[ 0.01433357,  0.02269128, -0.02008287, ..., -0.02429619,\n",
      "           0.01551065,  0.01785793],\n",
      "         [ 0.01036936, -0.00568576, -0.02344611, ...,  0.00446143,\n",
      "           0.00116828, -0.00438493],\n",
      "         [ 0.00158371,  0.00159716,  0.01448021, ..., -0.01889275,\n",
      "          -0.01545514,  0.00034658],\n",
      "         ...,\n",
      "         [-0.00555911, -0.00734504,  0.0181272 , ...,  0.00877302,\n",
      "          -0.0015499 , -0.00775313],\n",
      "         [-0.02308581,  0.00377971, -0.01116396, ...,  0.01163127,\n",
      "          -0.01352205,  0.00052711],\n",
      "         [ 0.02266516,  0.0102358 ,  0.00492154, ...,  0.00023523,\n",
      "           0.00249691, -0.00525187]]]], dtype=float32)>, <tf.Variable 'basic_block_15/conv2d_38/bias:0' shape=(512,) dtype=float32, numpy=\n",
      "array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0.], dtype=float32)>, <tf.Variable 'basic_block_15/batch_normalization_40/gamma:0' shape=(512,) dtype=float32, numpy=\n",
      "array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1.], dtype=float32)>, <tf.Variable 'basic_block_15/batch_normalization_40/beta:0' shape=(512,) dtype=float32, numpy=\n",
      "array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0.], dtype=float32)>, <tf.Variable 'basic_block_15/conv2d_39/kernel:0' shape=(3, 3, 512, 512) dtype=float32, numpy=\n",
      "array([[[[-8.70551541e-03, -2.32236460e-02, -1.57222338e-03, ...,\n",
      "           2.34978274e-02, -2.25312896e-02,  2.18972806e-02],\n",
      "         [-2.68902630e-04,  7.26608932e-03,  1.48078948e-02, ...,\n",
      "           1.70484576e-02, -8.99843499e-03,  1.50752030e-02],\n",
      "         [ 1.47081502e-02, -1.14612468e-02, -1.42895952e-02, ...,\n",
      "          -6.59751706e-03, -9.51168314e-03,  9.26075131e-03],\n",
      "         ...,\n",
      "         [ 1.37386471e-02,  9.39918682e-04, -4.10540216e-03, ...,\n",
      "          -7.38007016e-03,  2.39514336e-02,  3.66736203e-04],\n",
      "         [ 1.79845169e-02, -7.99108855e-03,  7.13666156e-03, ...,\n",
      "          -2.13415213e-02, -6.80511817e-03, -1.56147555e-02],\n",
      "         [-1.49518317e-02,  5.27688861e-03,  1.76873654e-02, ...,\n",
      "           8.61363858e-03,  1.75403245e-02,  7.32210651e-03]],\n",
      "\n",
      "        [[ 1.72096938e-02,  2.08699070e-02, -1.31416135e-03, ...,\n",
      "          -2.44931653e-02,  4.86127287e-03,  1.26541508e-02],\n",
      "         [-2.51077451e-02,  2.51768045e-02,  6.89655542e-03, ...,\n",
      "           6.97169080e-03, -2.25853343e-02,  1.00685423e-02],\n",
      "         [ 1.24358013e-02,  1.35165751e-02, -1.29040703e-02, ...,\n",
      "          -5.70363738e-03, -2.00783145e-02, -1.74477547e-02],\n",
      "         ...,\n",
      "         [-1.94081515e-02, -1.76528804e-02,  1.47971511e-02, ...,\n",
      "          -1.82963070e-02,  8.75393674e-03, -1.28336614e-02],\n",
      "         [ 2.25957111e-03,  2.92204507e-03, -1.19826281e-02, ...,\n",
      "           4.87142615e-03, -1.30410008e-02, -2.37392262e-04],\n",
      "         [ 1.19068734e-02, -2.34946217e-02,  1.11036748e-03, ...,\n",
      "           6.19506463e-03, -1.50427055e-02, -1.65863298e-02]],\n",
      "\n",
      "        [[ 4.45249490e-03,  5.34984656e-03, -2.31615398e-02, ...,\n",
      "           1.07818656e-03, -1.60233341e-02,  6.66059647e-03],\n",
      "         [ 2.06150636e-02, -1.23341009e-02,  1.67786144e-02, ...,\n",
      "           6.56906515e-03,  2.98941322e-03,  3.97838652e-03],\n",
      "         [ 2.48435158e-02,  1.53689263e-02,  1.46299005e-02, ...,\n",
      "          -1.40835578e-02, -1.30741373e-02,  6.01388514e-03],\n",
      "         ...,\n",
      "         [ 3.72968055e-03,  1.14090592e-02,  1.27575174e-02, ...,\n",
      "           1.03874169e-02,  1.44847743e-02, -1.94190070e-02],\n",
      "         [-1.68415383e-02, -1.87815707e-02, -6.90067187e-04, ...,\n",
      "          -2.34309658e-02, -2.15422120e-02,  1.37319267e-02],\n",
      "         [ 1.61461458e-02,  2.07385272e-02,  2.42170505e-03, ...,\n",
      "           2.24138759e-02, -1.49348769e-02, -6.35669939e-03]]],\n",
      "\n",
      "\n",
      "       [[[ 1.61244571e-02, -5.78442402e-03,  8.61898065e-04, ...,\n",
      "           2.22395547e-02,  2.17755996e-02, -1.18499072e-02],\n",
      "         [ 4.30143252e-03,  5.51162101e-03, -3.24656814e-03, ...,\n",
      "           2.20038928e-02,  1.20497905e-02, -2.22829785e-02],\n",
      "         [-1.35934511e-02,  2.34642401e-02, -5.27620129e-03, ...,\n",
      "          -6.41854294e-03,  2.17181668e-02, -1.38211455e-02],\n",
      "         ...,\n",
      "         [ 2.13603936e-02,  6.61993399e-03,  1.87844224e-03, ...,\n",
      "          -8.35934095e-03,  1.07757114e-02, -2.00341269e-03],\n",
      "         [-2.19740793e-02, -2.14601234e-02,  1.86218210e-02, ...,\n",
      "           1.55292414e-02,  1.08066089e-02,  1.52014494e-02],\n",
      "         [ 2.48031430e-02, -2.44462974e-02,  7.23740086e-03, ...,\n",
      "           1.48228090e-02, -4.36051935e-03,  5.27535100e-03]],\n",
      "\n",
      "        [[-2.40641534e-02, -9.52951983e-03, -1.90446340e-02, ...,\n",
      "           3.29713337e-03, -1.09325768e-02, -2.20298432e-02],\n",
      "         [-1.27204377e-02, -9.03232582e-03,  7.93485343e-03, ...,\n",
      "           1.90734938e-02,  1.05721802e-02, -9.36947204e-03],\n",
      "         [-4.14744392e-03,  1.38113946e-02,  1.96590312e-02, ...,\n",
      "           4.83982265e-03,  1.89566631e-02,  5.29256649e-03],\n",
      "         ...,\n",
      "         [ 9.89545137e-04,  8.50059465e-03, -1.79103035e-02, ...,\n",
      "           2.00268328e-02,  2.70387158e-04,  2.75347568e-03],\n",
      "         [-2.36880407e-03, -1.18808597e-02,  1.16433091e-02, ...,\n",
      "           1.63590498e-02, -2.03159265e-02,  1.85929239e-03],\n",
      "         [-2.26740725e-03,  2.16335729e-02, -4.25979123e-03, ...,\n",
      "          -9.30456258e-03, -2.43683830e-02,  1.42646544e-02]],\n",
      "\n",
      "        [[ 2.61105597e-05, -2.44630277e-02, -9.47728753e-03, ...,\n",
      "           1.71309561e-02,  9.22537688e-03,  1.77127644e-02],\n",
      "         [-1.81437600e-02, -1.99401975e-02, -5.13941050e-04, ...,\n",
      "          -1.12021500e-02, -1.87161192e-02, -9.49916989e-03],\n",
      "         [-1.05610536e-02, -5.02021238e-03, -1.71086192e-02, ...,\n",
      "          -1.24974325e-02, -1.42145939e-02, -1.47196241e-02],\n",
      "         ...,\n",
      "         [ 2.04884335e-02,  1.87097117e-03, -7.21755810e-03, ...,\n",
      "          -2.03057416e-02, -9.05016810e-03, -9.59895551e-05],\n",
      "         [-5.49571961e-03, -1.91084445e-02, -1.00974925e-03, ...,\n",
      "          -1.92268752e-03, -1.76487975e-02,  1.66051649e-02],\n",
      "         [ 7.55542889e-03,  5.85282221e-04,  1.67297274e-02, ...,\n",
      "           4.47694398e-03,  2.13387795e-03, -1.20531581e-02]]],\n",
      "\n",
      "\n",
      "       [[[ 1.18873939e-02, -6.73140585e-03, -1.63811520e-02, ...,\n",
      "          -3.42295691e-03,  1.10815950e-02, -6.76470622e-03],\n",
      "         [ 2.26725638e-02,  1.69424526e-02,  2.01247148e-02, ...,\n",
      "           2.04665028e-02,  6.91371784e-03, -7.92527385e-03],\n",
      "         [-2.41863243e-02,  1.50683410e-02, -1.96008123e-02, ...,\n",
      "          -4.79389913e-03,  4.89922613e-03, -1.16325486e-02],\n",
      "         ...,\n",
      "         [ 1.36500746e-02,  9.25286487e-03,  7.88930058e-03, ...,\n",
      "           2.55018100e-03,  1.35747865e-02,  2.09707022e-02],\n",
      "         [ 9.14145634e-03, -2.22574770e-02,  1.04758665e-02, ...,\n",
      "          -6.20438345e-03,  1.35694146e-02,  6.54535368e-04],\n",
      "         [ 2.95311958e-03,  6.96837157e-03, -5.48246503e-03, ...,\n",
      "           1.93849802e-02, -2.12630220e-02,  5.94413280e-03]],\n",
      "\n",
      "        [[ 1.09291747e-02,  1.93677172e-02, -5.42829745e-03, ...,\n",
      "           2.07140930e-02, -1.69582255e-02,  8.81584734e-03],\n",
      "         [-6.10937178e-03,  2.45537125e-02, -2.12194659e-02, ...,\n",
      "          -1.55132059e-02, -1.17210010e-02, -5.36283478e-03],\n",
      "         [-2.31475420e-02,  1.70571432e-02,  6.96134940e-03, ...,\n",
      "           4.28757444e-03, -2.27330029e-02,  1.48664229e-02],\n",
      "         ...,\n",
      "         [ 1.60558149e-04, -6.55679032e-04, -1.44680887e-02, ...,\n",
      "          -1.75092947e-02,  7.19251111e-03,  1.26615129e-02],\n",
      "         [-4.31123190e-03,  4.70214896e-03, -1.65633969e-02, ...,\n",
      "           1.13736652e-02,  1.01741031e-02,  1.04718581e-02],\n",
      "         [-1.83397960e-02, -7.96592794e-03,  1.26682036e-03, ...,\n",
      "           1.01538189e-03,  2.29450017e-02,  1.51290298e-02]],\n",
      "\n",
      "        [[ 1.40297674e-02,  2.27225572e-02,  1.79676414e-02, ...,\n",
      "           9.28957388e-03, -1.88274402e-02, -8.83196294e-03],\n",
      "         [ 1.82508752e-02, -8.52777623e-03, -3.61109711e-03, ...,\n",
      "           1.10014118e-02,  2.54746154e-03,  8.15204903e-03],\n",
      "         [ 6.00687042e-03,  2.03687549e-02, -4.96049225e-03, ...,\n",
      "          -3.39629874e-03,  1.51459351e-02,  1.38828158e-03],\n",
      "         ...,\n",
      "         [ 1.23423934e-02,  1.58213638e-02,  4.23237309e-03, ...,\n",
      "          -2.26044357e-02,  2.04606913e-02, -1.49499774e-02],\n",
      "         [ 1.62967257e-02, -4.28882800e-03, -2.31432095e-02, ...,\n",
      "           1.01414770e-02,  6.79144356e-03, -1.61651783e-02],\n",
      "         [ 9.25164111e-03, -1.87777933e-02, -2.24188715e-02, ...,\n",
      "           1.11774169e-03,  1.56160444e-04, -1.77467577e-02]]]],\n",
      "      dtype=float32)>, <tf.Variable 'basic_block_15/conv2d_39/bias:0' shape=(512,) dtype=float32, numpy=\n",
      "array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0.], dtype=float32)>, <tf.Variable 'basic_block_15/batch_normalization_41/gamma:0' shape=(512,) dtype=float32, numpy=\n",
      "array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1.], dtype=float32)>, <tf.Variable 'basic_block_15/batch_normalization_41/beta:0' shape=(512,) dtype=float32, numpy=\n",
      "array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0.], dtype=float32)>, <tf.Variable 'basic_block_15/batch_normalization_40/moving_mean:0' shape=(512,) dtype=float32, numpy=\n",
      "array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0.], dtype=float32)>, <tf.Variable 'basic_block_15/batch_normalization_40/moving_variance:0' shape=(512,) dtype=float32, numpy=\n",
      "array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1.], dtype=float32)>, <tf.Variable 'basic_block_15/batch_normalization_41/moving_mean:0' shape=(512,) dtype=float32, numpy=\n",
      "array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0.], dtype=float32)>, <tf.Variable 'basic_block_15/batch_normalization_41/moving_variance:0' shape=(512,) dtype=float32, numpy=\n",
      "array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1.], dtype=float32)>, <tf.Variable 'mlp_head_2/dense_4/kernel:0' shape=(512, 512) dtype=float32, numpy=\n",
      "array([[-0.03232576, -0.02002431,  0.01968573, ..., -0.06404427,\n",
      "         0.01885396,  0.06899314],\n",
      "       [ 0.03629794,  0.01279337,  0.00466471, ...,  0.06532878,\n",
      "        -0.0598689 ,  0.04981423],\n",
      "       [ 0.05708411,  0.03414455,  0.03367253, ..., -0.07170365,\n",
      "         0.05819076,  0.06152891],\n",
      "       ...,\n",
      "       [ 0.00396309,  0.01916299,  0.00369618, ..., -0.02449228,\n",
      "        -0.04254583, -0.03739236],\n",
      "       [-0.07435422,  0.00142216,  0.01524566, ...,  0.01455681,\n",
      "        -0.04475335,  0.05112011],\n",
      "       [ 0.01943855, -0.01043712, -0.05150363, ..., -0.01788849,\n",
      "         0.07389008, -0.05851617]], dtype=float32)>, <tf.Variable 'mlp_head_2/dense_4/bias:0' shape=(512,) dtype=float32, numpy=\n",
      "array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0.], dtype=float32)>, <tf.Variable 'mlp_head_2/dense_5/kernel:0' shape=(512, 128) dtype=float32, numpy=\n",
      "array([[-0.06104078,  0.04176198, -0.07932916, ..., -0.07476186,\n",
      "         0.09213717,  0.06153294],\n",
      "       [-0.04221569,  0.02660105, -0.05840175, ..., -0.05159014,\n",
      "        -0.03228672, -0.07404861],\n",
      "       [ 0.08975427, -0.08808448, -0.07675959, ...,  0.04280064,\n",
      "         0.00549152, -0.01596779],\n",
      "       ...,\n",
      "       [ 0.05902906,  0.02576887, -0.05941755, ...,  0.03600286,\n",
      "         0.00185128,  0.05276357],\n",
      "       [ 0.09338759, -0.05195973, -0.0254916 , ..., -0.01613917,\n",
      "        -0.06695041, -0.0570491 ],\n",
      "       [ 0.02598668,  0.0626144 , -0.06673274, ..., -0.05023493,\n",
      "         0.01197378, -0.05875769]], dtype=float32)>, <tf.Variable 'mlp_head_2/batch_normalization_42/moving_mean:0' shape=(512,) dtype=float32, numpy=\n",
      "array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0.], dtype=float32)>, <tf.Variable 'mlp_head_2/batch_normalization_42/moving_variance:0' shape=(512,) dtype=float32, numpy=\n",
      "array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1.], dtype=float32)>]\n",
      "varliables online: \n",
      " "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/5 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[<tf.Variable 'res_net18/conv2d/kernel:0' shape=(7, 7, 3, 64) dtype=float32, numpy=\n",
      "array([[[[ 7.13101402e-03, -1.08212642e-02,  1.75425187e-02, ...,\n",
      "          -3.01801339e-02, -3.75212952e-02,  1.48176067e-02],\n",
      "         [-4.04120386e-02, -3.41520049e-02, -1.55382063e-02, ...,\n",
      "           2.18393765e-02,  2.26096027e-02,  2.23434456e-02],\n",
      "         [-1.96427219e-02,  2.04371326e-02, -1.81615800e-02, ...,\n",
      "           9.32507962e-03, -2.59556733e-02,  3.86325084e-02]],\n",
      "\n",
      "        [[ 3.78599800e-02, -3.02022733e-02,  1.68009736e-02, ...,\n",
      "          -3.21607664e-03, -2.59746723e-02, -2.19756402e-02],\n",
      "         [ 7.17030466e-03, -1.77399572e-02,  3.10802460e-03, ...,\n",
      "          -1.27667766e-02,  4.18871231e-02, -1.65146962e-02],\n",
      "         [-7.09977001e-04, -2.98420079e-02,  1.42942630e-02, ...,\n",
      "          -1.77808851e-03, -1.60246324e-02, -3.42210755e-03]],\n",
      "\n",
      "        [[-1.23124570e-04, -1.88492872e-02, -3.72549556e-02, ...,\n",
      "          -2.63853688e-02,  4.02253829e-02,  2.29878537e-02],\n",
      "         [ 3.64062302e-02,  1.36432387e-02, -3.25683355e-02, ...,\n",
      "          -4.40409407e-03, -3.47604677e-02,  2.56156810e-02],\n",
      "         [-3.88959348e-02,  2.15015076e-02, -6.93776086e-03, ...,\n",
      "          -3.96137834e-02,  3.39317434e-02, -7.21246004e-03]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ 6.67049363e-03,  1.95088126e-02,  3.95760201e-02, ...,\n",
      "           2.50639804e-02,  1.83889642e-02,  2.21824460e-02],\n",
      "         [ 4.13407572e-02,  2.69506015e-02,  3.58489156e-03, ...,\n",
      "           8.39349627e-03,  4.07006107e-02,  1.61308497e-02],\n",
      "         [-2.25098282e-02,  2.64734514e-02,  6.13682717e-03, ...,\n",
      "          -3.65332551e-02, -2.78339162e-02, -2.89794505e-02]],\n",
      "\n",
      "        [[-3.20381671e-03, -2.03635041e-02, -3.95143367e-02, ...,\n",
      "          -3.45325507e-02,  3.66599374e-02,  1.75350159e-02],\n",
      "         [ 2.42412575e-02,  1.95464008e-02, -9.15202126e-03, ...,\n",
      "          -8.50952789e-03,  4.26085331e-02,  1.10792965e-02],\n",
      "         [ 3.94177698e-02,  3.91286947e-02,  3.67498137e-02, ...,\n",
      "          -3.06423008e-03,  3.78266387e-02, -7.86946714e-03]],\n",
      "\n",
      "        [[ 8.76715034e-03, -1.12937763e-02,  9.91707668e-03, ...,\n",
      "          -1.17515326e-02,  1.95387676e-02,  3.78127880e-02],\n",
      "         [ 8.12271982e-03,  3.38196866e-02,  2.33276151e-02, ...,\n",
      "          -4.62096930e-03, -3.96856926e-02,  3.78269888e-02],\n",
      "         [-4.33394685e-03,  4.34827060e-03,  4.24487554e-02, ...,\n",
      "           3.80326696e-02,  1.63070858e-04, -5.50082698e-03]]],\n",
      "\n",
      "\n",
      "       [[[-3.47547494e-02,  3.25202309e-02,  1.28924586e-02, ...,\n",
      "           2.98780166e-02,  3.57940160e-02, -3.72272208e-02],\n",
      "         [ 2.48089246e-02,  2.43487768e-02, -3.13978642e-04, ...,\n",
      "          -2.52195615e-02, -3.08751799e-02,  6.78688288e-03],\n",
      "         [ 2.03377008e-03,  1.03195272e-02,  3.52969654e-02, ...,\n",
      "           2.08835043e-02,  4.18647714e-02, -4.59444895e-03]],\n",
      "\n",
      "        [[-3.59242409e-03,  1.97414644e-02, -1.28405094e-02, ...,\n",
      "           8.91629606e-04, -3.88961919e-02, -2.15766542e-02],\n",
      "         [-2.86231413e-02,  1.70123950e-02,  1.74284428e-02, ...,\n",
      "           2.80150361e-02,  3.01659070e-02,  1.54656917e-03],\n",
      "         [-3.69576514e-02,  1.84608512e-02, -3.45254876e-02, ...,\n",
      "          -1.26429684e-02, -3.55093069e-02, -5.11084124e-03]],\n",
      "\n",
      "        [[ 2.74637975e-02,  2.06986926e-02, -2.53573749e-02, ...,\n",
      "          -7.73933902e-03,  2.98151933e-02, -9.53365862e-03],\n",
      "         [-2.82651801e-02,  6.39904290e-04, -1.68328155e-02, ...,\n",
      "           2.76077650e-02,  2.43809931e-02,  4.06443961e-02],\n",
      "         [-3.99668925e-02,  3.81951444e-02,  2.42319070e-02, ...,\n",
      "          -3.39572467e-02, -3.60467881e-02, -1.62312537e-02]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ 2.76238844e-03,  2.07430534e-02,  4.12101336e-02, ...,\n",
      "           1.67605095e-02,  4.13533561e-02, -1.85114779e-02],\n",
      "         [-1.87202711e-02, -3.04016471e-02, -3.27830836e-02, ...,\n",
      "           1.19394511e-02, -1.42315291e-02,  2.53763422e-03],\n",
      "         [ 2.41053589e-02,  2.82969289e-02, -4.15511318e-02, ...,\n",
      "          -3.01430337e-02,  2.44024880e-02,  3.71855497e-03]],\n",
      "\n",
      "        [[ 1.21732876e-02, -2.02994645e-02,  3.09055559e-02, ...,\n",
      "           6.71332330e-03, -1.03027746e-03, -8.94542783e-04],\n",
      "         [-1.95995364e-02,  4.13375683e-02,  4.01609130e-02, ...,\n",
      "          -1.00411512e-02,  2.23586969e-02, -2.96498910e-02],\n",
      "         [-1.38378441e-02, -1.21142324e-02,  3.90902534e-03, ...,\n",
      "          -9.45233181e-03, -3.54913585e-02,  2.48322003e-02]],\n",
      "\n",
      "        [[-3.24067362e-02, -3.45371999e-02,  3.56788673e-02, ...,\n",
      "           3.92161198e-02, -1.50196329e-02,  2.47762166e-02],\n",
      "         [-6.74628466e-03, -3.98744270e-02,  2.58093216e-02, ...,\n",
      "          -2.04644911e-02,  1.97311491e-03,  1.97267085e-02],\n",
      "         [ 1.27702616e-02, -3.73570248e-02,  4.21535261e-02, ...,\n",
      "           1.69939995e-02,  4.98308614e-03,  3.65407877e-02]]],\n",
      "\n",
      "\n",
      "       [[[-1.53500419e-02,  3.23145427e-02, -2.49542668e-03, ...,\n",
      "           4.22394536e-02,  3.36713679e-02,  1.17104501e-03],\n",
      "         [-1.46855637e-02, -1.17682591e-02,  4.15048338e-02, ...,\n",
      "           1.16125084e-02,  2.75200494e-02,  4.08728085e-02],\n",
      "         [ 8.65544006e-03, -3.64310555e-02,  3.33957039e-02, ...,\n",
      "          -3.33037153e-02, -8.82178545e-04, -4.20036577e-02]],\n",
      "\n",
      "        [[ 2.74350531e-02, -3.64915580e-02,  2.82889605e-03, ...,\n",
      "           3.85234617e-02,  4.10984121e-02,  2.71605588e-02],\n",
      "         [ 2.11940072e-02, -3.56144831e-02, -1.80770829e-02, ...,\n",
      "           4.24862094e-02,  2.56988518e-02, -2.25337092e-02],\n",
      "         [ 1.78068206e-02, -4.07614075e-02,  1.73783489e-02, ...,\n",
      "          -3.12426407e-02,  3.51526849e-02, -3.35757807e-02]],\n",
      "\n",
      "        [[-9.96473804e-03,  3.91022153e-02, -1.03402585e-02, ...,\n",
      "           1.41976587e-02, -1.52285676e-02,  3.40174921e-02],\n",
      "         [-6.30958006e-03, -6.58566132e-03, -3.29612866e-02, ...,\n",
      "          -2.76959315e-03, -3.70432772e-02, -3.61948460e-02],\n",
      "         [ 3.92324440e-02, -1.34930722e-02,  1.07035004e-02, ...,\n",
      "           2.08097510e-02, -8.52647796e-03,  1.28980130e-02]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-3.91051695e-02,  1.57251656e-02,  1.40185170e-02, ...,\n",
      "          -2.85992809e-02, -3.13960873e-02, -3.99553441e-02],\n",
      "         [-5.47215343e-04, -8.39132443e-03,  4.74562496e-03, ...,\n",
      "          -2.75723562e-02, -3.76537181e-02, -2.94637252e-02],\n",
      "         [ 3.41445990e-02,  3.13108675e-02, -3.50412391e-02, ...,\n",
      "          -2.75675133e-02, -2.10919194e-02,  2.59605683e-02]],\n",
      "\n",
      "        [[ 2.43907683e-02,  1.35299899e-02,  3.00194882e-02, ...,\n",
      "          -6.75095618e-03,  3.54271047e-02,  4.12263684e-02],\n",
      "         [-1.29491705e-02,  2.08396278e-02, -3.96805331e-02, ...,\n",
      "           1.48929991e-02,  9.85780731e-03,  3.06779183e-02],\n",
      "         [-2.92295925e-02, -2.46250760e-02, -1.51645187e-02, ...,\n",
      "          -1.56463478e-02,  1.63932443e-02, -3.38301584e-02]],\n",
      "\n",
      "        [[ 3.00400332e-03, -6.74891472e-03, -3.90735082e-02, ...,\n",
      "          -2.47798879e-02, -1.58364177e-02,  4.10443060e-02],\n",
      "         [ 1.58525519e-02, -1.19190868e-02, -2.47765556e-02, ...,\n",
      "          -3.97792794e-02,  8.13473016e-04,  3.26163210e-02],\n",
      "         [ 1.67673193e-02, -2.87776999e-02, -5.87720424e-04, ...,\n",
      "           4.75388020e-03, -5.04392758e-03, -1.42645091e-04]]],\n",
      "\n",
      "\n",
      "       ...,\n",
      "\n",
      "\n",
      "       [[[ 4.20583673e-02,  3.01374756e-02,  1.82637796e-02, ...,\n",
      "          -1.51868910e-02,  2.91640684e-03,  3.89426090e-02],\n",
      "         [-4.03944142e-02, -3.28816436e-02,  4.87981737e-03, ...,\n",
      "          -3.60454433e-02,  1.26602948e-02,  4.24325131e-02],\n",
      "         [ 2.61022635e-02, -1.09476596e-02, -2.83462815e-02, ...,\n",
      "          -1.73107311e-02,  1.50254406e-02, -3.83181535e-02]],\n",
      "\n",
      "        [[-2.45620552e-02, -4.02634442e-02,  4.68438491e-03, ...,\n",
      "           1.88163742e-02,  8.85841623e-03,  1.38776675e-02],\n",
      "         [-4.00706716e-02, -2.26858314e-02,  6.58422709e-03, ...,\n",
      "           9.84834880e-03,  2.99581103e-02,  1.82675198e-02],\n",
      "         [-1.98561102e-02, -2.45682001e-02,  2.10083686e-02, ...,\n",
      "           1.97329447e-02, -4.10844274e-02,  1.05754733e-02]],\n",
      "\n",
      "        [[ 4.01205979e-02,  3.22526433e-02,  3.23281102e-02, ...,\n",
      "           2.88815014e-02,  3.25217359e-02, -3.97448167e-02],\n",
      "         [ 2.04929821e-02, -3.38292718e-02,  9.65131074e-03, ...,\n",
      "          -5.26074320e-03,  2.86822878e-02, -2.93838158e-02],\n",
      "         [ 3.22043039e-02,  8.05434957e-03,  9.03505087e-03, ...,\n",
      "          -4.15183417e-02,  1.98278539e-02,  4.17107157e-02]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-2.64686625e-02,  2.87653469e-02, -7.07453489e-03, ...,\n",
      "          -5.64917922e-04, -2.40542758e-02, -2.97390297e-03],\n",
      "         [-4.10348810e-02, -4.56769392e-03,  3.65203992e-03, ...,\n",
      "           4.80152667e-05,  2.61816494e-02, -3.52828130e-02],\n",
      "         [-1.65748633e-02, -3.08584869e-02,  3.77456732e-02, ...,\n",
      "          -2.99475715e-02,  8.45648348e-03, -1.64087769e-02]],\n",
      "\n",
      "        [[ 2.01938413e-02,  1.89789236e-02,  1.41299516e-03, ...,\n",
      "          -3.13229077e-02,  1.70665383e-02, -8.87246057e-03],\n",
      "         [ 2.90823318e-02,  1.67742372e-02,  1.69162117e-02, ...,\n",
      "           8.68058577e-03,  4.19726595e-03,  1.59534588e-02],\n",
      "         [-4.05622162e-02, -9.96779650e-03,  3.65776941e-03, ...,\n",
      "          -3.82404253e-02,  1.97634585e-02,  3.52151431e-02]],\n",
      "\n",
      "        [[-3.82830426e-02,  3.50902341e-02,  4.17778231e-02, ...,\n",
      "          -1.16743855e-02,  4.09557484e-02, -5.18579781e-03],\n",
      "         [-4.19049934e-02,  3.10807563e-02,  4.95995209e-03, ...,\n",
      "          -3.53952534e-02, -4.73793969e-03, -6.20992854e-03],\n",
      "         [-3.12617198e-02, -3.66645977e-02,  3.04177962e-02, ...,\n",
      "          -9.59615782e-03, -3.61137725e-02, -2.62609292e-02]]],\n",
      "\n",
      "\n",
      "       [[[-2.57520787e-02,  2.27990709e-02, -8.81446525e-03, ...,\n",
      "          -3.23190689e-02,  1.72652826e-02,  2.74502523e-02],\n",
      "         [ 1.86223313e-02,  2.96096690e-02,  2.43938752e-02, ...,\n",
      "           6.35137782e-03,  3.59608866e-02,  3.16688605e-02],\n",
      "         [-2.96862982e-02,  1.99519098e-04, -2.56773382e-02, ...,\n",
      "          -1.45915989e-02,  1.04130954e-02,  1.50018446e-02]],\n",
      "\n",
      "        [[ 4.99289110e-03, -1.28110312e-02,  1.84626840e-02, ...,\n",
      "           1.84294581e-02, -2.07948089e-02, -2.14223303e-02],\n",
      "         [-1.44811329e-02, -1.02497600e-02, -4.26030867e-02, ...,\n",
      "          -8.13426077e-03, -6.07912615e-03, -2.61306893e-02],\n",
      "         [ 2.14198418e-02,  3.89530547e-02,  1.94858275e-02, ...,\n",
      "           3.21563073e-02,  3.43465693e-02, -3.33450660e-02]],\n",
      "\n",
      "        [[-3.80292162e-03,  3.31955031e-03,  3.17107029e-02, ...,\n",
      "          -2.81886347e-02, -3.34584489e-02, -2.76477076e-02],\n",
      "         [ 3.89724337e-02, -9.65673104e-03,  1.11485347e-02, ...,\n",
      "          -4.16816846e-02, -3.07353400e-02,  4.10573073e-02],\n",
      "         [-3.30810286e-02,  3.66631486e-02,  1.59828328e-02, ...,\n",
      "          -1.99782792e-02, -2.96473019e-02, -2.24610791e-03]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ 3.22475471e-02,  4.18080054e-02,  1.14449523e-02, ...,\n",
      "          -3.47400717e-02,  1.54927485e-02,  2.49295793e-02],\n",
      "         [ 9.26967338e-03, -4.07343768e-02, -2.56637204e-02, ...,\n",
      "           8.24218616e-03, -2.28472594e-02, -2.35181097e-02],\n",
      "         [ 2.98406556e-03, -1.27670709e-02,  2.39385329e-02, ...,\n",
      "          -6.21494278e-03,  3.45945321e-02, -9.38831270e-03]],\n",
      "\n",
      "        [[-3.52453440e-02,  2.16765516e-02,  9.06633213e-03, ...,\n",
      "          -1.69636663e-02,  2.93664671e-02,  3.96157689e-02],\n",
      "         [-1.58579126e-02, -3.05471867e-02, -4.23690975e-02, ...,\n",
      "           4.13405336e-02,  3.03107537e-02, -5.41032478e-03],\n",
      "         [-7.34181330e-03, -1.84423216e-02, -1.27516296e-02, ...,\n",
      "           2.13425122e-02,  2.65056677e-02,  1.71017013e-02]],\n",
      "\n",
      "        [[-4.82118875e-03, -1.41834095e-02,  9.71187279e-03, ...,\n",
      "           3.19421403e-02,  1.72721706e-02, -1.29066575e-02],\n",
      "         [-4.68792394e-03, -1.35397855e-02, -7.49890134e-03, ...,\n",
      "          -4.08083834e-02, -2.67106108e-02,  1.63112655e-02],\n",
      "         [-2.24277377e-02,  3.82437222e-02, -1.56593025e-02, ...,\n",
      "          -2.18373686e-02, -1.06787831e-02,  7.38304108e-04]]],\n",
      "\n",
      "\n",
      "       [[[-2.91132778e-02, -3.21103893e-02,  1.44388042e-02, ...,\n",
      "          -3.73977832e-02, -2.05862802e-02,  2.33266838e-02],\n",
      "         [-3.31146866e-02, -6.84726238e-03,  1.01052709e-02, ...,\n",
      "           3.52157243e-02,  2.19117440e-02, -2.12329235e-02],\n",
      "         [ 5.04934788e-03, -1.68675203e-02,  3.03108655e-02, ...,\n",
      "           1.97397023e-02, -9.39945132e-03, -3.38008255e-03]],\n",
      "\n",
      "        [[-5.84701449e-03,  2.01883540e-03, -5.43106347e-04, ...,\n",
      "           3.31467278e-02,  2.97410823e-02, -4.11931425e-03],\n",
      "         [ 3.02150436e-02, -1.73606426e-02,  3.72378044e-02, ...,\n",
      "          -3.86786126e-02,  1.32307485e-02,  4.16639186e-02],\n",
      "         [-3.47952619e-02,  1.80612653e-02,  2.44711339e-03, ...,\n",
      "           1.23071298e-03,  1.52795315e-02, -1.45289246e-02]],\n",
      "\n",
      "        [[-2.42348462e-02, -1.92057900e-02, -2.41175704e-02, ...,\n",
      "          -4.23555821e-02,  1.21538490e-02, -4.06973958e-02],\n",
      "         [ 4.13807742e-02,  5.41315973e-03,  2.28532963e-02, ...,\n",
      "          -1.05655156e-02, -2.46428717e-02,  9.04703885e-03],\n",
      "         [ 1.41743682e-02, -2.73071565e-02, -1.40941124e-02, ...,\n",
      "           3.83207835e-02, -9.53525677e-03, -9.42527130e-03]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ 3.44715379e-02,  2.46890299e-02, -3.17989886e-02, ...,\n",
      "          -4.16075364e-02, -3.75229456e-02,  1.04505718e-02],\n",
      "         [-2.28275172e-02,  3.59973721e-02, -1.44186635e-02, ...,\n",
      "          -3.55098881e-02,  8.43284652e-03, -3.21464390e-02],\n",
      "         [-1.93996299e-02, -1.02542713e-03, -7.00398162e-03, ...,\n",
      "          -1.21190846e-02,  1.91750303e-02, -2.46285405e-02]],\n",
      "\n",
      "        [[-2.46425048e-02, -5.32234460e-03, -4.09885868e-02, ...,\n",
      "           2.52022855e-02,  1.40943788e-02, -3.54728512e-02],\n",
      "         [ 2.45294161e-02, -4.10618000e-02, -1.66610610e-02, ...,\n",
      "           1.56642646e-02, -1.58044137e-02, -2.16169953e-02],\n",
      "         [-2.59972699e-02, -3.97078991e-02,  3.43767516e-02, ...,\n",
      "          -3.59548852e-02, -1.56261027e-03, -1.02698803e-02]],\n",
      "\n",
      "        [[ 1.73656568e-02,  2.76894122e-03, -1.35305095e-02, ...,\n",
      "          -2.93505676e-02,  2.94069834e-02,  2.62025036e-02],\n",
      "         [-3.25824730e-02, -4.04176340e-02,  3.73083316e-02, ...,\n",
      "           3.80438976e-02, -2.20599007e-02, -3.34370025e-02],\n",
      "         [-5.04342839e-03,  5.85555285e-03, -3.52551900e-02, ...,\n",
      "          -1.87125057e-03,  1.88130885e-03, -8.27860460e-03]]]],\n",
      "      dtype=float32)>, <tf.Variable 'res_net18/conv2d/bias:0' shape=(64,) dtype=float32, numpy=\n",
      "array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32)>, <tf.Variable 'res_net18/batch_normalization/gamma:0' shape=(64,) dtype=float32, numpy=\n",
      "array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32)>, <tf.Variable 'res_net18/batch_normalization/beta:0' shape=(64,) dtype=float32, numpy=\n",
      "array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32)>, <tf.Variable 'res_net18/batch_normalization/moving_mean:0' shape=(64,) dtype=float32, numpy=\n",
      "array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32)>, <tf.Variable 'res_net18/batch_normalization/moving_variance:0' shape=(64,) dtype=float32, numpy=\n",
      "array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32)>, <tf.Variable 'basic_block/conv2d_1/kernel:0' shape=(3, 3, 64, 64) dtype=float32, numpy=\n",
      "array([[[[ 0.03188237, -0.01184898,  0.03633366, ...,  0.06557354,\n",
      "           0.04352143, -0.04578689],\n",
      "         [-0.03434483, -0.05072434,  0.04377227, ..., -0.00048555,\n",
      "          -0.05085438, -0.03737141],\n",
      "         [ 0.0637745 , -0.05295659, -0.06666687, ...,  0.06121331,\n",
      "           0.00609913,  0.07172897],\n",
      "         ...,\n",
      "         [-0.04543198, -0.02610337,  0.00839263, ..., -0.02035102,\n",
      "           0.04619119,  0.03597544],\n",
      "         [ 0.04555253, -0.07039971,  0.01073167, ..., -0.06696323,\n",
      "           0.03427211,  0.00906362],\n",
      "         [-0.00208122,  0.00407662,  0.06042498, ..., -0.01971065,\n",
      "           0.03613894, -0.02940864]],\n",
      "\n",
      "        [[-0.04789992, -0.06970302, -0.05171277, ..., -0.06315046,\n",
      "           0.00264199, -0.05041125],\n",
      "         [ 0.05483875,  0.03474639,  0.06844357, ..., -0.06352399,\n",
      "          -0.06935043, -0.0222231 ],\n",
      "         [-0.0186438 , -0.02231061, -0.02026595, ...,  0.04331838,\n",
      "           0.05220071, -0.0026801 ],\n",
      "         ...,\n",
      "         [-0.01238567,  0.03065194,  0.03399953, ..., -0.03541248,\n",
      "           0.04816183, -0.0389779 ],\n",
      "         [-0.00960816,  0.02032517,  0.02346531, ...,  0.01757394,\n",
      "           0.02463043,  0.06198379],\n",
      "         [ 0.06237508,  0.06473072,  0.04130813, ..., -0.03092922,\n",
      "          -0.03245939, -0.00359064]],\n",
      "\n",
      "        [[ 0.02779134,  0.04073782, -0.01635824, ..., -0.05320329,\n",
      "          -0.03286043,  0.04566346],\n",
      "         [ 0.01266902, -0.02439015,  0.02116392, ..., -0.00227128,\n",
      "          -0.0189181 ,  0.04445118],\n",
      "         [-0.03481153, -0.01487951,  0.04090691, ..., -0.07121808,\n",
      "          -0.03974846, -0.06446927],\n",
      "         ...,\n",
      "         [-0.0425065 , -0.03534478,  0.01868758, ..., -0.00133537,\n",
      "           0.00519171, -0.02563706],\n",
      "         [-0.06432956,  0.02672318,  0.00813884, ...,  0.06690302,\n",
      "          -0.00099684, -0.06590821],\n",
      "         [ 0.03181268, -0.04493169,  0.03578318, ..., -0.00337818,\n",
      "          -0.01886236, -0.03375258]]],\n",
      "\n",
      "\n",
      "       [[[ 0.03134749, -0.06426398, -0.00349324, ..., -0.06777919,\n",
      "           0.03424277,  0.03576305],\n",
      "         [-0.009446  , -0.0563124 , -0.06827407, ...,  0.01411963,\n",
      "          -0.02049565,  0.01096662],\n",
      "         [-0.01600143,  0.0602378 , -0.03220103, ..., -0.06905281,\n",
      "           0.06833689, -0.04918579],\n",
      "         ...,\n",
      "         [ 0.07114193, -0.01480609, -0.03328829, ...,  0.01246761,\n",
      "           0.06828518, -0.03187442],\n",
      "         [-0.03368183, -0.06276689,  0.07213151, ...,  0.03570514,\n",
      "           0.05923511, -0.01329606],\n",
      "         [-0.04644375, -0.01856035, -0.05816742, ...,  0.03194276,\n",
      "          -0.03143187, -0.06234554]],\n",
      "\n",
      "        [[-0.03167101, -0.00447283, -0.03334682, ...,  0.03152134,\n",
      "          -0.05942725,  0.01791303],\n",
      "         [-0.04262858, -0.04115019, -0.05992891, ...,  0.06508762,\n",
      "          -0.01501799, -0.01440616],\n",
      "         [ 0.04628134,  0.04568946, -0.05993033, ...,  0.01448533,\n",
      "           0.03154533,  0.04930185],\n",
      "         ...,\n",
      "         [-0.02955399,  0.04990347,  0.01036745, ..., -0.01697335,\n",
      "          -0.05064768,  0.02518456],\n",
      "         [-0.04532274,  0.05133656, -0.00151125, ...,  0.03612037,\n",
      "          -0.05938819,  0.04150094],\n",
      "         [-0.04888341,  0.07210228, -0.04138231, ..., -0.06860752,\n",
      "          -0.05198799,  0.01529864]],\n",
      "\n",
      "        [[ 0.05327812,  0.03392842, -0.04724932, ...,  0.01422386,\n",
      "          -0.01681075, -0.07102335],\n",
      "         [-0.06496196, -0.05523865,  0.01889043, ..., -0.05475254,\n",
      "           0.03164406, -0.0550833 ],\n",
      "         [ 0.03341345,  0.00569431, -0.03659551, ...,  0.00697476,\n",
      "          -0.05193584,  0.01282337],\n",
      "         ...,\n",
      "         [ 0.03730759, -0.00955885,  0.03008057, ..., -0.053897  ,\n",
      "           0.05333489, -0.06142264],\n",
      "         [ 0.0247484 ,  0.03899428,  0.05239651, ..., -0.07000162,\n",
      "           0.04642285,  0.01835819],\n",
      "         [-0.04324006, -0.03327622,  0.06023176, ..., -0.06302975,\n",
      "          -0.02319795, -0.06903116]]],\n",
      "\n",
      "\n",
      "       [[[-0.00206733,  0.042668  ,  0.03613979, ..., -0.0702662 ,\n",
      "          -0.02847423, -0.02892   ],\n",
      "         [ 0.06938988, -0.00752318,  0.04015902, ...,  0.01979683,\n",
      "           0.0604898 , -0.03723732],\n",
      "         [ 0.0604613 ,  0.05616152,  0.05488183, ..., -0.06360926,\n",
      "           0.03456717,  0.03679504],\n",
      "         ...,\n",
      "         [ 0.0173947 ,  0.04678375,  0.06880625, ...,  0.00412358,\n",
      "           0.03796763,  0.03451897],\n",
      "         [-0.06791533, -0.04845316,  0.00501835, ...,  0.0370845 ,\n",
      "          -0.06388474,  0.04739459],\n",
      "         [ 0.00368172, -0.02543793,  0.00846999, ..., -0.06311176,\n",
      "          -0.02027851, -0.00702044]],\n",
      "\n",
      "        [[ 0.00809792, -0.06764693, -0.0541461 , ...,  0.03459697,\n",
      "           0.03045682,  0.01263657],\n",
      "         [ 0.00952865, -0.01990645, -0.0057599 , ..., -0.01989983,\n",
      "           0.05929644, -0.0510282 ],\n",
      "         [-0.00519982,  0.01753927,  0.0496452 , ...,  0.03796431,\n",
      "          -0.05582481, -0.03743065],\n",
      "         ...,\n",
      "         [ 0.00375799,  0.04007786, -0.01016537, ...,  0.03131251,\n",
      "          -0.02712704,  0.06453201],\n",
      "         [ 0.04551429,  0.05723648,  0.04988115, ..., -0.05739293,\n",
      "          -0.01181335,  0.0061248 ],\n",
      "         [ 0.06195243,  0.0364323 ,  0.05300748, ..., -0.02957986,\n",
      "           0.01858884, -0.07088429]],\n",
      "\n",
      "        [[-0.03458146,  0.00880421, -0.0381004 , ..., -0.06834815,\n",
      "          -0.06905575,  0.04359678],\n",
      "         [-0.04871365, -0.03553712,  0.05073984, ..., -0.02400916,\n",
      "           0.04477609, -0.04755413],\n",
      "         [-0.06121831,  0.01436975, -0.05968643, ..., -0.04476752,\n",
      "           0.06981342,  0.00591695],\n",
      "         ...,\n",
      "         [-0.0398477 , -0.00559504, -0.01607428, ...,  0.06665234,\n",
      "          -0.01371044, -0.04718732],\n",
      "         [ 0.05751984,  0.03101181, -0.07113325, ...,  0.01259636,\n",
      "          -0.05057906, -0.02689142],\n",
      "         [-0.06717899, -0.02925926, -0.00077871, ...,  0.04639722,\n",
      "           0.0713532 ,  0.026467  ]]]], dtype=float32)>, <tf.Variable 'basic_block/conv2d_1/bias:0' shape=(64,) dtype=float32, numpy=\n",
      "array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32)>, <tf.Variable 'basic_block/batch_normalization_1/gamma:0' shape=(64,) dtype=float32, numpy=\n",
      "array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32)>, <tf.Variable 'basic_block/batch_normalization_1/beta:0' shape=(64,) dtype=float32, numpy=\n",
      "array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32)>, <tf.Variable 'basic_block/conv2d_2/kernel:0' shape=(3, 3, 64, 64) dtype=float32, numpy=\n",
      "array([[[[ 5.97504675e-02,  6.47657663e-02, -1.08118355e-03, ...,\n",
      "          -5.38331121e-02,  2.67343968e-02,  1.44158676e-02],\n",
      "         [-6.37892038e-02, -5.80204278e-03,  2.47601420e-03, ...,\n",
      "          -9.84862074e-03,  1.72681659e-02, -5.64349964e-02],\n",
      "         [-2.22854428e-02, -8.07227194e-03,  4.05529216e-02, ...,\n",
      "           1.95617974e-02,  6.54792339e-02, -5.80234192e-02],\n",
      "         ...,\n",
      "         [ 2.53752246e-02,  5.64838797e-02, -3.79882753e-03, ...,\n",
      "           7.01712966e-02,  5.69178909e-02, -6.10781014e-02],\n",
      "         [ 5.01573011e-02,  3.54021788e-04, -4.02863957e-02, ...,\n",
      "           5.32608479e-02, -4.10737097e-02, -7.16603696e-02],\n",
      "         [ 2.60655284e-02, -3.26180123e-02,  3.21391225e-03, ...,\n",
      "           2.84250751e-02,  5.25161400e-02,  2.19228044e-02]],\n",
      "\n",
      "        [[ 3.45142409e-02, -6.89467192e-02, -3.71854976e-02, ...,\n",
      "          -8.99428874e-03, -3.37532535e-02, -2.66111791e-02],\n",
      "         [-2.85328887e-02,  7.14895129e-02,  1.61570683e-02, ...,\n",
      "           4.97563928e-03,  5.24090827e-02, -6.49798363e-02],\n",
      "         [ 5.23565486e-02, -3.56950127e-02,  1.43447891e-02, ...,\n",
      "          -1.51744485e-03,  4.37173471e-02,  6.55339509e-02],\n",
      "         ...,\n",
      "         [-4.18214276e-02, -3.67588624e-02,  4.74131554e-02, ...,\n",
      "           2.52979025e-02,  4.45466414e-02,  6.51104152e-02],\n",
      "         [-5.54255843e-02,  5.79089075e-02,  2.86364928e-02, ...,\n",
      "           5.60357720e-02,  1.90973803e-02,  6.71538413e-02],\n",
      "         [ 5.48384339e-02,  1.80242509e-02,  1.76915824e-02, ...,\n",
      "          -6.57151714e-02, -5.81048727e-02, -3.50382775e-02]],\n",
      "\n",
      "        [[ 3.56713682e-02,  6.89953715e-02, -1.09272040e-02, ...,\n",
      "           1.34269968e-02, -6.18048981e-02, -9.29727405e-03],\n",
      "         [-2.77821757e-02,  2.50900313e-02,  3.42032835e-02, ...,\n",
      "          -2.21723132e-02, -1.59306638e-02, -5.89452498e-02],\n",
      "         [ 1.88943446e-02,  4.36130390e-02, -3.29830498e-03, ...,\n",
      "          -2.00497359e-03,  2.38227844e-02, -5.97439706e-03],\n",
      "         ...,\n",
      "         [-2.85321847e-02, -2.62727961e-02,  3.95374894e-02, ...,\n",
      "          -1.95904821e-03, -6.42775223e-02,  3.40791047e-03],\n",
      "         [ 2.35633254e-02, -2.90531069e-02,  3.91766354e-02, ...,\n",
      "          -9.37092304e-03,  5.77586740e-02,  2.63187215e-02],\n",
      "         [ 3.53716314e-02, -1.94469914e-02,  3.08324024e-02, ...,\n",
      "           4.31083441e-02, -2.22743787e-02,  4.44380566e-02]]],\n",
      "\n",
      "\n",
      "       [[[ 6.79712445e-02,  6.65895790e-02,  5.04425615e-02, ...,\n",
      "           2.00315267e-02,  2.40755752e-02,  5.85777462e-02],\n",
      "         [-3.01851332e-03,  3.63481492e-02, -3.13675366e-02, ...,\n",
      "          -2.86144130e-02, -5.86460494e-02,  5.10054529e-02],\n",
      "         [-4.47027571e-02,  2.61698142e-02,  6.99983686e-02, ...,\n",
      "           5.42322546e-03,  3.76576707e-02,  5.85136265e-02],\n",
      "         ...,\n",
      "         [ 9.10001993e-03, -1.99017562e-02, -5.19912913e-02, ...,\n",
      "           2.04170570e-02, -5.31648546e-02, -1.99021697e-02],\n",
      "         [-1.24536827e-02,  6.09201938e-03,  2.39487663e-02, ...,\n",
      "           3.84063423e-02,  3.41031104e-02, -2.68794596e-03],\n",
      "         [ 5.12343645e-03,  1.52982622e-02, -2.43325382e-02, ...,\n",
      "          -6.70766234e-02,  4.45029885e-02, -4.89342511e-02]],\n",
      "\n",
      "        [[ 6.96679950e-02,  2.57332548e-02, -4.40470576e-02, ...,\n",
      "           4.39991355e-02, -4.28769514e-02,  1.91264749e-02],\n",
      "         [-7.02977628e-02,  3.32309678e-02,  2.99153849e-02, ...,\n",
      "          -2.58323997e-02,  9.91506875e-03, -5.10904193e-03],\n",
      "         [-6.59368932e-04,  6.13646507e-02,  8.08035582e-03, ...,\n",
      "           3.84926796e-02,  2.03318298e-02,  4.08569723e-02],\n",
      "         ...,\n",
      "         [ 3.37374434e-02,  3.97381485e-02,  6.19855672e-02, ...,\n",
      "           2.26866603e-02,  3.47320735e-02, -4.78226319e-02],\n",
      "         [-2.39954665e-02, -5.68060651e-02,  1.89714059e-02, ...,\n",
      "          -6.75744042e-02, -1.20012090e-02,  7.10695386e-02],\n",
      "         [-5.20436466e-03, -6.99305907e-02,  4.02046964e-02, ...,\n",
      "          -3.66088934e-02, -2.76962295e-02,  3.33099812e-02]],\n",
      "\n",
      "        [[-5.42603657e-02, -7.14486092e-02,  5.76258451e-02, ...,\n",
      "          -6.64364249e-02,  1.25327483e-02,  4.65733111e-02],\n",
      "         [ 5.61666787e-02, -1.27654634e-02, -6.47531077e-02, ...,\n",
      "          -1.99473202e-02, -3.08298916e-02,  2.41031274e-02],\n",
      "         [-1.09709799e-04, -4.88249958e-03, -3.44917700e-02, ...,\n",
      "           2.34737173e-02,  2.15395615e-02, -5.90516701e-02],\n",
      "         ...,\n",
      "         [ 4.92919758e-02, -4.74757552e-02,  8.30433518e-03, ...,\n",
      "           5.01750559e-02,  6.15058690e-02, -3.76700088e-02],\n",
      "         [-1.39899552e-03, -4.49770242e-02,  4.95060682e-02, ...,\n",
      "           5.80224097e-02,  1.27790719e-02, -1.55010819e-03],\n",
      "         [-5.90757094e-02, -1.65548772e-02,  3.72934490e-02, ...,\n",
      "           3.45483422e-03, -3.91559377e-02, -2.39577889e-03]]],\n",
      "\n",
      "\n",
      "       [[[ 1.33677199e-02,  5.75567484e-02, -1.79484487e-05, ...,\n",
      "          -1.35268122e-02,  1.51555315e-02,  2.10702121e-02],\n",
      "         [-5.24040908e-02,  5.76164722e-02,  5.98993748e-02, ...,\n",
      "          -1.79165192e-02,  6.64268583e-02,  4.06569242e-03],\n",
      "         [-3.90011817e-02,  5.90511858e-02, -4.65580150e-02, ...,\n",
      "          -2.27557458e-02,  2.67001987e-03,  3.51961255e-02],\n",
      "         ...,\n",
      "         [-6.13918230e-02,  6.58679754e-02,  6.72581345e-02, ...,\n",
      "           1.82069987e-02, -2.54035667e-02,  3.54499072e-02],\n",
      "         [ 6.68664426e-02,  9.06167179e-03, -6.61321655e-02, ...,\n",
      "          -4.39918749e-02,  4.17275131e-02, -2.43786350e-02],\n",
      "         [-7.01240450e-03, -7.85127282e-04, -3.61758433e-02, ...,\n",
      "          -6.68075681e-03,  1.09565258e-02,  6.60061687e-02]],\n",
      "\n",
      "        [[ 6.59274161e-02, -2.60821693e-02,  6.49233758e-02, ...,\n",
      "           6.23051375e-02, -5.59181646e-02, -4.74618152e-02],\n",
      "         [ 2.27598026e-02, -2.03851201e-02, -5.59596866e-02, ...,\n",
      "           1.96636766e-02,  4.69048619e-02, -1.75259188e-02],\n",
      "         [ 1.01302043e-02,  3.19002569e-03, -5.61115146e-03, ...,\n",
      "          -1.08655356e-02, -1.01151839e-02, -4.63460386e-03],\n",
      "         ...,\n",
      "         [ 3.94691452e-02, -5.97550683e-02,  3.41080353e-02, ...,\n",
      "           4.13535163e-02,  5.33306599e-02, -8.02841038e-03],\n",
      "         [ 1.64640769e-02, -5.36207855e-02,  2.11972073e-02, ...,\n",
      "           3.85064632e-03,  6.35946840e-02,  3.95145863e-02],\n",
      "         [ 8.09410214e-03,  5.50705940e-03,  3.36802825e-02, ...,\n",
      "           3.69877741e-02,  1.61191970e-02, -4.48017791e-02]],\n",
      "\n",
      "        [[-1.07460730e-02, -1.67183205e-02, -2.38120556e-05, ...,\n",
      "           4.69904840e-02,  2.13391632e-02, -1.76278315e-02],\n",
      "         [-4.90954444e-02,  4.18115482e-02,  2.21799687e-02, ...,\n",
      "           4.40006852e-02,  3.86337712e-02,  1.22918934e-03],\n",
      "         [-4.77937460e-02, -1.63715780e-02,  6.88092411e-02, ...,\n",
      "          -5.08074425e-02,  6.03589714e-02,  5.86237311e-02],\n",
      "         ...,\n",
      "         [-1.06850751e-02,  5.34343123e-02,  6.39038086e-02, ...,\n",
      "           1.14696994e-02,  1.36758685e-02,  2.04989538e-02],\n",
      "         [ 4.73245978e-04,  3.85121107e-02, -4.26261872e-02, ...,\n",
      "           4.78745624e-02, -3.88380140e-02,  4.86207753e-03],\n",
      "         [-1.05293058e-02,  6.91453516e-02, -4.50744331e-02, ...,\n",
      "          -4.58855405e-02, -3.72324176e-02,  3.37342098e-02]]]],\n",
      "      dtype=float32)>, <tf.Variable 'basic_block/conv2d_2/bias:0' shape=(64,) dtype=float32, numpy=\n",
      "array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32)>, <tf.Variable 'basic_block/batch_normalization_2/gamma:0' shape=(64,) dtype=float32, numpy=\n",
      "array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32)>, <tf.Variable 'basic_block/batch_normalization_2/beta:0' shape=(64,) dtype=float32, numpy=\n",
      "array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32)>, <tf.Variable 'basic_block/batch_normalization_1/moving_mean:0' shape=(64,) dtype=float32, numpy=\n",
      "array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32)>, <tf.Variable 'basic_block/batch_normalization_1/moving_variance:0' shape=(64,) dtype=float32, numpy=\n",
      "array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32)>, <tf.Variable 'basic_block/batch_normalization_2/moving_mean:0' shape=(64,) dtype=float32, numpy=\n",
      "array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32)>, <tf.Variable 'basic_block/batch_normalization_2/moving_variance:0' shape=(64,) dtype=float32, numpy=\n",
      "array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32)>, <tf.Variable 'basic_block_1/conv2d_3/kernel:0' shape=(3, 3, 64, 64) dtype=float32, numpy=\n",
      "array([[[[-0.06832818, -0.00826627,  0.06778559, ..., -0.06955147,\n",
      "           0.04609822, -0.063101  ],\n",
      "         [-0.05120016, -0.00954285, -0.06408378, ..., -0.03804749,\n",
      "          -0.03378965, -0.05876379],\n",
      "         [-0.02345393,  0.05744116,  0.01459698, ...,  0.0219897 ,\n",
      "          -0.07179452,  0.05771643],\n",
      "         ...,\n",
      "         [ 0.03275957,  0.05022497, -0.03093665, ..., -0.02174666,\n",
      "          -0.01771304, -0.02864406],\n",
      "         [-0.02797114, -0.00706826,  0.04202949, ..., -0.04398385,\n",
      "           0.03916745, -0.04099907],\n",
      "         [ 0.01564531, -0.05741399, -0.02250677, ...,  0.07010834,\n",
      "           0.04114663, -0.02365547]],\n",
      "\n",
      "        [[ 0.01158568,  0.06398113, -0.06658573, ..., -0.06880561,\n",
      "          -0.00778946,  0.05693668],\n",
      "         [-0.00767279, -0.01475077, -0.05740457, ..., -0.02383092,\n",
      "           0.06420881, -0.0110101 ],\n",
      "         [ 0.00463874,  0.03316634,  0.06345865, ..., -0.05942477,\n",
      "           0.03077868,  0.06308867],\n",
      "         ...,\n",
      "         [-0.06872109,  0.00897049,  0.05737659, ...,  0.04892959,\n",
      "          -0.01932467, -0.01422599],\n",
      "         [-0.02690966, -0.01686647, -0.0611324 , ...,  0.04414023,\n",
      "          -0.02551868, -0.04351684],\n",
      "         [ 0.00073958,  0.00649286,  0.01234945, ...,  0.01459689,\n",
      "           0.06420559, -0.04846832]],\n",
      "\n",
      "        [[ 0.06251822,  0.01770261, -0.02324274, ...,  0.03291869,\n",
      "          -0.02345752,  0.03278208],\n",
      "         [-0.02839188, -0.00523227,  0.03936251, ..., -0.04973073,\n",
      "           0.03312682,  0.05955178],\n",
      "         [-0.06645206,  0.04463165, -0.00231978, ...,  0.0316733 ,\n",
      "           0.00012545,  0.05366719],\n",
      "         ...,\n",
      "         [-0.03929276,  0.04822987, -0.00117329, ..., -0.05098568,\n",
      "           0.00532006, -0.0368626 ],\n",
      "         [ 0.02187528,  0.03192063,  0.02872843, ...,  0.04957185,\n",
      "          -0.06917537,  0.06648748],\n",
      "         [-0.05679972, -0.01406745,  0.04279892, ...,  0.02488708,\n",
      "          -0.01665254, -0.00952304]]],\n",
      "\n",
      "\n",
      "       [[[-0.02651723, -0.02123317, -0.01214641, ..., -0.05563226,\n",
      "          -0.01406012, -0.01660106],\n",
      "         [ 0.03581958, -0.02484861, -0.05538955, ...,  0.02188957,\n",
      "          -0.05959223,  0.01320177],\n",
      "         [ 0.06379017, -0.06949985, -0.05707636, ..., -0.05887209,\n",
      "          -0.0553332 , -0.05171157],\n",
      "         ...,\n",
      "         [ 0.05884925, -0.05971586,  0.04527332, ..., -0.06634537,\n",
      "          -0.01652841,  0.04664808],\n",
      "         [ 0.0020372 , -0.06961033,  0.00864748, ..., -0.02573513,\n",
      "          -0.06234437, -0.02164821],\n",
      "         [ 0.04754871,  0.02459325, -0.05891722, ..., -0.04268324,\n",
      "          -0.04958555,  0.01779253]],\n",
      "\n",
      "        [[-0.05900976, -0.05961322,  0.03392144, ...,  0.01049684,\n",
      "           0.03998095, -0.01700843],\n",
      "         [ 0.02164817,  0.05955769,  0.04352944, ..., -0.02813298,\n",
      "           0.01735628,  0.01905152],\n",
      "         [ 0.05408661, -0.05621902, -0.00567479, ...,  0.05222683,\n",
      "          -0.05571565, -0.05883272],\n",
      "         ...,\n",
      "         [-0.00318117, -0.05875082, -0.03113551, ..., -0.02193541,\n",
      "          -0.00968759,  0.03452314],\n",
      "         [ 0.0091455 ,  0.00105659,  0.05570017, ..., -0.05867511,\n",
      "           0.03452424,  0.02608883],\n",
      "         [ 0.05664781,  0.01437596, -0.0256794 , ..., -0.02627006,\n",
      "          -0.01720905, -0.03666   ]],\n",
      "\n",
      "        [[-0.05861279,  0.00337018, -0.06653799, ...,  0.00498269,\n",
      "          -0.06180641,  0.06834915],\n",
      "         [-0.00953588,  0.02968495,  0.00900505, ..., -0.06235774,\n",
      "           0.05803846,  0.04727612],\n",
      "         [ 0.00950496, -0.03169957,  0.0203546 , ..., -0.00412812,\n",
      "          -0.06350697, -0.02962537],\n",
      "         ...,\n",
      "         [-0.02620284,  0.0440564 , -0.04329624, ...,  0.02015168,\n",
      "           0.06363122,  0.01493947],\n",
      "         [-0.02676082, -0.03735968, -0.0562385 , ...,  0.01576858,\n",
      "          -0.0333078 ,  0.02525581],\n",
      "         [ 0.01551511,  0.07134625,  0.05773401, ...,  0.01616871,\n",
      "          -0.03493736, -0.06684226]]],\n",
      "\n",
      "\n",
      "       [[[ 0.03950807,  0.01151958, -0.03463116, ..., -0.03645868,\n",
      "           0.06805409, -0.04487035],\n",
      "         [ 0.01581749,  0.02599865,  0.0503975 , ..., -0.02104581,\n",
      "           0.05289385,  0.01304672],\n",
      "         [-0.02952341,  0.01268324, -0.02260564, ...,  0.01169127,\n",
      "           0.00795443,  0.05171487],\n",
      "         ...,\n",
      "         [-0.06699582, -0.00356817,  0.03385957, ...,  0.036337  ,\n",
      "          -0.00761164, -0.02423754],\n",
      "         [ 0.0252197 ,  0.01206709,  0.05317925, ...,  0.04025718,\n",
      "           0.03748131, -0.06215925],\n",
      "         [ 0.05499569, -0.03569334, -0.04106171, ..., -0.06780759,\n",
      "           0.02669811,  0.00643893]],\n",
      "\n",
      "        [[ 0.06051973, -0.04936704,  0.0101348 , ..., -0.04574636,\n",
      "          -0.06428706,  0.05092008],\n",
      "         [ 0.02591972,  0.00759409,  0.00071226, ...,  0.00616886,\n",
      "          -0.06964681, -0.03428065],\n",
      "         [-0.03335228,  0.00315897,  0.03859883, ..., -0.03543208,\n",
      "           0.04360545, -0.02118399],\n",
      "         ...,\n",
      "         [-0.05891471, -0.04824718, -0.0148787 , ...,  0.06577039,\n",
      "           0.05373263,  0.00037376],\n",
      "         [-0.00403608,  0.02017254, -0.05910604, ..., -0.01532753,\n",
      "          -0.01395857,  0.02480061],\n",
      "         [-0.02206063,  0.02353057, -0.01003313, ...,  0.03872698,\n",
      "          -0.04850533,  0.04458045]],\n",
      "\n",
      "        [[-0.05606413,  0.05991969,  0.0683167 , ...,  0.0096259 ,\n",
      "          -0.00254565, -0.05823041],\n",
      "         [ 0.01190709,  0.06301269, -0.03667996, ..., -0.00535966,\n",
      "          -0.05371492,  0.05966792],\n",
      "         [ 0.03104948, -0.01783099,  0.01379914, ...,  0.00147686,\n",
      "          -0.06177016, -0.03285121],\n",
      "         ...,\n",
      "         [-0.06310648,  0.06843553, -0.06809003, ..., -0.0107858 ,\n",
      "           0.06070383,  0.00723523],\n",
      "         [ 0.03782433,  0.04826666, -0.02739809, ...,  0.03390859,\n",
      "           0.04388165,  0.02319222],\n",
      "         [ 0.03657954, -0.04758018, -0.02359702, ...,  0.04183826,\n",
      "           0.05032021, -0.03350156]]]], dtype=float32)>, <tf.Variable 'basic_block_1/conv2d_3/bias:0' shape=(64,) dtype=float32, numpy=\n",
      "array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32)>, <tf.Variable 'basic_block_1/batch_normalization_3/gamma:0' shape=(64,) dtype=float32, numpy=\n",
      "array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32)>, <tf.Variable 'basic_block_1/batch_normalization_3/beta:0' shape=(64,) dtype=float32, numpy=\n",
      "array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32)>, <tf.Variable 'basic_block_1/conv2d_4/kernel:0' shape=(3, 3, 64, 64) dtype=float32, numpy=\n",
      "array([[[[ 0.06724288,  0.05753542, -0.03081621, ..., -0.05468142,\n",
      "          -0.01737431, -0.00232568],\n",
      "         [-0.03671113, -0.01954997,  0.05970572, ..., -0.0378653 ,\n",
      "           0.01757175,  0.00420479],\n",
      "         [ 0.01571354, -0.0554186 , -0.02348221, ...,  0.05157933,\n",
      "          -0.03061577, -0.07104892],\n",
      "         ...,\n",
      "         [-0.01628284,  0.04251786, -0.00553622, ...,  0.06899668,\n",
      "           0.01597845, -0.0136307 ],\n",
      "         [-0.02211405,  0.01832639,  0.02094915, ..., -0.01921016,\n",
      "          -0.0407561 , -0.02027823],\n",
      "         [ 0.01469163, -0.02303991, -0.0698536 , ..., -0.01159196,\n",
      "          -0.03610712,  0.03122727]],\n",
      "\n",
      "        [[-0.04273201, -0.04137172,  0.0530576 , ..., -0.03174019,\n",
      "          -0.06977557,  0.04563697],\n",
      "         [ 0.0238682 , -0.06329545,  0.03671347, ...,  0.05500224,\n",
      "           0.01932576,  0.0513508 ],\n",
      "         [ 0.02222925, -0.01902004,  0.06997815, ...,  0.01344077,\n",
      "          -0.03682514,  0.05356461],\n",
      "         ...,\n",
      "         [ 0.06897643, -0.01867864, -0.01742368, ..., -0.06692789,\n",
      "          -0.0064913 ,  0.0141945 ],\n",
      "         [-0.06541474, -0.02875072, -0.03406163, ...,  0.05779214,\n",
      "          -0.02537537,  0.05497144],\n",
      "         [-0.07088152,  0.07015499,  0.0572567 , ..., -0.05873557,\n",
      "          -0.04274555, -0.00082835]],\n",
      "\n",
      "        [[ 0.01571123, -0.07143619, -0.0661846 , ..., -0.05965889,\n",
      "           0.03999446, -0.00101379],\n",
      "         [-0.00083836, -0.00197292, -0.04079204, ...,  0.04441699,\n",
      "          -0.00290912, -0.01417284],\n",
      "         [ 0.00323816, -0.04485887,  0.06520173, ...,  0.01953805,\n",
      "           0.0256718 ,  0.02503692],\n",
      "         ...,\n",
      "         [-0.00311776, -0.06067365,  0.06564316, ..., -0.01446857,\n",
      "           0.04975771,  0.02741064],\n",
      "         [-0.00637498, -0.00922637, -0.03989237, ...,  0.00200514,\n",
      "          -0.03798764, -0.02764325],\n",
      "         [-0.04129951,  0.02440919,  0.01297569, ..., -0.03182549,\n",
      "           0.06278634, -0.05420154]]],\n",
      "\n",
      "\n",
      "       [[[ 0.00397065,  0.03602961,  0.02549502, ..., -0.07074769,\n",
      "           0.0155303 , -0.00214672],\n",
      "         [-0.03578072,  0.03701588,  0.04857942, ..., -0.00210264,\n",
      "          -0.05916138,  0.03375898],\n",
      "         [ 0.02695479, -0.02698364,  0.03067169, ...,  0.0458311 ,\n",
      "          -0.02589928, -0.0636141 ],\n",
      "         ...,\n",
      "         [ 0.0637729 , -0.07128494,  0.04022662, ..., -0.05422328,\n",
      "           0.04838707,  0.00108395],\n",
      "         [ 0.05214663,  0.00212296,  0.04276849, ...,  0.03202752,\n",
      "           0.06753233,  0.04080422],\n",
      "         [ 0.07119638,  0.06190996,  0.05583289, ..., -0.06876512,\n",
      "          -0.06385413, -0.05719047]],\n",
      "\n",
      "        [[ 0.01298992, -0.05393527,  0.05706388, ...,  0.07031932,\n",
      "          -0.06425808, -0.05185798],\n",
      "         [-0.04815405,  0.02483689, -0.05238451, ...,  0.07138531,\n",
      "          -0.02741088, -0.03019563],\n",
      "         [ 0.04196796, -0.04811962, -0.01664332, ..., -0.06281836,\n",
      "          -0.0451005 , -0.06437457],\n",
      "         ...,\n",
      "         [ 0.0394939 , -0.01402258, -0.01708638, ...,  0.01690874,\n",
      "          -0.03338142,  0.06818309],\n",
      "         [-0.07131068, -0.05381856, -0.03051842, ...,  0.00101421,\n",
      "          -0.02732679,  0.00966744],\n",
      "         [-0.01976553, -0.03610184, -0.01850038, ..., -0.03938556,\n",
      "          -0.03130425,  0.03357295]],\n",
      "\n",
      "        [[ 0.02074955,  0.00875166,  0.02478016, ..., -0.01026152,\n",
      "          -0.05253058,  0.07140572],\n",
      "         [ 0.04389368,  0.04221366, -0.02277846, ...,  0.06148756,\n",
      "           0.03182817, -0.06896948],\n",
      "         [-0.0496766 ,  0.06221707, -0.04989138, ...,  0.05696376,\n",
      "           0.02759905,  0.05704917],\n",
      "         ...,\n",
      "         [ 0.06079911, -0.04608599,  0.05003651, ..., -0.02675012,\n",
      "          -0.02765086, -0.03988358],\n",
      "         [ 0.0061297 ,  0.00324085,  0.0154654 , ...,  0.05222091,\n",
      "          -0.0459612 ,  0.05535634],\n",
      "         [-0.03340257, -0.03017847, -0.02820363, ..., -0.05882221,\n",
      "           0.06517154,  0.02642678]]],\n",
      "\n",
      "\n",
      "       [[[ 0.03377748,  0.03610375,  0.01188895, ...,  0.01636464,\n",
      "          -0.02594713, -0.03652974],\n",
      "         [-0.00443687,  0.06060214,  0.0603793 , ..., -0.06745494,\n",
      "           0.01603986,  0.01319674],\n",
      "         [ 0.06430589, -0.04801497,  0.01621503, ..., -0.06482386,\n",
      "           0.02961357,  0.05198202],\n",
      "         ...,\n",
      "         [-0.01725371,  0.05587058, -0.0578209 , ..., -0.03312618,\n",
      "           0.03657145, -0.04132912],\n",
      "         [ 0.01525485,  0.05900925, -0.03735342, ...,  0.01610658,\n",
      "          -0.00773931,  0.00035653],\n",
      "         [ 0.02293588, -0.02767242,  0.05571547, ..., -0.00947612,\n",
      "          -0.0187283 ,  0.00082589]],\n",
      "\n",
      "        [[ 0.00886086,  0.02296959, -0.02180031, ...,  0.00765418,\n",
      "           0.06731705, -0.04425425],\n",
      "         [-0.06790019, -0.0008109 ,  0.04424581, ..., -0.02170124,\n",
      "           0.02877811, -0.02315552],\n",
      "         [-0.0555435 ,  0.01531127,  0.03459621, ..., -0.04451402,\n",
      "          -0.03815275, -0.05050353],\n",
      "         ...,\n",
      "         [ 0.05689482, -0.05873878,  0.03226702, ..., -0.04490235,\n",
      "          -0.06912718, -0.03907092],\n",
      "         [-0.0681801 , -0.05264033,  0.04832162, ..., -0.0478029 ,\n",
      "          -0.04188681,  0.0563661 ],\n",
      "         [-0.01160491, -0.05704904, -0.03027646, ..., -0.02123971,\n",
      "          -0.06702869, -0.04380524]],\n",
      "\n",
      "        [[-0.00721364,  0.01563957, -0.01270669, ..., -0.03567245,\n",
      "          -0.01240711, -0.04299614],\n",
      "         [ 0.06747958,  0.03521798, -0.01438207, ...,  0.03165611,\n",
      "           0.05484949,  0.04934161],\n",
      "         [ 0.00018827,  0.00053637, -0.04512985, ..., -0.00543408,\n",
      "          -0.01624661, -0.02657967],\n",
      "         ...,\n",
      "         [-0.02126481, -0.00804994,  0.05724525, ..., -0.06938607,\n",
      "           0.03891525, -0.04356094],\n",
      "         [ 0.03948659, -0.02460371,  0.05296344, ..., -0.04186357,\n",
      "           0.06943226,  0.00269662],\n",
      "         [-0.04105877, -0.03668527, -0.03785124, ...,  0.01623768,\n",
      "          -0.02532762,  0.03750776]]]], dtype=float32)>, <tf.Variable 'basic_block_1/conv2d_4/bias:0' shape=(64,) dtype=float32, numpy=\n",
      "array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32)>, <tf.Variable 'basic_block_1/batch_normalization_4/gamma:0' shape=(64,) dtype=float32, numpy=\n",
      "array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32)>, <tf.Variable 'basic_block_1/batch_normalization_4/beta:0' shape=(64,) dtype=float32, numpy=\n",
      "array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32)>, <tf.Variable 'basic_block_1/batch_normalization_3/moving_mean:0' shape=(64,) dtype=float32, numpy=\n",
      "array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32)>, <tf.Variable 'basic_block_1/batch_normalization_3/moving_variance:0' shape=(64,) dtype=float32, numpy=\n",
      "array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32)>, <tf.Variable 'basic_block_1/batch_normalization_4/moving_mean:0' shape=(64,) dtype=float32, numpy=\n",
      "array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32)>, <tf.Variable 'basic_block_1/batch_normalization_4/moving_variance:0' shape=(64,) dtype=float32, numpy=\n",
      "array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32)>, <tf.Variable 'basic_block_2/conv2d_5/kernel:0' shape=(3, 3, 64, 128) dtype=float32, numpy=\n",
      "array([[[[-0.02423785,  0.00372644, -0.03588967, ...,  0.0348735 ,\n",
      "           0.04842368,  0.05188225],\n",
      "         [ 0.0319124 ,  0.05339162, -0.00467528, ..., -0.03579303,\n",
      "          -0.04400004, -0.0359074 ],\n",
      "         [-0.00618999, -0.00878891,  0.03138127, ...,  0.05354673,\n",
      "           0.00419559,  0.04897134],\n",
      "         ...,\n",
      "         [-0.05537181,  0.00057184, -0.04475258, ...,  0.00702891,\n",
      "          -0.00881794,  0.02800217],\n",
      "         [-0.0394058 ,  0.03982259, -0.05880442, ...,  0.01926779,\n",
      "          -0.03320846, -0.05677303],\n",
      "         [-0.00531657, -0.04450617, -0.02247925, ...,  0.05037977,\n",
      "           0.02925875,  0.03520222]],\n",
      "\n",
      "        [[-0.01268818,  0.01094541, -0.01370972, ..., -0.02946335,\n",
      "          -0.03099892,  0.04049532],\n",
      "         [ 0.00106917, -0.00428435, -0.01553449, ...,  0.03895954,\n",
      "           0.0384415 ,  0.04778088],\n",
      "         [ 0.01784546, -0.05206586, -0.01283249, ...,  0.02905549,\n",
      "           0.01629105, -0.00259772],\n",
      "         ...,\n",
      "         [-0.01501546,  0.05675762, -0.02505906, ...,  0.03037891,\n",
      "           0.04467004,  0.04101568],\n",
      "         [-0.00362197, -0.00460259, -0.0544831 , ..., -0.04142872,\n",
      "           0.01120489,  0.02767709],\n",
      "         [ 0.04899931,  0.03423673,  0.01195512, ..., -0.0390836 ,\n",
      "          -0.03240573,  0.01494474]],\n",
      "\n",
      "        [[ 0.0469888 , -0.00277079, -0.02794514, ...,  0.02599989,\n",
      "           0.04890634, -0.04172275],\n",
      "         [-0.01021061,  0.00315594,  0.04894863, ...,  0.04760556,\n",
      "          -0.05855741,  0.01942806],\n",
      "         [-0.00194119,  0.05529266,  0.04368726, ..., -0.05032886,\n",
      "           0.02394747,  0.00505248],\n",
      "         ...,\n",
      "         [-0.00059823, -0.00772587,  0.05149002, ...,  0.05584723,\n",
      "           0.05317668, -0.05069882],\n",
      "         [ 0.04213252, -0.00020138,  0.00897751, ...,  0.02230975,\n",
      "          -0.01554615, -0.00734045],\n",
      "         [ 0.05836141, -0.02753093, -0.04270341, ...,  0.03826689,\n",
      "          -0.02498114,  0.01784698]]],\n",
      "\n",
      "\n",
      "       [[[-0.02035507, -0.01174794, -0.04194988, ...,  0.04724608,\n",
      "           0.03757334,  0.04617506],\n",
      "         [ 0.05255653,  0.03041169, -0.05820502, ...,  0.0157667 ,\n",
      "          -0.02017032,  0.0514749 ],\n",
      "         [-0.00745913,  0.01104015, -0.04629888, ...,  0.0294476 ,\n",
      "           0.03126692, -0.04429569],\n",
      "         ...,\n",
      "         [-0.04637961, -0.01015206,  0.01135106, ..., -0.01866417,\n",
      "           0.00638125, -0.04908686],\n",
      "         [-0.02295008, -0.03357375, -0.03746672, ..., -0.04097533,\n",
      "           0.01626933, -0.034676  ],\n",
      "         [-0.05751113,  0.04164887,  0.00401234, ...,  0.02525407,\n",
      "          -0.00125093,  0.03803727]],\n",
      "\n",
      "        [[-0.03132647,  0.05156785, -0.02947208, ...,  0.00707259,\n",
      "          -0.05387771, -0.03096955],\n",
      "         [-0.01158113,  0.00615164, -0.01900262, ..., -0.0312184 ,\n",
      "           0.02247449,  0.01776636],\n",
      "         [-0.01380172,  0.01755314,  0.02964914, ...,  0.05412337,\n",
      "          -0.05631635, -0.01966354],\n",
      "         ...,\n",
      "         [ 0.02495563, -0.05406457, -0.02066362, ...,  0.01072795,\n",
      "           0.00545795, -0.02932045],\n",
      "         [-0.02097469,  0.02665008,  0.00931069, ...,  0.01243887,\n",
      "          -0.03758617, -0.04962242],\n",
      "         [-0.01706901, -0.04066935, -0.00330677, ..., -0.02835259,\n",
      "           0.04284981, -0.02088677]],\n",
      "\n",
      "        [[-0.05179415, -0.01521432,  0.05805467, ...,  0.03065696,\n",
      "           0.04333356,  0.01927787],\n",
      "         [-0.01303028,  0.03466984, -0.03015231, ...,  0.00451541,\n",
      "          -0.00379903, -0.03624831],\n",
      "         [-0.0332867 ,  0.04421289, -0.01880367, ...,  0.02806157,\n",
      "           0.04045044,  0.02041506],\n",
      "         ...,\n",
      "         [ 0.03085822, -0.0406734 ,  0.00703319, ...,  0.02560876,\n",
      "          -0.00126006,  0.01723688],\n",
      "         [-0.05519905,  0.00839176, -0.00319795, ..., -0.00461567,\n",
      "          -0.04728289,  0.03752164],\n",
      "         [-0.00729974,  0.01092625, -0.01098577, ...,  0.0274058 ,\n",
      "          -0.0057771 , -0.04511428]]],\n",
      "\n",
      "\n",
      "       [[[-0.04254795,  0.00835418,  0.04944688, ..., -0.04267793,\n",
      "           0.04143595,  0.01698737],\n",
      "         [ 0.02118931,  0.03250803,  0.05712489, ...,  0.05245389,\n",
      "           0.03634913,  0.05191405],\n",
      "         [ 0.00714   , -0.04077435,  0.05609505, ...,  0.05186345,\n",
      "           0.03620327, -0.04111461],\n",
      "         ...,\n",
      "         [ 0.00280482,  0.01917926, -0.03664663, ..., -0.0281768 ,\n",
      "           0.03086137, -0.01973269],\n",
      "         [ 0.03624851, -0.03074236, -0.01930237, ...,  0.04534021,\n",
      "          -0.02398365,  0.04594526],\n",
      "         [-0.02686561,  0.0388141 ,  0.03926916, ...,  0.0519972 ,\n",
      "           0.02154915,  0.0305058 ]],\n",
      "\n",
      "        [[ 0.0523917 ,  0.01430098, -0.00505942, ...,  0.0246419 ,\n",
      "           0.00999708,  0.05672048],\n",
      "         [ 0.02897253, -0.04627687,  0.01509522, ...,  0.02885123,\n",
      "          -0.04772642, -0.02237981],\n",
      "         [-0.03146532,  0.02094167, -0.0152376 , ..., -0.016211  ,\n",
      "           0.05697392,  0.05888248],\n",
      "         ...,\n",
      "         [ 0.04600943, -0.02640733, -0.04383822, ..., -0.05888279,\n",
      "           0.01685249,  0.03302063],\n",
      "         [ 0.03692938,  0.05157788, -0.02019857, ...,  0.00046405,\n",
      "           0.05287612, -0.03962404],\n",
      "         [ 0.05825254, -0.0260792 ,  0.01612711, ...,  0.02028449,\n",
      "          -0.02031796,  0.04911992]],\n",
      "\n",
      "        [[ 0.04538232, -0.00982654,  0.02021528, ..., -0.05574384,\n",
      "           0.01134029,  0.01484824],\n",
      "         [ 0.03100659, -0.04659549, -0.04644052, ...,  0.04230237,\n",
      "          -0.01515983, -0.05718636],\n",
      "         [ 0.00261541, -0.00801154,  0.01508327, ..., -0.04399915,\n",
      "           0.03432589, -0.02457633],\n",
      "         ...,\n",
      "         [-0.01891534, -0.00721043,  0.05858162, ...,  0.04472369,\n",
      "          -0.05018182, -0.03983772],\n",
      "         [ 0.04015442,  0.00258474,  0.02747038, ..., -0.04103421,\n",
      "           0.0067316 , -0.0369219 ],\n",
      "         [-0.04846205,  0.044354  ,  0.04615337, ...,  0.03563057,\n",
      "          -0.0252174 , -0.00878214]]]], dtype=float32)>, <tf.Variable 'basic_block_2/conv2d_5/bias:0' shape=(128,) dtype=float32, numpy=\n",
      "array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32)>, <tf.Variable 'basic_block_2/batch_normalization_5/gamma:0' shape=(128,) dtype=float32, numpy=\n",
      "array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32)>, <tf.Variable 'basic_block_2/batch_normalization_5/beta:0' shape=(128,) dtype=float32, numpy=\n",
      "array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32)>, <tf.Variable 'basic_block_2/conv2d_6/kernel:0' shape=(3, 3, 128, 128) dtype=float32, numpy=\n",
      "array([[[[-0.0475037 , -0.0143135 , -0.02629622, ..., -0.01259234,\n",
      "           0.03429164, -0.02269187],\n",
      "         [-0.01116606, -0.04039685, -0.01316831, ..., -0.03460902,\n",
      "          -0.01098729, -0.01735969],\n",
      "         [-0.03971896, -0.01792971,  0.00689171, ...,  0.00679211,\n",
      "           0.03409303,  0.04600868],\n",
      "         ...,\n",
      "         [-0.02038037,  0.0435116 , -0.04042173, ...,  0.00264898,\n",
      "           0.02568066,  0.04149395],\n",
      "         [ 0.03597821, -0.01252736, -0.04427023, ..., -0.01389271,\n",
      "          -0.04435372, -0.00479001],\n",
      "         [ 0.03395423, -0.02526525,  0.02054056, ..., -0.03552821,\n",
      "          -0.00651695, -0.02104021]],\n",
      "\n",
      "        [[ 0.04640631, -0.02137418,  0.03105836, ...,  0.00673141,\n",
      "           0.00804625, -0.02227779],\n",
      "         [-0.04097673,  0.04782394, -0.03147511, ..., -0.03558735,\n",
      "           0.00301787, -0.04126731],\n",
      "         [ 0.00089166,  0.01858635,  0.04177228, ...,  0.00646235,\n",
      "          -0.05026437,  0.03541773],\n",
      "         ...,\n",
      "         [ 0.04989371,  0.02752523, -0.03629778, ..., -0.03699932,\n",
      "           0.00634345, -0.01680446],\n",
      "         [-0.00120518, -0.00883811, -0.03140812, ..., -0.03953986,\n",
      "          -0.02179757,  0.00261837],\n",
      "         [-0.03476945, -0.04699409,  0.03112253, ..., -0.00804104,\n",
      "           0.01438259,  0.04059837]],\n",
      "\n",
      "        [[-0.05025388,  0.00935911,  0.01205316, ...,  0.03335846,\n",
      "           0.03200895, -0.04609595],\n",
      "         [-0.05065534, -0.01455748, -0.01534687, ...,  0.00600004,\n",
      "           0.02115514, -0.02207771],\n",
      "         [-0.00590775,  0.01589281, -0.04451065, ...,  0.03516308,\n",
      "           0.0002177 , -0.04124893],\n",
      "         ...,\n",
      "         [-0.0027245 ,  0.03898744, -0.00944567, ..., -0.02090014,\n",
      "           0.04731716, -0.02656868],\n",
      "         [-0.00236531,  0.0074338 ,  0.02060308, ...,  0.0289983 ,\n",
      "           0.0191296 ,  0.02183351],\n",
      "         [-0.0398467 , -0.01047742, -0.00711264, ...,  0.00522373,\n",
      "           0.0137874 , -0.03730723]]],\n",
      "\n",
      "\n",
      "       [[[ 0.04036999,  0.01749124,  0.02858216, ...,  0.0232287 ,\n",
      "          -0.03866766,  0.03698055],\n",
      "         [-0.02944566, -0.01876989, -0.03235733, ...,  0.02155319,\n",
      "          -0.02665641,  0.03191061],\n",
      "         [ 0.04851459,  0.02580355, -0.00534316, ...,  0.01170617,\n",
      "          -0.02109512, -0.036502  ],\n",
      "         ...,\n",
      "         [-0.04875191, -0.01297384,  0.02680232, ..., -0.01298395,\n",
      "          -0.02100982,  0.03953716],\n",
      "         [ 0.01546782, -0.00778313,  0.04497217, ...,  0.01525263,\n",
      "          -0.02204461, -0.02933316],\n",
      "         [ 0.02893051,  0.0430995 ,  0.03098433, ...,  0.01213147,\n",
      "          -0.03037481,  0.00813796]],\n",
      "\n",
      "        [[ 0.03296728, -0.01422446, -0.00548242, ...,  0.04168876,\n",
      "           0.00487317,  0.04767786],\n",
      "         [ 0.01474468,  0.01495444, -0.01419165, ..., -0.03453312,\n",
      "          -0.04709894, -0.04342072],\n",
      "         [ 0.0183823 ,  0.02989335, -0.03176943, ..., -0.00467269,\n",
      "           0.02188967, -0.01101694],\n",
      "         ...,\n",
      "         [ 0.0419409 ,  0.01673426, -0.02404327, ...,  0.03733224,\n",
      "          -0.04453472,  0.0388573 ],\n",
      "         [ 0.02109982, -0.01760815,  0.02098527, ...,  0.04113939,\n",
      "          -0.0014074 , -0.03666759],\n",
      "         [ 0.04353267, -0.00651778, -0.04247281, ..., -0.01821564,\n",
      "          -0.01642948,  0.03677617]],\n",
      "\n",
      "        [[-0.04003286, -0.04378214,  0.04910508, ..., -0.02980655,\n",
      "          -0.00308836,  0.02958685],\n",
      "         [ 0.01780799,  0.03693049, -0.00832931, ...,  0.01273451,\n",
      "           0.00576008,  0.04640009],\n",
      "         [ 0.01258049, -0.02049014, -0.04634696, ...,  0.05004784,\n",
      "          -0.01934803,  0.007872  ],\n",
      "         ...,\n",
      "         [ 0.04279961,  0.04894637, -0.03517167, ...,  0.00572416,\n",
      "          -0.044783  , -0.0216329 ],\n",
      "         [ 0.01060671,  0.03745659,  0.0457071 , ...,  0.01891869,\n",
      "          -0.00179615,  0.0003656 ],\n",
      "         [ 0.00611013, -0.02593109,  0.01742785, ..., -0.04417175,\n",
      "          -0.02491383, -0.00667575]]],\n",
      "\n",
      "\n",
      "       [[[-0.03490525,  0.00293215,  0.01067957, ...,  0.00463651,\n",
      "           0.00460023,  0.02193792],\n",
      "         [ 0.01706215, -0.03673578,  0.0240877 , ...,  0.04150345,\n",
      "           0.02456612,  0.00452356],\n",
      "         [-0.02368186,  0.02592094, -0.03893188, ..., -0.02023425,\n",
      "           0.03588443,  0.02948895],\n",
      "         ...,\n",
      "         [-0.0023786 , -0.01751521,  0.02137476, ..., -0.00691638,\n",
      "          -0.02811531,  0.04867197],\n",
      "         [-0.02612869, -0.04610199, -0.02559224, ...,  0.02505945,\n",
      "           0.01477255, -0.02038997],\n",
      "         [-0.01823856, -0.00105426, -0.03788843, ..., -0.02201662,\n",
      "          -0.00772411, -0.02196503]],\n",
      "\n",
      "        [[-0.05005335, -0.02000352,  0.02253946, ..., -0.00961198,\n",
      "          -0.00398747, -0.02214022],\n",
      "         [ 0.03087007, -0.04229563, -0.03317825, ...,  0.04057295,\n",
      "           0.01985613, -0.01755479],\n",
      "         [ 0.04442042,  0.00635817, -0.02266998, ...,  0.02162328,\n",
      "           0.03223069, -0.0011933 ],\n",
      "         ...,\n",
      "         [ 0.012451  , -0.04916068, -0.01550023, ...,  0.00035161,\n",
      "          -0.04282216, -0.02543584],\n",
      "         [-0.02386684, -0.02445403,  0.02247301, ...,  0.03106977,\n",
      "           0.03724758, -0.04764292],\n",
      "         [-0.03297372,  0.03590389,  0.00396495, ..., -0.03055228,\n",
      "           0.01378439, -0.04043773]],\n",
      "\n",
      "        [[-0.0132131 , -0.01233307, -0.03136687, ...,  0.03531316,\n",
      "          -0.02228807, -0.03775034],\n",
      "         [ 0.03994972,  0.00479138,  0.02777333, ...,  0.0435684 ,\n",
      "          -0.0461016 , -0.0448533 ],\n",
      "         [-0.0425915 ,  0.01048734,  0.01480301, ...,  0.03847938,\n",
      "          -0.03070559, -0.04362981],\n",
      "         ...,\n",
      "         [ 0.0174389 , -0.02167108, -0.00209869, ...,  0.02041314,\n",
      "          -0.04534272,  0.04876062],\n",
      "         [-0.03251898,  0.03159758, -0.00780802, ...,  0.0149548 ,\n",
      "           0.0496487 ,  0.03008861],\n",
      "         [-0.03452298, -0.03445124,  0.01515243, ..., -0.00349834,\n",
      "           0.02157309,  0.04314296]]]], dtype=float32)>, <tf.Variable 'basic_block_2/conv2d_6/bias:0' shape=(128,) dtype=float32, numpy=\n",
      "array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32)>, <tf.Variable 'basic_block_2/batch_normalization_6/gamma:0' shape=(128,) dtype=float32, numpy=\n",
      "array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32)>, <tf.Variable 'basic_block_2/batch_normalization_6/beta:0' shape=(128,) dtype=float32, numpy=\n",
      "array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32)>, <tf.Variable 'conv2d_7/kernel:0' shape=(1, 1, 64, 128) dtype=float32, numpy=\n",
      "array([[[[-0.14945833,  0.16932999,  0.03469436, ...,  0.12303807,\n",
      "           0.0467419 ,  0.17034836],\n",
      "         [ 0.04305077,  0.07248279,  0.12422447, ..., -0.05971968,\n",
      "          -0.13010155,  0.13886653],\n",
      "         [ 0.17336883,  0.06242011, -0.07057018, ..., -0.02056611,\n",
      "          -0.15436953, -0.07041213],\n",
      "         ...,\n",
      "         [ 0.02394459,  0.17253216, -0.07797812, ..., -0.05860022,\n",
      "          -0.05561268, -0.13687687],\n",
      "         [ 0.122216  ,  0.12180476,  0.10617314, ...,  0.12263502,\n",
      "           0.04559143,  0.05765449],\n",
      "         [-0.00649069, -0.04238498,  0.106813  , ...,  0.15414555,\n",
      "          -0.07067891,  0.06098893]]]], dtype=float32)>, <tf.Variable 'conv2d_7/bias:0' shape=(128,) dtype=float32, numpy=\n",
      "array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32)>, <tf.Variable 'batch_normalization_7/gamma:0' shape=(128,) dtype=float32, numpy=\n",
      "array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32)>, <tf.Variable 'batch_normalization_7/beta:0' shape=(128,) dtype=float32, numpy=\n",
      "array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32)>, <tf.Variable 'basic_block_2/batch_normalization_5/moving_mean:0' shape=(128,) dtype=float32, numpy=\n",
      "array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32)>, <tf.Variable 'basic_block_2/batch_normalization_5/moving_variance:0' shape=(128,) dtype=float32, numpy=\n",
      "array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32)>, <tf.Variable 'basic_block_2/batch_normalization_6/moving_mean:0' shape=(128,) dtype=float32, numpy=\n",
      "array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32)>, <tf.Variable 'basic_block_2/batch_normalization_6/moving_variance:0' shape=(128,) dtype=float32, numpy=\n",
      "array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32)>, <tf.Variable 'batch_normalization_7/moving_mean:0' shape=(128,) dtype=float32, numpy=\n",
      "array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32)>, <tf.Variable 'batch_normalization_7/moving_variance:0' shape=(128,) dtype=float32, numpy=\n",
      "array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32)>, <tf.Variable 'basic_block_3/conv2d_8/kernel:0' shape=(3, 3, 128, 128) dtype=float32, numpy=\n",
      "array([[[[-0.04679478,  0.03612667, -0.0058298 , ..., -0.02965752,\n",
      "           0.03813958, -0.01095729],\n",
      "         [ 0.02655797, -0.00731388, -0.01478798, ..., -0.04759214,\n",
      "          -0.0410067 ,  0.01191445],\n",
      "         [-0.01341264,  0.03535848, -0.03927359, ..., -0.03700244,\n",
      "           0.0450945 , -0.04224059],\n",
      "         ...,\n",
      "         [-0.03174384, -0.05086822, -0.02944223, ...,  0.04028486,\n",
      "           0.00795287, -0.01971764],\n",
      "         [-0.01985101, -0.03513299,  0.02119236, ..., -0.02156685,\n",
      "          -0.04961897,  0.00226513],\n",
      "         [ 0.04311025, -0.04184241, -0.04350141, ..., -0.0187742 ,\n",
      "          -0.05023818,  0.00386744]],\n",
      "\n",
      "        [[ 0.05077963,  0.01222931,  0.0357075 , ...,  0.01220687,\n",
      "          -0.02873486, -0.02288798],\n",
      "         [-0.03270826, -0.02110881, -0.03387626, ...,  0.04255033,\n",
      "          -0.04165264,  0.04019212],\n",
      "         [-0.0223381 ,  0.04478157,  0.0110527 , ...,  0.03331289,\n",
      "           0.00039078, -0.00553246],\n",
      "         ...,\n",
      "         [-0.03405017, -0.01073286,  0.04217836, ..., -0.0013787 ,\n",
      "          -0.03229922,  0.02791901],\n",
      "         [ 0.03025332,  0.01049872, -0.03388358, ...,  0.03521883,\n",
      "          -0.02782843,  0.01498903],\n",
      "         [-0.03085391,  0.04823287, -0.03167263, ..., -0.02232159,\n",
      "          -0.04425943,  0.01899859]],\n",
      "\n",
      "        [[ 0.0033991 ,  0.00236753, -0.04268489, ...,  0.00290687,\n",
      "          -0.04898116, -0.02200563],\n",
      "         [ 0.03118772, -0.00720374, -0.01809499, ..., -0.03630775,\n",
      "           0.03679625, -0.00330968],\n",
      "         [-0.01303196,  0.00956917,  0.00488074, ..., -0.03821184,\n",
      "           0.02890228,  0.00432304],\n",
      "         ...,\n",
      "         [-0.00599216, -0.01855946,  0.03006906, ..., -0.00611872,\n",
      "          -0.05003871,  0.03732783],\n",
      "         [-0.00836868,  0.01812973,  0.0036263 , ...,  0.00217824,\n",
      "          -0.01013049,  0.02165991],\n",
      "         [-0.00553647,  0.01711434,  0.002433  , ..., -0.01590911,\n",
      "          -0.0370662 ,  0.02289843]]],\n",
      "\n",
      "\n",
      "       [[[-0.01198184, -0.05025985,  0.01963319, ..., -0.00365661,\n",
      "           0.04576668,  0.00034568],\n",
      "         [-0.02772349, -0.01714364,  0.04129427, ...,  0.04723593,\n",
      "          -0.01042497,  0.03065619],\n",
      "         [ 0.00878601,  0.00741282,  0.04673048, ..., -0.02598775,\n",
      "           0.02422575,  0.04609871],\n",
      "         ...,\n",
      "         [-0.03293408,  0.04644319,  0.00110621, ..., -0.03286554,\n",
      "          -0.01330282, -0.05054254],\n",
      "         [-0.02841546, -0.00246372,  0.02044293, ..., -0.03887419,\n",
      "          -0.00630631,  0.01443671],\n",
      "         [-0.01442922,  0.03227698,  0.00554509, ..., -0.00299267,\n",
      "          -0.0485995 ,  0.03001646]],\n",
      "\n",
      "        [[-0.01602484, -0.03797332, -0.00738716, ..., -0.01178832,\n",
      "          -0.02736289,  0.04961264],\n",
      "         [ 0.01053741, -0.02519612, -0.04608965, ...,  0.03017604,\n",
      "           0.04506963,  0.04739251],\n",
      "         [-0.04843676,  0.01839428,  0.00881143, ...,  0.02983011,\n",
      "          -0.00130245, -0.00450951],\n",
      "         ...,\n",
      "         [-0.04752782, -0.01182911, -0.02410448, ..., -0.03662924,\n",
      "           0.04337551, -0.02703332],\n",
      "         [ 0.0086356 , -0.01217374,  0.0366542 , ...,  0.02408069,\n",
      "           0.01571816, -0.04806018],\n",
      "         [-0.0270905 , -0.04717438, -0.00609476, ..., -0.03021027,\n",
      "          -0.00824813,  0.02780222]],\n",
      "\n",
      "        [[ 0.00954781,  0.02081694,  0.04643662, ...,  0.02921227,\n",
      "          -0.00884746, -0.02118745],\n",
      "         [ 0.01310254, -0.03139679,  0.00687722, ...,  0.04455655,\n",
      "           0.00116339, -0.03314847],\n",
      "         [ 0.04495247, -0.012537  , -0.00332028, ..., -0.0047617 ,\n",
      "           0.02245919, -0.00253301],\n",
      "         ...,\n",
      "         [ 0.00447157, -0.01502043, -0.01875182, ..., -0.00547782,\n",
      "           0.04557417, -0.04054802],\n",
      "         [-0.04203415, -0.01308307,  0.01366294, ...,  0.02313235,\n",
      "           0.01889978,  0.03545076],\n",
      "         [-0.01270783,  0.02088186, -0.04319919, ..., -0.00818805,\n",
      "          -0.04627621, -0.02327288]]],\n",
      "\n",
      "\n",
      "       [[[ 0.02691296,  0.0443203 ,  0.0325771 , ..., -0.04125777,\n",
      "          -0.02516828, -0.01692659],\n",
      "         [ 0.0098771 , -0.02211157,  0.02293443, ...,  0.00670697,\n",
      "           0.01320855, -0.02916358],\n",
      "         [ 0.02005563,  0.04793071,  0.03730507, ..., -0.04031872,\n",
      "          -0.04431237,  0.01044335],\n",
      "         ...,\n",
      "         [ 0.01529788, -0.01674274, -0.03077984, ...,  0.05030355,\n",
      "           0.02953551,  0.02209651],\n",
      "         [ 0.04693543,  0.0338368 , -0.04958965, ..., -0.03877576,\n",
      "           0.00392106, -0.04731187],\n",
      "         [-0.01871971,  0.01336414, -0.04925682, ..., -0.03369397,\n",
      "          -0.03196151, -0.00948313]],\n",
      "\n",
      "        [[-0.04528698, -0.01122165, -0.01239282, ..., -0.04533288,\n",
      "           0.01990856, -0.01194821],\n",
      "         [ 0.01484563,  0.02881588, -0.04810074, ..., -0.00357115,\n",
      "          -0.00992369,  0.04904755],\n",
      "         [-0.0183203 , -0.01526962,  0.0438541 , ...,  0.01070742,\n",
      "           0.00232471, -0.00384278],\n",
      "         ...,\n",
      "         [-0.01303096, -0.03342588, -0.01727283, ..., -0.04948848,\n",
      "           0.03234283,  0.01894636],\n",
      "         [-0.01300006, -0.01503309, -0.01846395, ...,  0.01202551,\n",
      "          -0.01461279,  0.02851158],\n",
      "         [-0.00307119,  0.0444659 ,  0.01070809, ...,  0.02255901,\n",
      "          -0.02267093,  0.00854003]],\n",
      "\n",
      "        [[-0.00300509, -0.03080433, -0.02119499, ..., -0.00037208,\n",
      "           0.0505491 ,  0.00572607],\n",
      "         [ 0.04441883, -0.03072216,  0.03357599, ...,  0.02351356,\n",
      "           0.05045819,  0.00037055],\n",
      "         [ 0.00061856, -0.00752157, -0.03412187, ...,  0.03216811,\n",
      "           0.04553026, -0.0056451 ],\n",
      "         ...,\n",
      "         [ 0.00337911,  0.01721863,  0.04921947, ..., -0.0306212 ,\n",
      "          -0.0041183 ,  0.01701733],\n",
      "         [ 0.03268301,  0.03501304,  0.02551047, ...,  0.00438042,\n",
      "           0.01424953,  0.00497389],\n",
      "         [ 0.00371373,  0.01362923, -0.01084745, ...,  0.04136568,\n",
      "          -0.04091507, -0.01047121]]]], dtype=float32)>, <tf.Variable 'basic_block_3/conv2d_8/bias:0' shape=(128,) dtype=float32, numpy=\n",
      "array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32)>, <tf.Variable 'basic_block_3/batch_normalization_8/gamma:0' shape=(128,) dtype=float32, numpy=\n",
      "array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32)>, <tf.Variable 'basic_block_3/batch_normalization_8/beta:0' shape=(128,) dtype=float32, numpy=\n",
      "array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32)>, <tf.Variable 'basic_block_3/conv2d_9/kernel:0' shape=(3, 3, 128, 128) dtype=float32, numpy=\n",
      "array([[[[ 3.53110507e-02,  3.86901349e-02,  2.86658481e-03, ...,\n",
      "          -2.39902735e-03,  2.65286788e-02,  2.09546834e-02],\n",
      "         [ 9.11523029e-03, -4.71680090e-02, -3.93785052e-02, ...,\n",
      "          -3.13221850e-02, -4.60747667e-02,  1.73299387e-03],\n",
      "         [ 3.77979949e-02,  2.52050757e-02,  3.54647040e-02, ...,\n",
      "           3.12422216e-02, -4.19678837e-02,  3.34440395e-02],\n",
      "         ...,\n",
      "         [-2.18449086e-02,  4.13605794e-02, -4.87025306e-02, ...,\n",
      "          -3.57349440e-02, -2.96436604e-02, -1.86702386e-02],\n",
      "         [ 4.73300219e-02, -1.80986337e-02,  1.63086280e-02, ...,\n",
      "          -1.42038241e-03,  1.61431581e-02,  3.64640951e-02],\n",
      "         [-4.10237052e-02,  1.69813633e-03,  5.01463711e-02, ...,\n",
      "           4.90111783e-02,  2.04998106e-02,  1.87200606e-02]],\n",
      "\n",
      "        [[-2.02556998e-02,  9.42029804e-03,  8.62916932e-03, ...,\n",
      "           3.98808494e-02,  1.39719546e-02, -2.75349673e-02],\n",
      "         [-3.19039971e-02,  4.94614616e-03, -2.47290246e-02, ...,\n",
      "           1.52806714e-02,  4.36966047e-02, -1.98556334e-02],\n",
      "         [ 1.34432614e-02, -1.83049701e-02,  2.05234811e-03, ...,\n",
      "           4.82133031e-03, -2.32680291e-02,  3.49931344e-02],\n",
      "         ...,\n",
      "         [-2.35894620e-02,  4.52047363e-02, -4.50952239e-02, ...,\n",
      "          -3.08617335e-02, -2.00191662e-02,  1.97040141e-02],\n",
      "         [ 4.29017842e-03,  6.55847415e-03, -2.58493870e-02, ...,\n",
      "           2.84304991e-02,  2.96323448e-02,  1.76012963e-02],\n",
      "         [-1.34466514e-02,  3.63356993e-02,  1.87083483e-02, ...,\n",
      "          -1.57667920e-02,  5.04373983e-02,  4.77295667e-02]],\n",
      "\n",
      "        [[ 2.09630504e-02, -1.93388872e-02,  3.64795104e-02, ...,\n",
      "           1.10142753e-02, -1.56091228e-02, -4.45185788e-02],\n",
      "         [ 1.88437253e-02, -3.77952717e-02,  1.54530555e-02, ...,\n",
      "           1.60075724e-02, -4.34539020e-02,  2.28505507e-02],\n",
      "         [-4.25474197e-02, -3.85730192e-02, -3.13638076e-02, ...,\n",
      "           5.27378544e-03, -3.09193563e-02,  8.67664441e-03],\n",
      "         ...,\n",
      "         [-5.11742011e-03, -3.60955037e-02, -1.32913701e-02, ...,\n",
      "          -4.80148941e-04,  3.87955084e-03, -1.67324282e-02],\n",
      "         [-4.62219603e-02, -3.64684165e-02,  7.31249526e-03, ...,\n",
      "           3.64855304e-02,  5.01277074e-02,  4.42582369e-02],\n",
      "         [-1.34279393e-02,  2.54361033e-02, -1.00305825e-02, ...,\n",
      "           4.01277691e-02,  1.71079412e-02, -1.48892514e-02]]],\n",
      "\n",
      "\n",
      "       [[[ 2.89169922e-02, -4.47325557e-02,  8.00472125e-03, ...,\n",
      "           3.77279148e-02, -5.06554022e-02, -5.03786691e-02],\n",
      "         [-5.24410978e-03,  4.76318300e-02, -1.59318708e-02, ...,\n",
      "          -2.97377463e-02, -2.63498295e-02, -1.45189799e-02],\n",
      "         [ 2.89921090e-02, -4.60830033e-02,  1.84295550e-02, ...,\n",
      "           2.88502797e-02, -1.71252079e-02,  2.57045403e-02],\n",
      "         ...,\n",
      "         [ 4.56200093e-02,  1.65257230e-03,  4.84992117e-02, ...,\n",
      "          -3.99546996e-02, -2.24989932e-02, -7.88605958e-03],\n",
      "         [ 4.34317440e-03,  3.95538658e-03, -4.61843051e-02, ...,\n",
      "          -4.88853604e-02,  1.47375464e-02,  1.32173821e-02],\n",
      "         [-4.61161956e-02, -4.97521050e-02,  2.34133601e-02, ...,\n",
      "          -4.31489199e-02, -3.16133946e-02,  2.96645612e-02]],\n",
      "\n",
      "        [[ 4.50929478e-02,  1.17507055e-02, -8.68123025e-04, ...,\n",
      "          -4.36164886e-02,  1.50540024e-02, -1.41297430e-02],\n",
      "         [-2.19562706e-02,  4.04188260e-02,  3.99339199e-02, ...,\n",
      "          -9.11266357e-03, -1.62352100e-02, -3.06617375e-02],\n",
      "         [-1.88978799e-02,  1.47955939e-02,  9.39854607e-03, ...,\n",
      "           4.26163599e-02,  2.55035460e-02, -3.14816311e-02],\n",
      "         ...,\n",
      "         [ 4.79463488e-03,  2.93082222e-02, -1.95911415e-02, ...,\n",
      "          -8.72239470e-05, -5.22266328e-03, -1.62169598e-02],\n",
      "         [ 6.43029809e-03,  2.05391645e-03,  2.96160430e-02, ...,\n",
      "           4.23059016e-02,  2.93226391e-02,  1.67368725e-02],\n",
      "         [ 4.85160127e-02,  1.34767890e-02,  4.62785587e-02, ...,\n",
      "           3.70952189e-02, -1.51447915e-02, -2.24494617e-02]],\n",
      "\n",
      "        [[ 4.71087322e-02, -4.92318571e-02,  3.19824740e-02, ...,\n",
      "          -4.84572835e-02, -4.55762818e-02,  5.06692007e-02],\n",
      "         [-4.89534438e-02,  3.01715285e-02, -1.20882727e-02, ...,\n",
      "           1.44539028e-02,  2.80670598e-02,  3.97055149e-02],\n",
      "         [ 3.39876115e-02,  2.45241150e-02, -1.77815557e-04, ...,\n",
      "          -4.50212955e-02,  3.60930189e-02,  1.58550218e-02],\n",
      "         ...,\n",
      "         [ 2.33754739e-02, -1.51566043e-02,  4.23926115e-02, ...,\n",
      "           2.54043862e-02, -2.59521585e-02,  4.56107780e-02],\n",
      "         [ 3.41678634e-02, -3.02294530e-02, -5.04689813e-02, ...,\n",
      "          -1.35660321e-02,  1.33088380e-02,  1.27522126e-02],\n",
      "         [ 2.38262117e-02, -1.21331178e-02,  3.30679193e-02, ...,\n",
      "          -3.41024101e-02,  2.95300931e-02, -9.41920280e-03]]],\n",
      "\n",
      "\n",
      "       [[[ 3.98349315e-02, -3.09757851e-02,  9.53899696e-03, ...,\n",
      "          -4.21885401e-02, -2.96879113e-02,  3.26364487e-03],\n",
      "         [ 4.59761918e-03,  3.31253484e-02, -1.85946599e-02, ...,\n",
      "           9.86854732e-03, -1.46545321e-02, -1.63550302e-02],\n",
      "         [-1.35393403e-02,  1.07082836e-02, -2.94971839e-03, ...,\n",
      "           1.72927827e-02, -1.55441761e-02,  1.02390125e-02],\n",
      "         ...,\n",
      "         [-2.66279969e-02,  3.01365852e-02,  3.72072905e-02, ...,\n",
      "           3.11958939e-02, -2.43112780e-02, -4.89857234e-02],\n",
      "         [ 2.82810479e-02,  4.57351953e-02,  2.60085762e-02, ...,\n",
      "           1.30871534e-02,  4.58645225e-02, -2.68114228e-02],\n",
      "         [ 2.05936283e-02,  2.33477056e-02,  4.69254926e-02, ...,\n",
      "           1.66873261e-02,  3.92841771e-02,  5.08412719e-02]],\n",
      "\n",
      "        [[-2.70563290e-02,  2.23842934e-02,  1.68329477e-02, ...,\n",
      "          -1.81680322e-02,  9.87591967e-03, -7.44828954e-03],\n",
      "         [-4.67225723e-02, -1.72432996e-02,  4.57925126e-02, ...,\n",
      "           3.25176269e-02,  2.09338516e-02,  4.25090268e-03],\n",
      "         [ 3.47279161e-02,  1.37061551e-02, -3.87942828e-02, ...,\n",
      "           1.74344704e-03,  4.10110652e-02, -1.79272629e-02],\n",
      "         ...,\n",
      "         [ 4.42594066e-02,  1.09237544e-02,  1.76107734e-02, ...,\n",
      "          -3.32506523e-02, -4.09088396e-02,  2.18813494e-02],\n",
      "         [ 5.83816692e-03,  4.78018373e-02,  1.25013068e-02, ...,\n",
      "           2.22669840e-02, -4.23019454e-02,  6.80809841e-03],\n",
      "         [ 1.42402798e-02, -2.98163909e-02, -3.96282673e-02, ...,\n",
      "          -4.51284386e-02,  3.08402628e-03,  4.34195325e-02]],\n",
      "\n",
      "        [[-2.00307369e-03, -1.76356137e-02,  3.22133973e-02, ...,\n",
      "          -2.74664685e-02, -3.95561755e-02,  3.55522111e-02],\n",
      "         [-3.77787128e-02, -2.53407918e-02,  4.94313762e-02, ...,\n",
      "          -1.95602737e-02,  4.96495068e-02,  3.30401510e-02],\n",
      "         [-1.58879943e-02, -5.51432371e-04,  2.21021101e-02, ...,\n",
      "          -4.20245305e-02,  4.60847691e-02,  4.50351909e-02],\n",
      "         ...,\n",
      "         [ 2.78857350e-02, -2.34136153e-02,  2.70981416e-02, ...,\n",
      "          -2.30721440e-02,  2.53449380e-02,  1.64227635e-02],\n",
      "         [ 3.07287723e-02,  7.09217787e-03, -6.02545962e-03, ...,\n",
      "          -2.89401915e-02, -4.60468568e-02, -2.74681970e-02],\n",
      "         [-4.36167084e-02, -3.90006900e-02,  5.01295701e-02, ...,\n",
      "          -5.10029495e-05,  4.64921445e-02, -3.24069224e-02]]]],\n",
      "      dtype=float32)>, <tf.Variable 'basic_block_3/conv2d_9/bias:0' shape=(128,) dtype=float32, numpy=\n",
      "array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32)>, <tf.Variable 'basic_block_3/batch_normalization_9/gamma:0' shape=(128,) dtype=float32, numpy=\n",
      "array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32)>, <tf.Variable 'basic_block_3/batch_normalization_9/beta:0' shape=(128,) dtype=float32, numpy=\n",
      "array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32)>, <tf.Variable 'basic_block_3/batch_normalization_8/moving_mean:0' shape=(128,) dtype=float32, numpy=\n",
      "array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32)>, <tf.Variable 'basic_block_3/batch_normalization_8/moving_variance:0' shape=(128,) dtype=float32, numpy=\n",
      "array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32)>, <tf.Variable 'basic_block_3/batch_normalization_9/moving_mean:0' shape=(128,) dtype=float32, numpy=\n",
      "array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32)>, <tf.Variable 'basic_block_3/batch_normalization_9/moving_variance:0' shape=(128,) dtype=float32, numpy=\n",
      "array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32)>, <tf.Variable 'basic_block_4/conv2d_10/kernel:0' shape=(3, 3, 128, 256) dtype=float32, numpy=\n",
      "array([[[[-1.79297924e-02,  3.23982872e-02,  3.75593193e-02, ...,\n",
      "           1.20181739e-02,  1.27442665e-02, -3.50643098e-02],\n",
      "         [ 4.80833650e-03, -9.59092379e-03,  3.09685655e-02, ...,\n",
      "          -4.11051214e-02, -3.40647101e-02, -1.32139530e-02],\n",
      "         [-3.20636146e-02, -2.15334892e-02, -3.44471559e-02, ...,\n",
      "           2.37674527e-02,  7.79873133e-03, -7.40564987e-03],\n",
      "         ...,\n",
      "         [-1.28847361e-02,  2.69478448e-02,  2.67046429e-02, ...,\n",
      "           4.29177284e-03, -3.03463247e-02,  2.84290314e-03],\n",
      "         [-1.90183818e-02, -3.00519876e-02, -6.73319027e-03, ...,\n",
      "          -2.15132646e-02, -6.58347085e-03,  1.29615068e-02],\n",
      "         [ 4.03680392e-02, -2.29826570e-03, -2.35679857e-02, ...,\n",
      "          -1.57626346e-03,  3.69511880e-02,  3.62348370e-02]],\n",
      "\n",
      "        [[ 1.83065347e-02, -2.24160850e-02,  3.39649506e-02, ...,\n",
      "          -3.30338888e-02,  1.67318769e-02,  1.18024535e-02],\n",
      "         [ 1.35223381e-02,  1.28514282e-02,  3.74842435e-04, ...,\n",
      "          -1.23191383e-02, -1.46759562e-02, -2.69349627e-02],\n",
      "         [-1.55302286e-02,  1.32083893e-02, -3.75314653e-02, ...,\n",
      "           2.12910362e-02,  4.09635939e-02,  3.22268717e-02],\n",
      "         ...,\n",
      "         [-3.51761281e-02, -1.19912438e-02,  3.95763107e-02, ...,\n",
      "          -7.78162479e-03, -2.86677480e-02,  3.40606980e-02],\n",
      "         [ 9.00857523e-03, -3.56896631e-02,  3.77445035e-02, ...,\n",
      "           1.33427680e-02,  3.56682278e-02,  3.27594392e-02],\n",
      "         [-2.49665789e-02, -3.09694521e-02,  4.22655419e-03, ...,\n",
      "           2.22497620e-02,  3.83375399e-02,  1.17662549e-02]],\n",
      "\n",
      "        [[-7.01485202e-03, -1.33642163e-02, -2.75672283e-02, ...,\n",
      "           3.48871686e-02, -2.96261422e-02,  2.10005790e-04],\n",
      "         [ 3.90490331e-02, -2.08873302e-04,  3.65664475e-02, ...,\n",
      "          -1.48031320e-02,  3.17512043e-02, -1.17046647e-02],\n",
      "         [ 3.32613103e-02,  2.23226584e-02,  1.73764341e-02, ...,\n",
      "          -3.75771634e-02,  1.24979801e-02,  6.67596981e-03],\n",
      "         ...,\n",
      "         [ 6.92578033e-03,  2.56802924e-02, -2.45035198e-02, ...,\n",
      "          -1.51489973e-02, -2.17398908e-02, -1.85364783e-02],\n",
      "         [ 4.05799262e-02, -3.02835815e-02, -1.54551677e-02, ...,\n",
      "           1.24748759e-02,  5.41648269e-03,  3.97280864e-02],\n",
      "         [ 1.41416602e-02, -1.05362050e-02, -2.38551497e-02, ...,\n",
      "          -2.09803693e-02, -4.52477857e-03, -2.63060741e-02]]],\n",
      "\n",
      "\n",
      "       [[[-3.66177373e-02,  3.27241607e-02, -4.01698574e-02, ...,\n",
      "           3.83467264e-02,  3.50249521e-02, -1.56961754e-03],\n",
      "         [-3.99534628e-02,  1.02454014e-02,  2.22064443e-02, ...,\n",
      "           4.11100425e-02,  1.98784359e-02, -9.25211236e-03],\n",
      "         [ 1.13027804e-02,  4.78053093e-03,  6.62752986e-03, ...,\n",
      "           1.99613087e-02, -4.33583930e-03,  1.59110241e-02],\n",
      "         ...,\n",
      "         [ 1.21975951e-02,  2.02619620e-02,  3.30456682e-02, ...,\n",
      "           4.07405086e-02, -3.33938599e-02, -2.17421651e-02],\n",
      "         [ 2.64661647e-02, -3.27780657e-02,  1.60799734e-02, ...,\n",
      "           2.08234787e-03,  3.71212102e-02, -2.20941305e-02],\n",
      "         [-2.52657346e-02, -7.50957802e-03,  3.88555117e-02, ...,\n",
      "           2.85537280e-02,  9.93469357e-03, -3.28599289e-03]],\n",
      "\n",
      "        [[ 1.94351748e-03, -2.00011209e-03, -1.08235776e-02, ...,\n",
      "          -2.99000945e-02,  1.03107691e-02, -3.91942486e-02],\n",
      "         [ 4.04496863e-03,  1.98134668e-02,  1.76917911e-02, ...,\n",
      "          -2.00083852e-02, -2.19700634e-02, -3.59958336e-02],\n",
      "         [-3.41765881e-02,  2.38570571e-03,  4.08631004e-02, ...,\n",
      "          -1.59094539e-02,  3.27139385e-02, -1.57989264e-02],\n",
      "         ...,\n",
      "         [-3.61490957e-02,  5.63381240e-03, -8.43622163e-03, ...,\n",
      "          -1.47095621e-02, -2.17912793e-02, -1.34803262e-02],\n",
      "         [-1.88388433e-02, -1.31443739e-02, -2.18392517e-02, ...,\n",
      "          -4.10627201e-03, -3.18559818e-02,  1.58393495e-02],\n",
      "         [-1.59812868e-02,  1.89053826e-02, -3.47526297e-02, ...,\n",
      "          -3.84334028e-02,  2.61900164e-02,  3.07781287e-02]],\n",
      "\n",
      "        [[-1.99126508e-02, -1.52420811e-02,  3.82562354e-03, ...,\n",
      "           3.67831774e-02, -3.37617323e-02, -3.71488929e-03],\n",
      "         [-1.76804177e-02,  3.24335806e-02,  1.26583502e-03, ...,\n",
      "          -2.35709250e-02,  1.30610578e-02,  6.44475222e-07],\n",
      "         [-3.05577125e-02, -1.12729874e-02,  2.51228921e-02, ...,\n",
      "           2.96285748e-03,  9.31045413e-03, -3.37179899e-02],\n",
      "         ...,\n",
      "         [-5.59698790e-04, -2.06983387e-02, -1.74180176e-02, ...,\n",
      "           1.90235265e-02, -3.83536331e-02, -1.71853714e-02],\n",
      "         [-2.78766658e-02,  3.78784537e-03, -1.59402564e-03, ...,\n",
      "           2.05847919e-02, -2.60181241e-02, -4.06632125e-02],\n",
      "         [ 8.07911158e-03, -1.53162293e-02,  2.16710605e-02, ...,\n",
      "           5.97034767e-03,  2.09052898e-02, -3.83232348e-02]]],\n",
      "\n",
      "\n",
      "       [[[ 8.78655910e-03, -1.79764144e-02, -3.29788439e-02, ...,\n",
      "          -2.74240188e-02,  3.41328122e-02,  2.10356712e-03],\n",
      "         [-2.55188458e-02,  5.26657701e-03,  1.33097954e-02, ...,\n",
      "           3.80193703e-02,  2.71611400e-02, -3.34692225e-02],\n",
      "         [ 4.79901955e-03, -3.51032838e-02,  1.10590160e-02, ...,\n",
      "           4.84764576e-04, -2.60098875e-02, -9.04703140e-03],\n",
      "         ...,\n",
      "         [ 1.25240870e-02, -1.90984011e-02,  3.05588283e-02, ...,\n",
      "           2.00447142e-02, -6.04118034e-03,  1.00678690e-02],\n",
      "         [-4.01504152e-02,  2.81073861e-02, -3.87947857e-02, ...,\n",
      "           3.07847373e-02, -4.82369214e-04, -3.06480527e-02],\n",
      "         [ 2.55648904e-02,  1.37137063e-02, -1.21170282e-03, ...,\n",
      "           1.67461932e-02, -1.86766684e-02,  1.11920349e-02]],\n",
      "\n",
      "        [[-9.22247767e-03,  3.15556712e-02,  9.51237604e-03, ...,\n",
      "          -7.49515370e-03,  2.63441391e-02,  2.95888595e-02],\n",
      "         [-1.36243217e-02, -3.53855118e-02,  1.02058463e-02, ...,\n",
      "           3.53750698e-02, -2.82421913e-02,  2.61317529e-02],\n",
      "         [ 8.91305879e-03, -2.66274810e-03, -3.18897292e-02, ...,\n",
      "           2.05003209e-02,  3.21650617e-02,  3.59286703e-02],\n",
      "         ...,\n",
      "         [-4.10364494e-02,  2.13686712e-02,  1.44347847e-02, ...,\n",
      "           1.95822231e-02,  1.22396648e-02, -7.80867413e-03],\n",
      "         [ 8.36579874e-03, -3.43276933e-03, -1.42676830e-02, ...,\n",
      "          -1.53725557e-02, -1.52977817e-02, -4.06372361e-02],\n",
      "         [ 7.28875399e-04, -4.35829163e-04, -9.81271267e-03, ...,\n",
      "           1.87253542e-02, -3.15399766e-02, -3.90386581e-02]],\n",
      "\n",
      "        [[ 4.02800627e-02, -4.10457253e-02,  3.16788368e-02, ...,\n",
      "           3.64680402e-02, -2.32372191e-02,  3.40217464e-02],\n",
      "         [ 6.74472377e-03,  5.25395200e-03, -3.86766121e-02, ...,\n",
      "          -1.51604917e-02, -1.94998793e-02,  1.95784681e-02],\n",
      "         [-2.05752365e-02, -2.25177705e-02,  5.40565699e-04, ...,\n",
      "           1.99238472e-02, -1.66944265e-02, -3.51111107e-02],\n",
      "         ...,\n",
      "         [ 2.58776434e-02,  9.79261473e-03, -1.36487186e-02, ...,\n",
      "          -2.30155885e-02, -3.56593058e-02,  3.15645672e-02],\n",
      "         [ 3.98811214e-02,  1.43132992e-02,  1.29517615e-02, ...,\n",
      "           2.81723626e-02, -9.96679068e-03, -3.09654977e-02],\n",
      "         [-2.96466053e-02,  1.86377876e-02,  2.41734572e-02, ...,\n",
      "           2.39971317e-02, -2.42580678e-02,  9.83107090e-03]]]],\n",
      "      dtype=float32)>, <tf.Variable 'basic_block_4/conv2d_10/bias:0' shape=(256,) dtype=float32, numpy=\n",
      "array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0.], dtype=float32)>, <tf.Variable 'basic_block_4/batch_normalization_10/gamma:0' shape=(256,) dtype=float32, numpy=\n",
      "array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1.], dtype=float32)>, <tf.Variable 'basic_block_4/batch_normalization_10/beta:0' shape=(256,) dtype=float32, numpy=\n",
      "array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0.], dtype=float32)>, <tf.Variable 'basic_block_4/conv2d_11/kernel:0' shape=(3, 3, 256, 256) dtype=float32, numpy=\n",
      "array([[[[ 0.01326066,  0.01097598, -0.01113579, ...,  0.01538663,\n",
      "          -0.02769392, -0.03424105],\n",
      "         [ 0.03572837,  0.01746584, -0.02827379, ..., -0.0167403 ,\n",
      "           0.00895209, -0.02159664],\n",
      "         [ 0.00212499, -0.01308511, -0.02144978, ...,  0.00388285,\n",
      "           0.02799322, -0.01479064],\n",
      "         ...,\n",
      "         [-0.02057844,  0.02899751,  0.01424242, ...,  0.03419743,\n",
      "           0.0205022 , -0.00308901],\n",
      "         [ 0.01439686, -0.00089433, -0.00095328, ...,  0.00481095,\n",
      "          -0.00781607,  0.03550719],\n",
      "         [ 0.03469992, -0.02101058, -0.00810983, ..., -0.00712864,\n",
      "           0.00260441,  0.02363342]],\n",
      "\n",
      "        [[-0.03424674,  0.03112388, -0.00899082, ...,  0.02305905,\n",
      "           0.01662215,  0.00375327],\n",
      "         [-0.03388552, -0.01072973,  0.00965018, ..., -0.01725432,\n",
      "          -0.01511615,  0.0077028 ],\n",
      "         [-0.00992897,  0.01712554, -0.00022077, ..., -0.00054731,\n",
      "          -0.00037046, -0.00754467],\n",
      "         ...,\n",
      "         [-0.00253308,  0.00762993,  0.00761817, ...,  0.00398828,\n",
      "           0.02709023, -0.02441859],\n",
      "         [-0.02836962, -0.01248225,  0.02562952, ...,  0.01154672,\n",
      "          -0.02423707, -0.01288828],\n",
      "         [-0.01603924,  0.01953248, -0.02833368, ..., -0.01808862,\n",
      "          -0.0183759 , -0.01425944]],\n",
      "\n",
      "        [[ 0.00705539,  0.01625025,  0.00169533, ...,  0.00930905,\n",
      "           0.01144799,  0.03548329],\n",
      "         [-0.00707567, -0.00744535, -0.03558401, ..., -0.02723512,\n",
      "          -0.00318643, -0.01893061],\n",
      "         [-0.02330909, -0.03200103, -0.01005072, ...,  0.00117286,\n",
      "          -0.02349554, -0.03050705],\n",
      "         ...,\n",
      "         [-0.02107537, -0.00583927, -0.00180832, ..., -0.03422419,\n",
      "           0.0053198 ,  0.00798044],\n",
      "         [ 0.01498529,  0.01365736, -0.02078235, ...,  0.02987553,\n",
      "          -0.01405916, -0.00620689],\n",
      "         [-0.00964999,  0.02472959,  0.03148638, ...,  0.01626915,\n",
      "           0.00955082,  0.00103566]]],\n",
      "\n",
      "\n",
      "       [[[ 0.02616829, -0.00015425,  0.01347788, ..., -0.01492031,\n",
      "          -0.02483825,  0.03185894],\n",
      "         [-0.01616035,  0.01544685, -0.02806906, ..., -0.02983717,\n",
      "          -0.0337485 , -0.01212662],\n",
      "         [ 0.01822855,  0.03169011, -0.03158687, ..., -0.00909344,\n",
      "          -0.01085852, -0.02297612],\n",
      "         ...,\n",
      "         [ 0.01456411,  0.02289808, -0.00873808, ..., -0.01102235,\n",
      "          -0.00712668,  0.02671061],\n",
      "         [ 0.00928401,  0.02567258, -0.01664438, ..., -0.03121413,\n",
      "           0.03077943, -0.02610152],\n",
      "         [-0.0216597 ,  0.02708616,  0.0309992 , ...,  0.02467805,\n",
      "          -0.00198327,  0.02688657]],\n",
      "\n",
      "        [[ 0.00212876,  0.00012205, -0.03352474, ..., -0.02095529,\n",
      "           0.00056513,  0.00692536],\n",
      "         [-0.00192373, -0.02929365, -0.03475301, ...,  0.03160781,\n",
      "           0.01679612, -0.01366526],\n",
      "         [ 0.03201868,  0.00382708, -0.01611277, ...,  0.00453444,\n",
      "          -0.00900946,  0.0186255 ],\n",
      "         ...,\n",
      "         [-0.00686337,  0.03131101, -0.01764867, ..., -0.03268241,\n",
      "          -0.02878403,  0.02251991],\n",
      "         [-0.02364648,  0.03557488, -0.0348442 , ..., -0.0099919 ,\n",
      "           0.02306955, -0.03250467],\n",
      "         [ 0.01788169,  0.02757673,  0.00300968, ...,  0.00293206,\n",
      "           0.00851814,  0.00204479]],\n",
      "\n",
      "        [[ 0.01639697,  0.00509368,  0.02259585, ...,  0.00489213,\n",
      "          -0.00802806, -0.00179518],\n",
      "         [ 0.03193009, -0.01937271,  0.00578782, ..., -0.02112907,\n",
      "           0.01614539, -0.01758048],\n",
      "         [-0.02954048, -0.03177197, -0.00061463, ..., -0.02675535,\n",
      "          -0.00934067, -0.0169431 ],\n",
      "         ...,\n",
      "         [-0.0197247 , -0.0018267 , -0.00732093, ..., -0.03373504,\n",
      "           0.0256348 ,  0.03351022],\n",
      "         [-0.02030684,  0.01073601, -0.03119654, ...,  0.02503547,\n",
      "           0.03184699,  0.02677837],\n",
      "         [-0.03327906,  0.01116311,  0.02270209, ...,  0.00112772,\n",
      "          -0.01347733, -0.03252656]]],\n",
      "\n",
      "\n",
      "       [[[-0.02426179,  0.0143093 ,  0.00335406, ..., -0.01397975,\n",
      "          -0.01177336, -0.01441435],\n",
      "         [ 0.0276048 ,  0.03227661,  0.00233166, ...,  0.02467316,\n",
      "           0.00680868, -0.00188344],\n",
      "         [ 0.03005201,  0.03044371, -0.03104926, ..., -0.01877578,\n",
      "           0.01829942, -0.0056465 ],\n",
      "         ...,\n",
      "         [-0.02793833,  0.01545304, -0.0093691 , ...,  0.00015578,\n",
      "          -0.02680749,  0.00744247],\n",
      "         [ 0.02874617,  0.02593363,  0.00165642, ..., -0.01454459,\n",
      "          -0.02108652,  0.00288034],\n",
      "         [-0.03494561, -0.0290289 , -0.01732946, ..., -0.0143397 ,\n",
      "          -0.03569041, -0.00640514]],\n",
      "\n",
      "        [[ 0.00385974, -0.01543449, -0.01381309, ..., -0.03209478,\n",
      "          -0.03120248,  0.02390465],\n",
      "         [-0.00956955,  0.03116529,  0.00398577, ...,  0.03540875,\n",
      "          -0.03525771, -0.01791396],\n",
      "         [ 0.00629738, -0.01429834, -0.03020648, ..., -0.02515522,\n",
      "           0.02071482,  0.01125071],\n",
      "         ...,\n",
      "         [ 0.01740012, -0.0114838 , -0.00846605, ..., -0.02348116,\n",
      "          -0.01938436,  0.01831555],\n",
      "         [ 0.00983036,  0.01644499, -0.00848408, ..., -0.01337022,\n",
      "           0.03009036, -0.0345794 ],\n",
      "         [ 0.03121464, -0.0045736 ,  0.01807853, ..., -0.03118379,\n",
      "           0.01862079, -0.00683079]],\n",
      "\n",
      "        [[ 0.02159313,  0.01850181, -0.02451656, ..., -0.02808897,\n",
      "           0.0136188 ,  0.02566416],\n",
      "         [-0.02071241, -0.03364921,  0.01750273, ..., -0.00618545,\n",
      "           0.00508654,  0.02426358],\n",
      "         [ 0.03343197,  0.03466411, -0.03577875, ..., -0.01979846,\n",
      "          -0.00149078, -0.01916049],\n",
      "         ...,\n",
      "         [-0.00556314, -0.01327144, -0.02421215, ...,  0.03324579,\n",
      "          -0.03379844, -0.03260176],\n",
      "         [-0.01136986,  0.0307988 ,  0.02276162, ...,  0.02758197,\n",
      "           0.03148728, -0.01148526],\n",
      "         [ 0.01200181,  0.01041172, -0.03500381, ..., -0.02384344,\n",
      "          -0.03591324,  0.01794415]]]], dtype=float32)>, <tf.Variable 'basic_block_4/conv2d_11/bias:0' shape=(256,) dtype=float32, numpy=\n",
      "array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0.], dtype=float32)>, <tf.Variable 'basic_block_4/batch_normalization_11/gamma:0' shape=(256,) dtype=float32, numpy=\n",
      "array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1.], dtype=float32)>, <tf.Variable 'basic_block_4/batch_normalization_11/beta:0' shape=(256,) dtype=float32, numpy=\n",
      "array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0.], dtype=float32)>, <tf.Variable 'conv2d_12/kernel:0' shape=(1, 1, 128, 256) dtype=float32, numpy=\n",
      "array([[[[ 0.12066895, -0.06831008, -0.02603969, ...,  0.0096198 ,\n",
      "          -0.07591298, -0.00823322],\n",
      "         [ 0.09058899, -0.05870292,  0.07013994, ..., -0.0611352 ,\n",
      "          -0.03237468, -0.09788015],\n",
      "         [ 0.08333862, -0.00575349, -0.00335938, ..., -0.04080704,\n",
      "           0.09566164, -0.02900657],\n",
      "         ...,\n",
      "         [-0.03467378, -0.06207955,  0.10588637, ...,  0.02522627,\n",
      "          -0.0335449 , -0.05681908],\n",
      "         [ 0.0672445 , -0.04346955,  0.09053171, ...,  0.05165038,\n",
      "           0.03150767, -0.02490792],\n",
      "         [-0.11044917, -0.06595722, -0.03109342, ...,  0.12349167,\n",
      "          -0.11566722,  0.0272738 ]]]], dtype=float32)>, <tf.Variable 'conv2d_12/bias:0' shape=(256,) dtype=float32, numpy=\n",
      "array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0.], dtype=float32)>, <tf.Variable 'batch_normalization_12/gamma:0' shape=(256,) dtype=float32, numpy=\n",
      "array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1.], dtype=float32)>, <tf.Variable 'batch_normalization_12/beta:0' shape=(256,) dtype=float32, numpy=\n",
      "array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0.], dtype=float32)>, <tf.Variable 'basic_block_4/batch_normalization_10/moving_mean:0' shape=(256,) dtype=float32, numpy=\n",
      "array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0.], dtype=float32)>, <tf.Variable 'basic_block_4/batch_normalization_10/moving_variance:0' shape=(256,) dtype=float32, numpy=\n",
      "array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1.], dtype=float32)>, <tf.Variable 'basic_block_4/batch_normalization_11/moving_mean:0' shape=(256,) dtype=float32, numpy=\n",
      "array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0.], dtype=float32)>, <tf.Variable 'basic_block_4/batch_normalization_11/moving_variance:0' shape=(256,) dtype=float32, numpy=\n",
      "array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1.], dtype=float32)>, <tf.Variable 'batch_normalization_12/moving_mean:0' shape=(256,) dtype=float32, numpy=\n",
      "array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0.], dtype=float32)>, <tf.Variable 'batch_normalization_12/moving_variance:0' shape=(256,) dtype=float32, numpy=\n",
      "array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1.], dtype=float32)>, <tf.Variable 'basic_block_5/conv2d_13/kernel:0' shape=(3, 3, 256, 256) dtype=float32, numpy=\n",
      "array([[[[ 0.01069016,  0.03303237, -0.02148251, ..., -0.03491822,\n",
      "           0.01891766,  0.03082564],\n",
      "         [-0.01026942,  0.01632446, -0.00700308, ..., -0.02441362,\n",
      "           0.01886942,  0.02354242],\n",
      "         [-0.00539235,  0.02856146,  0.0056546 , ..., -0.02036842,\n",
      "          -0.00870703,  0.03216051],\n",
      "         ...,\n",
      "         [-0.03195171, -0.01872759, -0.00537579, ...,  0.02023921,\n",
      "          -0.01507508,  0.02588325],\n",
      "         [-0.00967356, -0.0078299 , -0.0125672 , ...,  0.00527347,\n",
      "           0.01357687, -0.01486601],\n",
      "         [-0.03204067, -0.00436695, -0.01527064, ...,  0.00191253,\n",
      "           0.02286059,  0.00623085]],\n",
      "\n",
      "        [[-0.0108818 , -0.00449328, -0.01169483, ..., -0.01891957,\n",
      "           0.02411032, -0.0084125 ],\n",
      "         [ 0.00610781,  0.02985454, -0.00271781, ..., -0.02217211,\n",
      "          -0.01910993, -0.01327311],\n",
      "         [ 0.01642611,  0.00764899, -0.03437679, ...,  0.0026699 ,\n",
      "          -0.02277844, -0.01119279],\n",
      "         ...,\n",
      "         [ 0.02503282,  0.03134166, -0.02109596, ..., -0.0225854 ,\n",
      "          -0.02703815,  0.01802207],\n",
      "         [ 0.02832357,  0.01786565,  0.00953294, ...,  0.02684012,\n",
      "          -0.03506506,  0.01290239],\n",
      "         [-0.01797421, -0.0227026 , -0.00222013, ...,  0.01971589,\n",
      "           0.01686316, -0.03572774]],\n",
      "\n",
      "        [[ 0.01401886, -0.03036622,  0.00451386, ..., -0.0336057 ,\n",
      "           0.00366493, -0.03548926],\n",
      "         [-0.03071501,  0.03056257, -0.01296426, ..., -0.0075466 ,\n",
      "          -0.01250863,  0.03368491],\n",
      "         [ 0.02989158, -0.00684129,  0.00133379, ...,  0.01840223,\n",
      "           0.0158927 , -0.0176684 ],\n",
      "         ...,\n",
      "         [ 0.00303658,  0.0169487 ,  0.02934635, ..., -0.009335  ,\n",
      "          -0.01354346, -0.0007497 ],\n",
      "         [-0.01400148,  0.00508818,  0.03180409, ...,  0.01962828,\n",
      "          -0.00535609,  0.03400932],\n",
      "         [-0.01653725, -0.03346532, -0.02152741, ..., -0.02185797,\n",
      "          -0.01463014,  0.0323196 ]]],\n",
      "\n",
      "\n",
      "       [[[ 0.0036185 , -0.02058617,  0.01326637, ..., -0.02328971,\n",
      "           0.00976865,  0.00293562],\n",
      "         [-0.01565751, -0.01085582,  0.00615586, ..., -0.01121363,\n",
      "           0.02187015,  0.02198531],\n",
      "         [ 0.02917521, -0.03111858,  0.004165  , ..., -0.02482693,\n",
      "           0.01403325,  0.00658546],\n",
      "         ...,\n",
      "         [ 0.01537208, -0.02586329,  0.02887093, ...,  0.02045162,\n",
      "           0.02360045, -0.0254538 ],\n",
      "         [-0.01128144,  0.00356224,  0.0057961 , ...,  0.01613822,\n",
      "           0.03306206,  0.01463168],\n",
      "         [-0.00508885,  0.02149186, -0.00815086, ...,  0.02286642,\n",
      "           0.0021045 ,  0.00598832]],\n",
      "\n",
      "        [[-0.01892253,  0.03012061, -0.01952107, ...,  0.03207844,\n",
      "           0.0131624 ,  0.01033375],\n",
      "         [ 0.0287885 , -0.00279202,  0.03181838, ..., -0.02439891,\n",
      "           0.00714904,  0.02647565],\n",
      "         [ 0.01812862,  0.03304433, -0.03155167, ...,  0.01816668,\n",
      "           0.00264676, -0.01503178],\n",
      "         ...,\n",
      "         [-0.02823675, -0.00563641, -0.00810204, ..., -0.00784514,\n",
      "          -0.00203236,  0.00748522],\n",
      "         [ 0.01621498,  0.00960178, -0.03398328, ..., -0.01514541,\n",
      "          -0.00754866,  0.02102119],\n",
      "         [ 0.00668826,  0.01210535, -0.01821804, ..., -0.00392178,\n",
      "           0.00104308, -0.01284813]],\n",
      "\n",
      "        [[-0.00348128, -0.02529547,  0.02399549, ...,  0.02388645,\n",
      "          -0.00559553,  0.00972863],\n",
      "         [-0.01274991, -0.0069507 ,  0.0019279 , ..., -0.02146713,\n",
      "          -0.02994935,  0.00526807],\n",
      "         [-0.00526907, -0.01675522,  0.03421778, ..., -0.03090732,\n",
      "           0.00536937, -0.01533423],\n",
      "         ...,\n",
      "         [ 0.020592  , -0.02339845,  0.03304025, ...,  0.00579373,\n",
      "           0.03271171, -0.0279838 ],\n",
      "         [ 0.01377865, -0.00099818, -0.01529749, ..., -0.0256816 ,\n",
      "           0.01974506, -0.00892416],\n",
      "         [-0.00244871, -0.03596815, -0.02681952, ..., -0.02594588,\n",
      "           0.0328104 ,  0.02093541]]],\n",
      "\n",
      "\n",
      "       [[[ 0.00322   , -0.0109629 , -0.02549738, ...,  0.00776541,\n",
      "           0.00495622,  0.01355704],\n",
      "         [-0.00905819,  0.01482371,  0.01589526, ..., -0.03543039,\n",
      "           0.00032061,  0.0132118 ],\n",
      "         [-0.01199349,  0.0115856 , -0.02736103, ...,  0.02904133,\n",
      "          -0.00331355, -0.02610233],\n",
      "         ...,\n",
      "         [-0.00431472,  0.03453137, -0.00900974, ...,  0.0336551 ,\n",
      "          -0.02854965, -0.02218905],\n",
      "         [-0.00241473,  0.0303859 , -0.00912006, ..., -0.02857785,\n",
      "          -0.02872305,  0.02011401],\n",
      "         [-0.03139234,  0.01738748, -0.03587219, ..., -0.01531562,\n",
      "          -0.01145767,  0.02891482]],\n",
      "\n",
      "        [[ 0.01803587,  0.03081453, -0.03084629, ..., -0.03597724,\n",
      "           0.0049472 ,  0.0308025 ],\n",
      "         [ 0.03260832,  0.01937037,  0.02829076, ...,  0.01113309,\n",
      "           0.01639869,  0.01415198],\n",
      "         [ 0.03536779,  0.02173202,  0.00447835, ...,  0.01653299,\n",
      "          -0.02799541,  0.02519313],\n",
      "         ...,\n",
      "         [-0.02475571, -0.00149207, -0.01811198, ..., -0.00820524,\n",
      "          -0.00075299, -0.02446709],\n",
      "         [-0.01542086,  0.0340353 ,  0.0260104 , ..., -0.03469959,\n",
      "          -0.00117707, -0.01211666],\n",
      "         [-0.02263534,  0.01436689,  0.00432728, ..., -0.00437552,\n",
      "           0.03306787, -0.01300247]],\n",
      "\n",
      "        [[-0.01892844,  0.02326592,  0.02027212, ..., -0.02950104,\n",
      "           0.0306334 ,  0.01955979],\n",
      "         [-0.0281079 , -0.03090434, -0.03241143, ..., -0.02141489,\n",
      "          -0.00244666,  0.02067105],\n",
      "         [-0.00421239, -0.01455729,  0.00323619, ..., -0.00896227,\n",
      "          -0.01982598,  0.03283668],\n",
      "         ...,\n",
      "         [ 0.02829438, -0.00871611,  0.00695512, ..., -0.01892733,\n",
      "          -0.01776233, -0.00707658],\n",
      "         [ 0.00409292, -0.0256527 ,  0.02285977, ...,  0.00915202,\n",
      "           0.00641031,  0.00143017],\n",
      "         [-0.01273876,  0.01171464,  0.01680071, ..., -0.02267233,\n",
      "           0.02340866,  0.02045017]]]], dtype=float32)>, <tf.Variable 'basic_block_5/conv2d_13/bias:0' shape=(256,) dtype=float32, numpy=\n",
      "array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0.], dtype=float32)>, <tf.Variable 'basic_block_5/batch_normalization_13/gamma:0' shape=(256,) dtype=float32, numpy=\n",
      "array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1.], dtype=float32)>, <tf.Variable 'basic_block_5/batch_normalization_13/beta:0' shape=(256,) dtype=float32, numpy=\n",
      "array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0.], dtype=float32)>, <tf.Variable 'basic_block_5/conv2d_14/kernel:0' shape=(3, 3, 256, 256) dtype=float32, numpy=\n",
      "array([[[[ 0.02168908, -0.03471548, -0.00740107, ..., -0.01779934,\n",
      "           0.01252352, -0.0033284 ],\n",
      "         [ 0.00069322,  0.0024136 , -0.01150901, ..., -0.01461496,\n",
      "          -0.00171455,  0.02656145],\n",
      "         [ 0.00941888, -0.03337662, -0.01148978, ...,  0.01301957,\n",
      "          -0.0304491 , -0.00928245],\n",
      "         ...,\n",
      "         [-0.01664941, -0.00093875, -0.00734212, ..., -0.01926537,\n",
      "           0.02366831, -0.02391103],\n",
      "         [ 0.00664295, -0.03027128, -0.0290427 , ...,  0.03190217,\n",
      "           0.02723788,  0.00733107],\n",
      "         [ 0.01790153, -0.02684229,  0.03280077, ..., -0.01389844,\n",
      "           0.00108229,  0.02019511]],\n",
      "\n",
      "        [[ 0.01265159, -0.01542285,  0.03082854, ...,  0.00492607,\n",
      "           0.00142376,  0.0207253 ],\n",
      "         [-0.0063498 ,  0.00569696, -0.01746102, ...,  0.0220794 ,\n",
      "           0.02815419, -0.01130527],\n",
      "         [ 0.02354901, -0.00263156,  0.03487401, ..., -0.00982814,\n",
      "           0.01350125, -0.0063092 ],\n",
      "         ...,\n",
      "         [-0.00555789,  0.00180778,  0.00191574, ...,  0.02910715,\n",
      "          -0.0016356 ,  0.03515916],\n",
      "         [-0.01617935,  0.02145309,  0.00556841, ..., -0.00930132,\n",
      "          -0.01897799, -0.00244475],\n",
      "         [-0.00795638,  0.01442499, -0.00499676, ..., -0.0304807 ,\n",
      "          -0.00429738, -0.00401032]],\n",
      "\n",
      "        [[ 0.03233476,  0.00204535, -0.01500583, ..., -0.02737718,\n",
      "          -0.03446979, -0.0032929 ],\n",
      "         [ 0.00207572, -0.0133876 , -0.03239546, ...,  0.00064146,\n",
      "           0.02047741, -0.0057721 ],\n",
      "         [ 0.02475649, -0.02517806, -0.00348016, ..., -0.0301709 ,\n",
      "           0.00571913, -0.00597411],\n",
      "         ...,\n",
      "         [ 0.02030605, -0.01095131,  0.02853848, ...,  0.02414856,\n",
      "           0.00547444,  0.00029657],\n",
      "         [ 0.01654835, -0.02082524,  0.02683728, ...,  0.02612985,\n",
      "           0.02830084, -0.03100313],\n",
      "         [ 0.02092412,  0.00561853, -0.03377507, ..., -0.01705225,\n",
      "           0.01142246,  0.02111049]]],\n",
      "\n",
      "\n",
      "       [[[-0.00991776, -0.02588202,  0.03224804, ...,  0.03164346,\n",
      "          -0.0161649 , -0.01654513],\n",
      "         [ 0.00124619,  0.00181351,  0.01189646, ..., -0.00104924,\n",
      "          -0.01819342, -0.00675597],\n",
      "         [-0.00853566, -0.01682364, -0.02153879, ..., -0.01119983,\n",
      "          -0.01153539,  0.02258821],\n",
      "         ...,\n",
      "         [ 0.02490573, -0.02304355, -0.03490392, ...,  0.00035173,\n",
      "           0.01992768, -0.02970199],\n",
      "         [ 0.01242472,  0.03537439, -0.0325846 , ..., -0.02181777,\n",
      "           0.01013396, -0.0004912 ],\n",
      "         [ 0.02131265, -0.02907249, -0.0169763 , ..., -0.01019731,\n",
      "           0.00455206, -0.01448105]],\n",
      "\n",
      "        [[-0.02227076, -0.0037731 ,  0.00604223, ..., -0.00016288,\n",
      "           0.00899447,  0.01938009],\n",
      "         [ 0.00035097,  0.02393282,  0.00536315, ..., -0.01114911,\n",
      "          -0.00116474,  0.01945294],\n",
      "         [-0.02960426,  0.00559292, -0.02471836, ..., -0.01806061,\n",
      "          -0.03400948,  0.01345197],\n",
      "         ...,\n",
      "         [-0.00159786, -0.01107778,  0.006973  , ...,  0.00362946,\n",
      "           0.03588849, -0.01585872],\n",
      "         [-0.00994047, -0.00882812,  0.02502535, ...,  0.0274444 ,\n",
      "          -0.03556189,  0.03529432],\n",
      "         [ 0.0166612 , -0.01415853,  0.00416852, ..., -0.02082402,\n",
      "          -0.00021383, -0.00624904]],\n",
      "\n",
      "        [[-0.02565015,  0.02950304, -0.0155186 , ..., -0.02904512,\n",
      "          -0.01881772, -0.00803995],\n",
      "         [-0.00882417,  0.0090436 , -0.0138667 , ..., -0.00724472,\n",
      "           0.01793178,  0.01184253],\n",
      "         [-0.03010297,  0.01409943, -0.02199098, ..., -0.00926918,\n",
      "          -0.03406908, -0.03215044],\n",
      "         ...,\n",
      "         [ 0.02717982, -0.02669516, -0.00078994, ..., -0.01279233,\n",
      "           0.02187118,  0.01300092],\n",
      "         [-0.01952851, -0.03136069, -0.01739905, ...,  0.01881209,\n",
      "           0.01658558,  0.02911609],\n",
      "         [-0.00972875,  0.01348327,  0.03101707, ...,  0.00244934,\n",
      "           0.02624918, -0.00075973]]],\n",
      "\n",
      "\n",
      "       [[[-0.01104749, -0.01826021,  0.0271846 , ...,  0.01493021,\n",
      "          -0.02562912,  0.03044166],\n",
      "         [ 0.02538986, -0.0219915 ,  0.00530581, ...,  0.0221375 ,\n",
      "          -0.01834247, -0.0258498 ],\n",
      "         [ 0.01782137, -0.00018121, -0.0280453 , ..., -0.01485071,\n",
      "          -0.00372047, -0.02724052],\n",
      "         ...,\n",
      "         [ 0.00974512, -0.03135838, -0.03286891, ...,  0.01892213,\n",
      "           0.03237226, -0.02057206],\n",
      "         [-0.02432744, -0.01292516,  0.01359901, ..., -0.01083177,\n",
      "           0.02570586, -0.02508   ],\n",
      "         [-0.03576634,  0.00085599,  0.03551831, ..., -0.0136524 ,\n",
      "          -0.00060506,  0.00532468]],\n",
      "\n",
      "        [[ 0.02348777, -0.03373735, -0.02437137, ..., -0.01865935,\n",
      "           0.00176633, -0.02741822],\n",
      "         [ 0.02374963, -0.01097868, -0.02284429, ...,  0.01671558,\n",
      "          -0.0214506 , -0.02751802],\n",
      "         [-0.02863674, -0.02887548, -0.00214276, ...,  0.025942  ,\n",
      "           0.01649768,  0.02727374],\n",
      "         ...,\n",
      "         [-0.00079029, -0.03217249, -0.00979733, ...,  0.02318704,\n",
      "          -0.03422681,  0.02480012],\n",
      "         [ 0.00678601,  0.01187813,  0.03122664, ..., -0.01843164,\n",
      "          -0.01751632, -0.01597143],\n",
      "         [-0.00678987,  0.01807815,  0.01027919, ...,  0.00904151,\n",
      "           0.02485701,  0.02008709]],\n",
      "\n",
      "        [[ 0.00408075,  0.0279442 ,  0.01755857, ...,  0.00305991,\n",
      "           0.02042642, -0.02426772],\n",
      "         [ 0.02489965, -0.00893734, -0.02202981, ...,  0.01803822,\n",
      "           0.01908579,  0.01935   ],\n",
      "         [-0.02070854,  0.02718608,  0.02677781, ..., -0.00135   ,\n",
      "          -0.01876273,  0.02783407],\n",
      "         ...,\n",
      "         [-0.03518043,  0.00011045,  0.03215411, ..., -0.01261785,\n",
      "          -0.02622032, -0.0159761 ],\n",
      "         [ 0.0107046 ,  0.02365555, -0.02350097, ..., -0.00465578,\n",
      "           0.00970775,  0.03056519],\n",
      "         [ 0.00055043, -0.03133543,  0.03603147, ...,  0.01678529,\n",
      "           0.03454381,  0.02622644]]]], dtype=float32)>, <tf.Variable 'basic_block_5/conv2d_14/bias:0' shape=(256,) dtype=float32, numpy=\n",
      "array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0.], dtype=float32)>, <tf.Variable 'basic_block_5/batch_normalization_14/gamma:0' shape=(256,) dtype=float32, numpy=\n",
      "array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1.], dtype=float32)>, <tf.Variable 'basic_block_5/batch_normalization_14/beta:0' shape=(256,) dtype=float32, numpy=\n",
      "array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0.], dtype=float32)>, <tf.Variable 'basic_block_5/batch_normalization_13/moving_mean:0' shape=(256,) dtype=float32, numpy=\n",
      "array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0.], dtype=float32)>, <tf.Variable 'basic_block_5/batch_normalization_13/moving_variance:0' shape=(256,) dtype=float32, numpy=\n",
      "array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1.], dtype=float32)>, <tf.Variable 'basic_block_5/batch_normalization_14/moving_mean:0' shape=(256,) dtype=float32, numpy=\n",
      "array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0.], dtype=float32)>, <tf.Variable 'basic_block_5/batch_normalization_14/moving_variance:0' shape=(256,) dtype=float32, numpy=\n",
      "array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1.], dtype=float32)>, <tf.Variable 'basic_block_6/conv2d_15/kernel:0' shape=(3, 3, 256, 512) dtype=float32, numpy=\n",
      "array([[[[-1.38947833e-02, -1.20017510e-02,  7.15869106e-03, ...,\n",
      "           2.68698949e-02,  1.92911197e-02,  1.78016853e-02],\n",
      "         [-1.18195210e-02, -1.03386715e-02, -2.16355585e-02, ...,\n",
      "          -5.92203997e-03,  1.18872803e-02,  8.94839503e-03],\n",
      "         [ 2.81323548e-02,  2.84976829e-02, -7.40015134e-03, ...,\n",
      "           9.46566276e-03,  2.09142622e-02,  1.88666768e-03],\n",
      "         ...,\n",
      "         [ 8.00991617e-03,  1.44258607e-02, -2.51796376e-02, ...,\n",
      "          -2.83836555e-02, -1.55752907e-02, -1.58743709e-02],\n",
      "         [ 1.40935984e-02, -1.95256099e-02, -1.13135632e-02, ...,\n",
      "          -2.31420472e-02,  3.95815261e-03,  2.88932454e-02],\n",
      "         [-1.35848485e-03, -6.04113936e-03, -1.60894170e-03, ...,\n",
      "           2.31181644e-03, -3.84653918e-03,  1.33709740e-02]],\n",
      "\n",
      "        [[-1.82965919e-02, -2.19663791e-03,  1.77080203e-02, ...,\n",
      "           5.74346446e-03,  1.95742976e-02,  2.53874566e-02],\n",
      "         [ 1.09125841e-02,  1.05761420e-02,  1.97547395e-02, ...,\n",
      "           2.15449128e-02, -9.43597406e-05, -9.28621739e-04],\n",
      "         [-9.34312679e-03,  2.77123787e-03,  2.92946603e-02, ...,\n",
      "           1.83859281e-03, -1.47288553e-02, -7.97611475e-03],\n",
      "         ...,\n",
      "         [-1.23928171e-02,  1.84878614e-02,  8.30367208e-06, ...,\n",
      "           1.88586768e-02, -2.32066810e-02,  6.62448071e-03],\n",
      "         [-1.25395451e-02, -2.60849167e-02, -2.18249094e-02, ...,\n",
      "           2.32054852e-03,  2.12322678e-02,  2.03305241e-02],\n",
      "         [ 9.77599807e-03, -1.61983334e-02,  1.45201217e-02, ...,\n",
      "          -2.69297324e-03, -1.51830157e-02, -4.04382870e-03]],\n",
      "\n",
      "        [[-1.47997392e-02, -2.09794641e-02,  1.79367978e-02, ...,\n",
      "           2.64858250e-02, -5.30210137e-03,  2.40861718e-02],\n",
      "         [ 6.68321736e-03, -7.04182498e-03,  5.81313111e-03, ...,\n",
      "          -1.99672729e-02, -1.86179988e-02, -9.21682082e-03],\n",
      "         [ 1.48937907e-02,  2.54077278e-03, -8.65816325e-03, ...,\n",
      "          -3.41237709e-03,  1.33221541e-02, -4.73770685e-03],\n",
      "         ...,\n",
      "         [-3.51814553e-03,  1.97020080e-02, -9.27813724e-03, ...,\n",
      "          -1.40863974e-02, -1.09659508e-04, -2.68441848e-02],\n",
      "         [-5.65473735e-03, -7.47505948e-03,  2.81692315e-02, ...,\n",
      "          -1.09873191e-02, -1.27464365e-02,  2.21843459e-03],\n",
      "         [-5.95450029e-03,  1.96764674e-02, -1.19692981e-02, ...,\n",
      "          -2.21862067e-02, -2.90679373e-02, -2.25935839e-02]]],\n",
      "\n",
      "\n",
      "       [[[ 2.80277673e-02,  3.30874696e-04,  2.86511052e-02, ...,\n",
      "           2.22278889e-02,  7.14465789e-03, -2.24832930e-02],\n",
      "         [-1.80969238e-02,  1.24845300e-02,  2.74421852e-02, ...,\n",
      "           2.81551350e-02,  2.13735607e-02, -2.34966502e-02],\n",
      "         [ 9.86621343e-03, -4.56516445e-03,  5.29100187e-03, ...,\n",
      "          -9.55254026e-03,  7.21667148e-03,  1.72796864e-02],\n",
      "         ...,\n",
      "         [-7.47170858e-03,  4.66688536e-03,  2.73955055e-03, ...,\n",
      "          -1.32343136e-02,  2.42571067e-02, -1.89283323e-02],\n",
      "         [ 1.82111282e-02, -1.63450744e-02, -2.21971013e-02, ...,\n",
      "           2.85282750e-02,  2.13689562e-02,  2.71358155e-03],\n",
      "         [-9.42546129e-03, -4.25107777e-03,  1.49244573e-02, ...,\n",
      "          -1.86744332e-02,  1.90353561e-02,  2.12333519e-02]],\n",
      "\n",
      "        [[-1.34708006e-02, -9.41780396e-03, -2.61857659e-02, ...,\n",
      "           9.14590992e-03, -3.37693840e-04, -7.96610489e-03],\n",
      "         [-2.15191692e-02, -2.10254267e-02,  7.70664401e-03, ...,\n",
      "           1.13385227e-02, -2.49761865e-02, -1.65790953e-02],\n",
      "         [ 1.74829010e-02, -1.66780278e-02,  1.77056883e-02, ...,\n",
      "          -1.25520136e-02,  5.52015565e-03,  1.11922156e-02],\n",
      "         ...,\n",
      "         [ 2.38347799e-04,  3.55189107e-03, -1.04665868e-02, ...,\n",
      "          -3.26097943e-03,  1.21559929e-02,  1.13934260e-02],\n",
      "         [-9.65430401e-03,  6.79340400e-03, -1.88541040e-02, ...,\n",
      "           3.94019671e-03, -8.77558440e-03,  2.61659008e-02],\n",
      "         [ 2.77881883e-03,  2.19068993e-02, -2.07614750e-02, ...,\n",
      "          -1.68828126e-02, -1.72100551e-02,  1.75190326e-02]],\n",
      "\n",
      "        [[ 2.70200726e-02,  1.83045436e-02, -2.22152602e-02, ...,\n",
      "          -2.24734657e-02, -2.43242942e-02, -1.21340081e-02],\n",
      "         [-4.89782915e-03, -1.80962905e-02,  2.64851358e-02, ...,\n",
      "          -1.29772183e-02, -2.22508609e-03, -5.02177514e-03],\n",
      "         [ 1.17883477e-02, -9.70135443e-03, -5.55986539e-03, ...,\n",
      "          -7.28825852e-03, -2.06803698e-02, -9.47527960e-03],\n",
      "         ...,\n",
      "         [ 2.34984960e-02,  2.60666739e-02, -2.09272243e-02, ...,\n",
      "           1.97696406e-02, -2.87854485e-03,  2.38353144e-02],\n",
      "         [-3.67192551e-03,  9.03979130e-03, -2.70915236e-02, ...,\n",
      "           5.42353280e-03,  2.38234159e-02, -2.28828583e-02],\n",
      "         [-1.39287049e-02,  2.38023642e-02, -1.23091843e-02, ...,\n",
      "          -1.06170159e-02,  2.85340566e-02,  6.79365732e-03]]],\n",
      "\n",
      "\n",
      "       [[[-2.64825784e-02,  2.38488149e-02, -1.58706196e-02, ...,\n",
      "          -7.43045472e-03,  2.55113337e-02,  2.59308126e-02],\n",
      "         [ 9.75210778e-03, -1.61352195e-03,  2.39128154e-02, ...,\n",
      "           1.63088087e-02, -2.68624201e-02,  9.91164707e-03],\n",
      "         [-2.64619477e-02,  1.77971516e-02,  2.29884367e-02, ...,\n",
      "           2.83151437e-02, -2.56376471e-02, -2.29805205e-02],\n",
      "         ...,\n",
      "         [ 1.92406587e-03, -1.42914699e-02, -6.70125149e-03, ...,\n",
      "          -9.33569483e-03, -7.18779862e-04,  1.69396754e-02],\n",
      "         [ 2.06002127e-02,  1.29804146e-02,  1.94945764e-02, ...,\n",
      "          -7.54647143e-03,  1.96412671e-02, -1.59885120e-02],\n",
      "         [-6.20969944e-03, -1.14617720e-02,  2.35160533e-02, ...,\n",
      "          -2.00563651e-02, -1.56454928e-02,  1.46893505e-02]],\n",
      "\n",
      "        [[-2.28591226e-02,  1.20680686e-02,  2.90240217e-02, ...,\n",
      "          -1.35334730e-02, -9.89447907e-03, -2.23022923e-02],\n",
      "         [ 8.96943919e-03,  4.07236256e-03, -2.84291059e-03, ...,\n",
      "           5.94177283e-03, -6.80048577e-03, -1.21258311e-02],\n",
      "         [ 1.20734628e-02,  8.80025327e-04,  2.44767610e-02, ...,\n",
      "          -2.20576655e-02, -2.90080048e-02, -2.48756390e-02],\n",
      "         ...,\n",
      "         [-2.42651142e-02, -1.44591294e-02,  2.48873793e-03, ...,\n",
      "          -2.94538401e-02, -2.13538706e-02,  2.15653609e-02],\n",
      "         [ 1.31360274e-02,  1.53100323e-02,  2.22786833e-02, ...,\n",
      "          -1.79712065e-02, -2.68801637e-02,  2.09977664e-03],\n",
      "         [-2.43175440e-02, -4.12113965e-03,  2.38879267e-02, ...,\n",
      "          -2.46970989e-02, -3.86818126e-03,  2.02345680e-02]],\n",
      "\n",
      "        [[ 9.29578952e-03,  1.65589340e-03, -9.60456394e-03, ...,\n",
      "          -1.94862522e-02, -1.56810991e-02, -2.78124735e-02],\n",
      "         [ 3.54273058e-03, -2.51248404e-02, -1.29513126e-02, ...,\n",
      "          -5.05524687e-03,  1.77892726e-02,  2.61448268e-02],\n",
      "         [-2.40073092e-02, -2.52284668e-03, -2.83466224e-02, ...,\n",
      "          -1.37889758e-03, -1.83698442e-02, -1.43544162e-02],\n",
      "         ...,\n",
      "         [-2.78068706e-03,  8.82982276e-03,  5.30526973e-03, ...,\n",
      "          -2.11085379e-03,  7.12310709e-03,  7.97490589e-03],\n",
      "         [-6.22469559e-03, -5.63053414e-04, -2.61051618e-02, ...,\n",
      "           5.76383434e-03, -2.83511039e-02,  7.52301700e-03],\n",
      "         [-2.07265560e-02, -7.78008997e-03,  1.81694645e-02, ...,\n",
      "           1.18428227e-02,  1.51786115e-02, -2.14625150e-04]]]],\n",
      "      dtype=float32)>, <tf.Variable 'basic_block_6/conv2d_15/bias:0' shape=(512,) dtype=float32, numpy=\n",
      "array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0.], dtype=float32)>, <tf.Variable 'basic_block_6/batch_normalization_15/gamma:0' shape=(512,) dtype=float32, numpy=\n",
      "array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1.], dtype=float32)>, <tf.Variable 'basic_block_6/batch_normalization_15/beta:0' shape=(512,) dtype=float32, numpy=\n",
      "array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0.], dtype=float32)>, <tf.Variable 'basic_block_6/conv2d_16/kernel:0' shape=(3, 3, 512, 512) dtype=float32, numpy=\n",
      "array([[[[-2.50395015e-02, -6.13550283e-03, -1.04470449e-02, ...,\n",
      "          -2.47721970e-02,  1.59331337e-02,  2.43235901e-02],\n",
      "         [ 2.04198658e-02, -1.20446458e-03, -1.07231634e-02, ...,\n",
      "           5.52762672e-03, -1.13687916e-02,  7.33429193e-03],\n",
      "         [ 1.49606206e-02,  1.68423131e-02,  2.37220414e-02, ...,\n",
      "           2.06324570e-02, -8.34636390e-03, -1.67448521e-02],\n",
      "         ...,\n",
      "         [-5.50674275e-03,  4.71401773e-03, -1.96247399e-02, ...,\n",
      "          -2.47678608e-02,  1.80864371e-02, -1.56009281e-02],\n",
      "         [ 8.37827101e-03, -8.56469013e-03,  8.85149091e-03, ...,\n",
      "          -1.61530413e-02,  2.08369605e-02, -7.56308064e-03],\n",
      "         [-8.36401805e-03,  2.43005492e-02, -1.26668438e-02, ...,\n",
      "           1.28225237e-02, -8.42742622e-03, -1.35310655e-02]],\n",
      "\n",
      "        [[ 1.10382326e-02, -1.65414549e-02, -1.19400769e-03, ...,\n",
      "           2.25305595e-02, -8.29972327e-04,  2.34782137e-02],\n",
      "         [ 2.12737396e-02, -1.92266423e-02, -1.80212837e-02, ...,\n",
      "          -2.69357860e-03, -2.51253005e-02,  2.52503008e-02],\n",
      "         [-5.56298904e-03,  2.09522359e-02, -9.69977491e-03, ...,\n",
      "           1.23856328e-02,  6.94558769e-03,  5.12211584e-03],\n",
      "         ...,\n",
      "         [-2.19074935e-02,  1.71011910e-02, -2.29816884e-04, ...,\n",
      "           1.11336038e-02,  2.45318078e-02, -1.99231654e-02],\n",
      "         [ 9.32798907e-03, -9.66083631e-03, -5.01164235e-03, ...,\n",
      "           1.65357068e-03, -3.16645764e-03, -2.93064117e-03],\n",
      "         [ 2.04231218e-02, -1.85563397e-02, -3.72304395e-03, ...,\n",
      "          -7.46270642e-03,  1.90900788e-02, -1.83438547e-02]],\n",
      "\n",
      "        [[ 2.14550979e-02, -1.59433074e-02,  3.27110291e-03, ...,\n",
      "          -8.43307003e-04,  5.16587310e-03,  7.08427280e-03],\n",
      "         [-1.14963967e-02,  1.42832138e-02, -2.14842930e-02, ...,\n",
      "           2.50385627e-02, -1.85233504e-02,  1.25092342e-02],\n",
      "         [ 1.82319582e-02,  1.05840303e-02,  1.71904266e-02, ...,\n",
      "          -7.87141733e-03, -9.17889923e-03,  1.44311264e-02],\n",
      "         ...,\n",
      "         [ 1.49449930e-02,  2.11530402e-02,  1.78007782e-02, ...,\n",
      "          -1.37995798e-02,  1.82366520e-02, -1.25122955e-02],\n",
      "         [-1.55385854e-02,  2.02265494e-02,  7.84715638e-03, ...,\n",
      "           1.96718611e-02, -1.50477514e-04,  1.80117153e-02],\n",
      "         [ 1.75531730e-02, -8.43175128e-03, -8.38360749e-03, ...,\n",
      "           1.48044452e-02, -2.13447940e-02,  1.87835135e-02]]],\n",
      "\n",
      "\n",
      "       [[[ 2.28197947e-02, -1.77483633e-03, -4.51652706e-03, ...,\n",
      "           1.71947107e-02,  2.39170939e-02,  2.38786153e-02],\n",
      "         [ 6.25077635e-03, -2.45173536e-02, -1.49290012e-02, ...,\n",
      "           1.91021897e-02, -1.47529598e-02,  1.18746832e-02],\n",
      "         [-1.59201175e-02,  1.15976669e-02, -3.22829373e-03, ...,\n",
      "           1.52843483e-02,  3.00208107e-04,  1.39492974e-02],\n",
      "         ...,\n",
      "         [-7.70875439e-03,  1.51213072e-02,  1.70846879e-02, ...,\n",
      "           2.41582952e-02, -1.63505208e-02, -7.70017691e-03],\n",
      "         [ 9.80712846e-03, -7.69594312e-03, -1.26917362e-02, ...,\n",
      "          -1.71674024e-02,  2.05695815e-03, -2.97424570e-03],\n",
      "         [ 3.85822728e-03,  1.05222426e-02, -1.91587284e-02, ...,\n",
      "           4.84664179e-03, -2.06287205e-02, -1.76523812e-02]],\n",
      "\n",
      "        [[ 1.98188424e-03, -1.28025450e-02, -2.20687706e-02, ...,\n",
      "          -2.53813509e-02, -1.79488733e-02, -2.37621684e-02],\n",
      "         [-8.69162567e-03,  5.43977134e-03,  1.86862759e-02, ...,\n",
      "           1.09079331e-02,  2.27746852e-02, -1.67653523e-03],\n",
      "         [ 5.29586896e-03,  3.87020595e-03, -1.37152281e-02, ...,\n",
      "          -9.17671248e-04, -6.38143532e-03, -1.18638873e-02],\n",
      "         ...,\n",
      "         [-1.98541209e-03, -1.98200271e-02,  9.98385251e-04, ...,\n",
      "           2.49162875e-02, -2.25123521e-02, -1.44120604e-02],\n",
      "         [ 7.88336992e-03, -1.32319527e-02,  3.29115428e-03, ...,\n",
      "          -2.13611163e-02,  3.00333090e-03, -9.60566476e-03],\n",
      "         [-9.51467082e-03, -1.20896474e-02, -1.43441092e-02, ...,\n",
      "           4.26858850e-03, -9.27466899e-05, -1.54599939e-02]],\n",
      "\n",
      "        [[-1.53713347e-02,  7.60804862e-04,  1.67960748e-02, ...,\n",
      "           4.36154194e-03,  2.06653960e-02,  2.09995098e-02],\n",
      "         [ 9.74938646e-03, -4.36010025e-03, -5.15360944e-03, ...,\n",
      "          -1.57297123e-02,  2.77994946e-03,  8.90876725e-03],\n",
      "         [-2.32087038e-02,  2.25116946e-02,  1.10551007e-02, ...,\n",
      "           1.16986819e-02,  2.53540128e-02,  2.44967416e-02],\n",
      "         ...,\n",
      "         [ 1.82618015e-03, -2.21144073e-02,  1.41698681e-02, ...,\n",
      "          -1.43787721e-02,  2.48635933e-03,  2.04399116e-02],\n",
      "         [ 1.54103227e-02, -1.97922252e-02,  8.75197351e-04, ...,\n",
      "           2.96462327e-03, -1.75827872e-02, -9.87324305e-03],\n",
      "         [-2.63269618e-03,  6.13352656e-03,  2.19438560e-02, ...,\n",
      "           2.74633989e-03, -1.51383476e-02, -1.04732523e-02]]],\n",
      "\n",
      "\n",
      "       [[[-2.17873473e-02, -2.24602297e-02, -3.65020707e-04, ...,\n",
      "          -2.20095739e-02, -1.55154262e-02,  2.15777345e-02],\n",
      "         [-8.05740431e-03, -3.26963142e-04, -2.05071084e-03, ...,\n",
      "           2.37896778e-02, -9.02547501e-03, -2.23616734e-02],\n",
      "         [ 8.52560997e-03,  2.43150033e-02,  6.14313781e-03, ...,\n",
      "          -1.33300405e-02, -2.28619203e-04, -9.07770731e-03],\n",
      "         ...,\n",
      "         [-2.07453333e-02, -8.69792327e-03, -5.27657196e-03, ...,\n",
      "          -9.56303254e-03, -2.35236157e-02,  1.69438981e-02],\n",
      "         [ 1.00741349e-02,  1.14068054e-02,  7.62344524e-03, ...,\n",
      "           2.17921250e-02,  4.98199649e-03,  1.14059076e-03],\n",
      "         [-2.50972379e-02, -2.37432979e-02,  1.26636848e-02, ...,\n",
      "           9.09305736e-03, -6.64324500e-03,  1.71955004e-02]],\n",
      "\n",
      "        [[ 3.08994018e-03,  5.73506951e-03,  1.66730508e-02, ...,\n",
      "          -8.47944990e-03, -1.93533469e-02, -1.53750097e-02],\n",
      "         [-1.18628042e-02, -5.97340986e-03,  2.51438729e-02, ...,\n",
      "           1.97120160e-02,  6.54825941e-03,  1.39411576e-02],\n",
      "         [-2.66239420e-03,  2.14539245e-02,  2.60578841e-03, ...,\n",
      "          -1.05991596e-02,  1.69066861e-02,  7.77192414e-03],\n",
      "         ...,\n",
      "         [-2.13718526e-02,  1.40810832e-02,  1.83044598e-02, ...,\n",
      "           2.91054696e-03, -1.25047155e-02, -1.45437289e-02],\n",
      "         [ 1.84959807e-02, -2.27574389e-02,  2.13545337e-02, ...,\n",
      "          -8.70204717e-03, -9.57080163e-03,  9.91217047e-03],\n",
      "         [ 8.11363757e-03,  2.14595348e-02, -3.98628227e-03, ...,\n",
      "          -8.52928497e-03,  6.70431182e-04,  1.27907060e-02]],\n",
      "\n",
      "        [[ 2.47686319e-02, -2.49490235e-02,  1.07684359e-02, ...,\n",
      "           1.95928551e-02, -1.83540005e-02, -5.52702509e-03],\n",
      "         [ 8.86902213e-03,  1.92444175e-02,  2.34929994e-02, ...,\n",
      "           9.90610570e-04, -3.39916348e-03, -2.27224901e-02],\n",
      "         [-1.89308394e-02, -1.31534161e-02, -2.08005887e-02, ...,\n",
      "          -2.28242893e-02, -2.18699295e-02,  2.47540437e-02],\n",
      "         ...,\n",
      "         [-1.86132938e-02, -2.43402664e-02, -9.29259136e-03, ...,\n",
      "           1.09322108e-02, -1.27836261e-02,  3.40814330e-03],\n",
      "         [-2.42260937e-02,  1.13567822e-02,  4.17441130e-04, ...,\n",
      "           1.86128728e-03,  1.16343200e-02, -1.88789479e-02],\n",
      "         [-1.77614316e-02,  2.48717889e-02,  3.50813568e-03, ...,\n",
      "          -4.12192941e-03,  1.03701465e-03, -2.34612972e-02]]]],\n",
      "      dtype=float32)>, <tf.Variable 'basic_block_6/conv2d_16/bias:0' shape=(512,) dtype=float32, numpy=\n",
      "array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0.], dtype=float32)>, <tf.Variable 'basic_block_6/batch_normalization_16/gamma:0' shape=(512,) dtype=float32, numpy=\n",
      "array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1.], dtype=float32)>, <tf.Variable 'basic_block_6/batch_normalization_16/beta:0' shape=(512,) dtype=float32, numpy=\n",
      "array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0.], dtype=float32)>, <tf.Variable 'conv2d_17/kernel:0' shape=(1, 1, 256, 512) dtype=float32, numpy=\n",
      "array([[[[-0.00430338, -0.02500577,  0.07403655, ...,  0.07363728,\n",
      "          -0.02657369, -0.02497852],\n",
      "         [-0.03935375,  0.01940464, -0.07743368, ...,  0.01836655,\n",
      "          -0.0252796 ,  0.02549431],\n",
      "         [ 0.05174173, -0.06108876, -0.05749473, ..., -0.07500301,\n",
      "           0.04186562, -0.06645268],\n",
      "         ...,\n",
      "         [ 0.08265621,  0.00628158, -0.06748503, ..., -0.04975614,\n",
      "           0.08491621, -0.07592881],\n",
      "         [-0.04619113, -0.02470808, -0.01700809, ...,  0.06014884,\n",
      "           0.03235105, -0.04422652],\n",
      "         [ 0.08492484, -0.00230383, -0.08511923, ..., -0.02463376,\n",
      "          -0.0025891 , -0.02521353]]]], dtype=float32)>, <tf.Variable 'conv2d_17/bias:0' shape=(512,) dtype=float32, numpy=\n",
      "array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0.], dtype=float32)>, <tf.Variable 'batch_normalization_17/gamma:0' shape=(512,) dtype=float32, numpy=\n",
      "array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1.], dtype=float32)>, <tf.Variable 'batch_normalization_17/beta:0' shape=(512,) dtype=float32, numpy=\n",
      "array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0.], dtype=float32)>, <tf.Variable 'basic_block_6/batch_normalization_15/moving_mean:0' shape=(512,) dtype=float32, numpy=\n",
      "array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0.], dtype=float32)>, <tf.Variable 'basic_block_6/batch_normalization_15/moving_variance:0' shape=(512,) dtype=float32, numpy=\n",
      "array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1.], dtype=float32)>, <tf.Variable 'basic_block_6/batch_normalization_16/moving_mean:0' shape=(512,) dtype=float32, numpy=\n",
      "array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0.], dtype=float32)>, <tf.Variable 'basic_block_6/batch_normalization_16/moving_variance:0' shape=(512,) dtype=float32, numpy=\n",
      "array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1.], dtype=float32)>, <tf.Variable 'batch_normalization_17/moving_mean:0' shape=(512,) dtype=float32, numpy=\n",
      "array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0.], dtype=float32)>, <tf.Variable 'batch_normalization_17/moving_variance:0' shape=(512,) dtype=float32, numpy=\n",
      "array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1.], dtype=float32)>, <tf.Variable 'basic_block_7/conv2d_18/kernel:0' shape=(3, 3, 512, 512) dtype=float32, numpy=\n",
      "array([[[[ 0.00910364, -0.00399083,  0.01305848, ..., -0.00063813,\n",
      "           0.02498429, -0.00927314],\n",
      "         [-0.01236252, -0.00506943, -0.00515654, ..., -0.02329216,\n",
      "           0.00943933, -0.00433911],\n",
      "         [-0.0113809 ,  0.01037698, -0.02390417, ..., -0.00220314,\n",
      "          -0.00885254,  0.01618823],\n",
      "         ...,\n",
      "         [ 0.02396721,  0.00918762, -0.02214568, ...,  0.00527293,\n",
      "           0.01894993, -0.02390684],\n",
      "         [ 0.01714721,  0.01688545, -0.00298726, ..., -0.02249965,\n",
      "           0.0028317 , -0.02531957],\n",
      "         [-0.00860142,  0.01804562, -0.00020753, ..., -0.0056582 ,\n",
      "          -0.01278169, -0.00834119]],\n",
      "\n",
      "        [[-0.00894921, -0.00578987, -0.02223393, ...,  0.00753424,\n",
      "          -0.00601593, -0.01199308],\n",
      "         [ 0.02069487,  0.00599554,  0.02017609, ...,  0.01683421,\n",
      "          -0.00825433,  0.02076596],\n",
      "         [ 0.02172064,  0.02096746, -0.00448141, ..., -0.01267957,\n",
      "          -0.00123955, -0.00068265],\n",
      "         ...,\n",
      "         [-0.01105127, -0.00672392, -0.00377219, ..., -0.00898262,\n",
      "          -0.0035182 ,  0.01934357],\n",
      "         [-0.01524745, -0.00594229, -0.01134853, ..., -0.0118258 ,\n",
      "           0.00287846,  0.00796325],\n",
      "         [-0.02340335,  0.00121545,  0.01986591, ...,  0.02135978,\n",
      "          -0.02278345,  0.00969301]],\n",
      "\n",
      "        [[-0.01563552, -0.01735982, -0.00314855, ...,  0.01399517,\n",
      "          -0.00834472, -0.01417638],\n",
      "         [-0.01008117,  0.01925086,  0.02014972, ..., -0.00644333,\n",
      "          -0.0138404 ,  0.01699136],\n",
      "         [-0.00378897, -0.00498531,  0.00796376, ...,  0.01200006,\n",
      "          -0.00894432, -0.01898948],\n",
      "         ...,\n",
      "         [ 0.00113071, -0.00068169,  0.00390408, ...,  0.01001642,\n",
      "          -0.00042016,  0.00821752],\n",
      "         [-0.01863366, -0.01178566, -0.01414834, ...,  0.00776159,\n",
      "           0.01897928, -0.02231218],\n",
      "         [-0.02480265,  0.00747866, -0.00957142, ..., -0.01809671,\n",
      "           0.01392575,  0.02005906]]],\n",
      "\n",
      "\n",
      "       [[[ 0.00625677,  0.0236766 , -0.02160827, ...,  0.00253548,\n",
      "          -0.00290793, -0.01177343],\n",
      "         [ 0.00421171,  0.01671779,  0.02269836, ...,  0.00593041,\n",
      "           0.01822029,  0.02046461],\n",
      "         [-0.00133085,  0.01574203,  0.02478863, ..., -0.02195841,\n",
      "           0.0231018 , -0.02429279],\n",
      "         ...,\n",
      "         [-0.0200268 , -0.0175823 , -0.01675225, ...,  0.01784746,\n",
      "          -0.0191936 ,  0.01364835],\n",
      "         [ 0.02551171,  0.00250536, -0.00672306, ...,  0.01478767,\n",
      "          -0.00870284,  0.00891417],\n",
      "         [ 0.02492907,  0.01743124, -0.01866497, ..., -0.00408831,\n",
      "          -0.02529502,  0.02550498]],\n",
      "\n",
      "        [[-0.01140634, -0.02135399,  0.01607619, ..., -0.01363261,\n",
      "          -0.01638008,  0.01197659],\n",
      "         [-0.02083506, -0.00758009, -0.01862603, ..., -0.02159104,\n",
      "          -0.00028013, -0.00836314],\n",
      "         [-0.01851581,  0.0183841 , -0.02445154, ...,  0.01942272,\n",
      "          -0.00078512, -0.01684993],\n",
      "         ...,\n",
      "         [ 0.02048771,  0.00158036, -0.01617016, ...,  0.00569545,\n",
      "          -0.01017582,  0.00092719],\n",
      "         [-0.01189413,  0.0139594 ,  0.01385782, ...,  0.02327151,\n",
      "          -0.00576748, -0.01646735],\n",
      "         [-0.01056281, -0.00982358, -0.00563475, ...,  0.0196436 ,\n",
      "          -0.01296823, -0.01935102]],\n",
      "\n",
      "        [[-0.01140627,  0.0153719 , -0.00218368, ...,  0.02238752,\n",
      "          -0.02101784, -0.01294724],\n",
      "         [ 0.01181098, -0.02199632,  0.0105263 , ...,  0.02089043,\n",
      "           0.01132652,  0.00723768],\n",
      "         [-0.01638959, -0.02215183, -0.01178333, ..., -0.02134576,\n",
      "           0.02416455,  0.01185023],\n",
      "         ...,\n",
      "         [ 0.01617652, -0.00680501,  0.01194283, ..., -0.01505833,\n",
      "          -0.01980585,  0.01897251],\n",
      "         [-0.00096078, -0.02328194, -0.0189997 , ...,  0.00856031,\n",
      "           0.01971737,  0.01401495],\n",
      "         [ 0.01545589, -0.01191438,  0.00712458, ..., -0.02227488,\n",
      "          -0.00677966,  0.00066275]]],\n",
      "\n",
      "\n",
      "       [[[ 0.02201976, -0.00912206, -0.01861705, ...,  0.02120927,\n",
      "          -0.01188539,  0.00824765],\n",
      "         [-0.00451425, -0.01153776,  0.00814166, ...,  0.00362222,\n",
      "          -0.02076221,  0.0001332 ],\n",
      "         [-0.00548975,  0.01037793, -0.00811809, ...,  0.01086509,\n",
      "          -0.01393037,  0.02425913],\n",
      "         ...,\n",
      "         [-0.02051759,  0.0026137 ,  0.02113593, ...,  0.0203175 ,\n",
      "          -0.00659235, -0.00694081],\n",
      "         [-0.01833211,  0.01876284, -0.02098586, ..., -0.00229581,\n",
      "          -0.01712411, -0.00043572],\n",
      "         [ 0.01380428,  0.01548797,  0.02215081, ...,  0.01449923,\n",
      "          -0.00977529, -0.02158389]],\n",
      "\n",
      "        [[-0.00234421,  0.00248541,  0.00972237, ...,  0.01793939,\n",
      "           0.01351983, -0.00180104],\n",
      "         [ 0.01406331, -0.00956028, -0.01261992, ..., -0.022769  ,\n",
      "           0.0220429 ,  0.01808808],\n",
      "         [ 0.02166237,  0.02474045,  0.02148754, ...,  0.00289173,\n",
      "          -0.02333235,  0.00645208],\n",
      "         ...,\n",
      "         [ 0.02272578, -0.01862163, -0.01333977, ..., -0.01600613,\n",
      "          -0.01367434,  0.01362597],\n",
      "         [-0.00598296,  0.01956005,  0.0078635 , ...,  0.01804968,\n",
      "          -0.0145156 , -0.00846869],\n",
      "         [-0.02195473, -0.01758678,  0.01428682, ...,  0.00593059,\n",
      "           0.01230108,  0.00310731]],\n",
      "\n",
      "        [[ 0.01433357,  0.02269128, -0.02008287, ..., -0.02429619,\n",
      "           0.01551065,  0.01785793],\n",
      "         [ 0.01036936, -0.00568576, -0.02344611, ...,  0.00446143,\n",
      "           0.00116828, -0.00438493],\n",
      "         [ 0.00158371,  0.00159716,  0.01448021, ..., -0.01889275,\n",
      "          -0.01545514,  0.00034658],\n",
      "         ...,\n",
      "         [-0.00555911, -0.00734504,  0.0181272 , ...,  0.00877302,\n",
      "          -0.0015499 , -0.00775313],\n",
      "         [-0.02308581,  0.00377971, -0.01116396, ...,  0.01163127,\n",
      "          -0.01352205,  0.00052711],\n",
      "         [ 0.02266516,  0.0102358 ,  0.00492154, ...,  0.00023523,\n",
      "           0.00249691, -0.00525187]]]], dtype=float32)>, <tf.Variable 'basic_block_7/conv2d_18/bias:0' shape=(512,) dtype=float32, numpy=\n",
      "array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0.], dtype=float32)>, <tf.Variable 'basic_block_7/batch_normalization_18/gamma:0' shape=(512,) dtype=float32, numpy=\n",
      "array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1.], dtype=float32)>, <tf.Variable 'basic_block_7/batch_normalization_18/beta:0' shape=(512,) dtype=float32, numpy=\n",
      "array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0.], dtype=float32)>, <tf.Variable 'basic_block_7/conv2d_19/kernel:0' shape=(3, 3, 512, 512) dtype=float32, numpy=\n",
      "array([[[[-8.70551541e-03, -2.32236441e-02, -1.57222338e-03, ...,\n",
      "           2.34978274e-02, -2.25312896e-02,  2.18972787e-02],\n",
      "         [-2.68902630e-04,  7.26608932e-03,  1.48078948e-02, ...,\n",
      "           1.70484558e-02, -8.99843499e-03,  1.50752030e-02],\n",
      "         [ 1.47081502e-02, -1.14612468e-02, -1.42895952e-02, ...,\n",
      "          -6.59751706e-03, -9.51168314e-03,  9.26075131e-03],\n",
      "         ...,\n",
      "         [ 1.37386471e-02,  9.39918682e-04, -4.10540216e-03, ...,\n",
      "          -7.38007016e-03,  2.39514336e-02,  3.66736203e-04],\n",
      "         [ 1.79845169e-02, -7.99108855e-03,  7.13666156e-03, ...,\n",
      "          -2.13415213e-02, -6.80511817e-03, -1.56147555e-02],\n",
      "         [-1.49518317e-02,  5.27688861e-03,  1.76873654e-02, ...,\n",
      "           8.61363858e-03,  1.75403245e-02,  7.32210651e-03]],\n",
      "\n",
      "        [[ 1.72096938e-02,  2.08699070e-02, -1.31416135e-03, ...,\n",
      "          -2.44931653e-02,  4.86127287e-03,  1.26541518e-02],\n",
      "         [-2.51077451e-02,  2.51768045e-02,  6.89655542e-03, ...,\n",
      "           6.97169080e-03, -2.25853343e-02,  1.00685433e-02],\n",
      "         [ 1.24358013e-02,  1.35165751e-02, -1.29040703e-02, ...,\n",
      "          -5.70363738e-03, -2.00783145e-02, -1.74477547e-02],\n",
      "         ...,\n",
      "         [-1.94081515e-02, -1.76528804e-02,  1.47971511e-02, ...,\n",
      "          -1.82963070e-02,  8.75393674e-03, -1.28336614e-02],\n",
      "         [ 2.25957111e-03,  2.92204507e-03, -1.19826281e-02, ...,\n",
      "           4.87142615e-03, -1.30410017e-02, -2.37392262e-04],\n",
      "         [ 1.19068734e-02, -2.34946217e-02,  1.11036748e-03, ...,\n",
      "           6.19506463e-03, -1.50427055e-02, -1.65863298e-02]],\n",
      "\n",
      "        [[ 4.45249490e-03,  5.34984656e-03, -2.31615398e-02, ...,\n",
      "           1.07818656e-03, -1.60233341e-02,  6.66059554e-03],\n",
      "         [ 2.06150636e-02, -1.23341009e-02,  1.67786144e-02, ...,\n",
      "           6.56906515e-03,  2.98941322e-03,  3.97838652e-03],\n",
      "         [ 2.48435140e-02,  1.53689273e-02,  1.46299005e-02, ...,\n",
      "          -1.40835578e-02, -1.30741373e-02,  6.01388514e-03],\n",
      "         ...,\n",
      "         [ 3.72968055e-03,  1.14090592e-02,  1.27575174e-02, ...,\n",
      "           1.03874169e-02,  1.44847743e-02, -1.94190051e-02],\n",
      "         [-1.68415401e-02, -1.87815707e-02, -6.90067187e-04, ...,\n",
      "          -2.34309658e-02, -2.15422120e-02,  1.37319267e-02],\n",
      "         [ 1.61461458e-02,  2.07385272e-02,  2.42170505e-03, ...,\n",
      "           2.24138759e-02, -1.49348769e-02, -6.35669939e-03]]],\n",
      "\n",
      "\n",
      "       [[[ 1.61244571e-02, -5.78442402e-03,  8.61898065e-04, ...,\n",
      "           2.22395547e-02,  2.17755996e-02, -1.18499072e-02],\n",
      "         [ 4.30143252e-03,  5.51162101e-03, -3.24656814e-03, ...,\n",
      "           2.20038928e-02,  1.20497905e-02, -2.22829785e-02],\n",
      "         [-1.35934511e-02,  2.34642401e-02, -5.27620129e-03, ...,\n",
      "          -6.41854294e-03,  2.17181668e-02, -1.38211455e-02],\n",
      "         ...,\n",
      "         [ 2.13603936e-02,  6.61993399e-03,  1.87844224e-03, ...,\n",
      "          -8.35934095e-03,  1.07757114e-02, -2.00341269e-03],\n",
      "         [-2.19740774e-02, -2.14601234e-02,  1.86218210e-02, ...,\n",
      "           1.55292414e-02,  1.08066089e-02,  1.52014494e-02],\n",
      "         [ 2.48031430e-02, -2.44462993e-02,  7.23740086e-03, ...,\n",
      "           1.48228109e-02, -4.36051935e-03,  5.27535006e-03]],\n",
      "\n",
      "        [[-2.40641534e-02, -9.52951983e-03, -1.90446340e-02, ...,\n",
      "           3.29713337e-03, -1.09325768e-02, -2.20298432e-02],\n",
      "         [-1.27204377e-02, -9.03232582e-03,  7.93485343e-03, ...,\n",
      "           1.90734938e-02,  1.05721802e-02, -9.36947204e-03],\n",
      "         [-4.14744392e-03,  1.38113946e-02,  1.96590312e-02, ...,\n",
      "           4.83982265e-03,  1.89566612e-02,  5.29256649e-03],\n",
      "         ...,\n",
      "         [ 9.89545137e-04,  8.50059465e-03, -1.79103035e-02, ...,\n",
      "           2.00268328e-02,  2.70387158e-04,  2.75347568e-03],\n",
      "         [-2.36880407e-03, -1.18808597e-02,  1.16433091e-02, ...,\n",
      "           1.63590498e-02, -2.03159265e-02,  1.85929239e-03],\n",
      "         [-2.26740725e-03,  2.16335729e-02, -4.25979123e-03, ...,\n",
      "          -9.30456258e-03, -2.43683830e-02,  1.42646544e-02]],\n",
      "\n",
      "        [[ 2.61105597e-05, -2.44630277e-02, -9.47728753e-03, ...,\n",
      "           1.71309561e-02,  9.22537595e-03,  1.77127644e-02],\n",
      "         [-1.81437600e-02, -1.99401975e-02, -5.13941050e-04, ...,\n",
      "          -1.12021500e-02, -1.87161192e-02, -9.49916989e-03],\n",
      "         [-1.05610536e-02, -5.02021238e-03, -1.71086192e-02, ...,\n",
      "          -1.24974335e-02, -1.42145939e-02, -1.47196231e-02],\n",
      "         ...,\n",
      "         [ 2.04884335e-02,  1.87097117e-03, -7.21755810e-03, ...,\n",
      "          -2.03057416e-02, -9.05016810e-03, -9.59895551e-05],\n",
      "         [-5.49571961e-03, -1.91084426e-02, -1.00974925e-03, ...,\n",
      "          -1.92268752e-03, -1.76487975e-02,  1.66051649e-02],\n",
      "         [ 7.55542889e-03,  5.85282221e-04,  1.67297274e-02, ...,\n",
      "           4.47694398e-03,  2.13387795e-03, -1.20531591e-02]]],\n",
      "\n",
      "\n",
      "       [[[ 1.18873939e-02, -6.73140585e-03, -1.63811520e-02, ...,\n",
      "          -3.42295691e-03,  1.10815950e-02, -6.76470622e-03],\n",
      "         [ 2.26725638e-02,  1.69424526e-02,  2.01247148e-02, ...,\n",
      "           2.04665028e-02,  6.91371784e-03, -7.92527385e-03],\n",
      "         [-2.41863262e-02,  1.50683410e-02, -1.96008123e-02, ...,\n",
      "          -4.79389913e-03,  4.89922613e-03, -1.16325486e-02],\n",
      "         ...,\n",
      "         [ 1.36500746e-02,  9.25286487e-03,  7.88930058e-03, ...,\n",
      "           2.55018100e-03,  1.35747865e-02,  2.09707022e-02],\n",
      "         [ 9.14145634e-03, -2.22574770e-02,  1.04758665e-02, ...,\n",
      "          -6.20438345e-03,  1.35694146e-02,  6.54535368e-04],\n",
      "         [ 2.95311958e-03,  6.96837157e-03, -5.48246503e-03, ...,\n",
      "           1.93849802e-02, -2.12630220e-02,  5.94413280e-03]],\n",
      "\n",
      "        [[ 1.09291747e-02,  1.93677172e-02, -5.42829745e-03, ...,\n",
      "           2.07140930e-02, -1.69582255e-02,  8.81584734e-03],\n",
      "         [-6.10937364e-03,  2.45537125e-02, -2.12194659e-02, ...,\n",
      "          -1.55132059e-02, -1.17210010e-02, -5.36283478e-03],\n",
      "         [-2.31475420e-02,  1.70571432e-02,  6.96134940e-03, ...,\n",
      "           4.28757444e-03, -2.27330029e-02,  1.48664229e-02],\n",
      "         ...,\n",
      "         [ 1.60558149e-04, -6.55679032e-04, -1.44680878e-02, ...,\n",
      "          -1.75092947e-02,  7.19251111e-03,  1.26615129e-02],\n",
      "         [-4.31123190e-03,  4.70214896e-03, -1.65633969e-02, ...,\n",
      "           1.13736652e-02,  1.01741031e-02,  1.04718581e-02],\n",
      "         [-1.83397960e-02, -7.96592794e-03,  1.26682036e-03, ...,\n",
      "           1.01538189e-03,  2.29450017e-02,  1.51290298e-02]],\n",
      "\n",
      "        [[ 1.40297674e-02,  2.27225572e-02,  1.79676414e-02, ...,\n",
      "           9.28957388e-03, -1.88274402e-02, -8.83196294e-03],\n",
      "         [ 1.82508752e-02, -8.52777623e-03, -3.61109711e-03, ...,\n",
      "           1.10014118e-02,  2.54746154e-03,  8.15204903e-03],\n",
      "         [ 6.00687042e-03,  2.03687549e-02, -4.96049225e-03, ...,\n",
      "          -3.39629874e-03,  1.51459351e-02,  1.38828158e-03],\n",
      "         ...,\n",
      "         [ 1.23423934e-02,  1.58213638e-02,  4.23237309e-03, ...,\n",
      "          -2.26044357e-02,  2.04606913e-02, -1.49499765e-02],\n",
      "         [ 1.62967257e-02, -4.28882800e-03, -2.31432095e-02, ...,\n",
      "           1.01414770e-02,  6.79144263e-03, -1.61651783e-02],\n",
      "         [ 9.25164297e-03, -1.87777933e-02, -2.24188697e-02, ...,\n",
      "           1.11774169e-03,  1.56160444e-04, -1.77467577e-02]]]],\n",
      "      dtype=float32)>, <tf.Variable 'basic_block_7/conv2d_19/bias:0' shape=(512,) dtype=float32, numpy=\n",
      "array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0.], dtype=float32)>, <tf.Variable 'basic_block_7/batch_normalization_19/gamma:0' shape=(512,) dtype=float32, numpy=\n",
      "array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1.], dtype=float32)>, <tf.Variable 'basic_block_7/batch_normalization_19/beta:0' shape=(512,) dtype=float32, numpy=\n",
      "array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0.], dtype=float32)>, <tf.Variable 'basic_block_7/batch_normalization_18/moving_mean:0' shape=(512,) dtype=float32, numpy=\n",
      "array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0.], dtype=float32)>, <tf.Variable 'basic_block_7/batch_normalization_18/moving_variance:0' shape=(512,) dtype=float32, numpy=\n",
      "array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1.], dtype=float32)>, <tf.Variable 'basic_block_7/batch_normalization_19/moving_mean:0' shape=(512,) dtype=float32, numpy=\n",
      "array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0.], dtype=float32)>, <tf.Variable 'basic_block_7/batch_normalization_19/moving_variance:0' shape=(512,) dtype=float32, numpy=\n",
      "array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1.], dtype=float32)>, <tf.Variable 'mlp_head/dense/kernel:0' shape=(512, 512) dtype=float32, numpy=\n",
      "array([[ 0.02714133, -0.04072341,  0.03186389, ...,  0.04041736,\n",
      "        -0.04227544, -0.06699453],\n",
      "       [ 0.06984702, -0.00364951, -0.04741509, ..., -0.01117805,\n",
      "         0.01604454, -0.06595174],\n",
      "       [ 0.05547548, -0.01262198,  0.01200675, ...,  0.07189936,\n",
      "         0.07385894, -0.05040496],\n",
      "       ...,\n",
      "       [-0.03095106,  0.0570671 , -0.00709546, ...,  0.0585438 ,\n",
      "         0.03796703, -0.05647609],\n",
      "       [ 0.0648916 , -0.07471786, -0.03457243, ..., -0.00415909,\n",
      "         0.05568013, -0.03349867],\n",
      "       [ 0.02918486, -0.06031017,  0.0724768 , ..., -0.00533643,\n",
      "        -0.05986074, -0.00323337]], dtype=float32)>, <tf.Variable 'mlp_head/dense/bias:0' shape=(512,) dtype=float32, numpy=\n",
      "array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0.], dtype=float32)>, <tf.Variable 'mlp_head/dense_1/kernel:0' shape=(512, 128) dtype=float32, numpy=\n",
      "array([[ 0.07310878,  0.0357673 , -0.08082557, ...,  0.05533344,\n",
      "        -0.09280665,  0.08718754],\n",
      "       [-0.04293859, -0.00921235, -0.04511969, ..., -0.05314449,\n",
      "        -0.07271713, -0.01921012],\n",
      "       [ 0.05670588, -0.03405407, -0.02479864, ..., -0.0176338 ,\n",
      "         0.03492284,  0.03053646],\n",
      "       ...,\n",
      "       [ 0.01773731,  0.08461788,  0.05449513, ...,  0.0517076 ,\n",
      "         0.05359605, -0.02041491],\n",
      "       [ 0.09327452,  0.07414778, -0.01481851, ...,  0.03142364,\n",
      "         0.05082089, -0.0768794 ],\n",
      "       [-0.01234555, -0.07844909,  0.05984189, ..., -0.05980583,\n",
      "         0.09334904,  0.04834963]], dtype=float32)>, <tf.Variable 'mlp_head/batch_normalization_20/moving_mean:0' shape=(512,) dtype=float32, numpy=\n",
      "array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0.], dtype=float32)>, <tf.Variable 'mlp_head/batch_normalization_20/moving_variance:0' shape=(512,) dtype=float32, numpy=\n",
      "array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1.], dtype=float32)>, <tf.Variable 'mlp_head_1/dense_2/kernel:0' shape=(128, 512) dtype=float32, numpy=\n",
      "array([[ 0.02779648,  0.02281894, -0.01989815, ...,  0.03809439,\n",
      "         0.05667238,  0.04721057],\n",
      "       [ 0.09087986, -0.05759445,  0.01429611, ..., -0.08399107,\n",
      "         0.02692846, -0.05607376],\n",
      "       [-0.08727591,  0.06193176,  0.03141505, ..., -0.07934444,\n",
      "        -0.01788861, -0.04760786],\n",
      "       ...,\n",
      "       [-0.07324649,  0.07395054,  0.03184061, ..., -0.01214917,\n",
      "         0.02411792,  0.0484542 ],\n",
      "       [ 0.06764662,  0.01499873, -0.09540663, ...,  0.02743825,\n",
      "         0.03810851, -0.0798482 ],\n",
      "       [ 0.02252419,  0.07426427,  0.04194273, ..., -0.093517  ,\n",
      "         0.04130438, -0.01028349]], dtype=float32)>, <tf.Variable 'mlp_head_1/dense_2/bias:0' shape=(512,) dtype=float32, numpy=\n",
      "array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0.], dtype=float32)>, <tf.Variable 'mlp_head_1/dense_3/kernel:0' shape=(512, 128) dtype=float32, numpy=\n",
      "array([[ 0.0571014 ,  0.08427182,  0.04426761, ..., -0.03962069,\n",
      "        -0.02537163, -0.04288607],\n",
      "       [-0.05341225, -0.00253637,  0.03939587, ...,  0.06916632,\n",
      "        -0.00449807, -0.08196025],\n",
      "       [-0.08033727,  0.0747214 , -0.06365746, ...,  0.07964048,\n",
      "         0.04219787, -0.02759227],\n",
      "       ...,\n",
      "       [-0.009243  ,  0.01109355, -0.09371696, ...,  0.0242262 ,\n",
      "         0.00061958, -0.0280399 ],\n",
      "       [-0.09434666, -0.05961157,  0.02979146, ..., -0.07287464,\n",
      "        -0.00291286, -0.07418202],\n",
      "       [-0.09072187, -0.08105768,  0.02349749, ...,  0.03982005,\n",
      "         0.08608171,  0.00251094]], dtype=float32)>, <tf.Variable 'mlp_head_1/batch_normalization_21/moving_mean:0' shape=(512,) dtype=float32, numpy=\n",
      "array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0.], dtype=float32)>, <tf.Variable 'mlp_head_1/batch_normalization_21/moving_variance:0' shape=(512,) dtype=float32, numpy=\n",
      "array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1.], dtype=float32)>]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 5/5 [00:18<00:00,  3.76s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 000: Loss: 0.824\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m~/.pyenv/versions/new_ml_stuff/lib/python3.8/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36m_get_op_def\u001b[0;34m(self, type)\u001b[0m\n\u001b[1;32m   3961\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3962\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_op_def_cache\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3963\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'StatefulPartitionedCall'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-8fe1d978ba3e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mconfig\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_byol\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mexperiment\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0meu\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mExperiment\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mexperiment\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mds_small\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'saved_model'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/Documents/KTH/S3/Advanced DL/project/SelfSupervisedLearning/experiments/experiment_utils.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, ds, save_path, epochs, show_history)\u001b[0m\n\u001b[1;32m     82\u001b[0m                     epoch, epoch_loss_avg.result()))\n\u001b[1;32m     83\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 84\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0monline_network\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msave_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     85\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/KTH/S3/Advanced DL/project/SelfSupervisedLearning/models/model.py\u001b[0m in \u001b[0;36msave_model\u001b[0;34m(self, saved_model_path)\u001b[0m\n\u001b[1;32m     55\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     56\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0msave_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msaved_model_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 57\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msaved_model_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     58\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mload_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msaved_model_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/new_ml_stuff/lib/python3.8/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36msave\u001b[0;34m(self, filepath, overwrite, include_optimizer, save_format, signatures, options, save_traces)\u001b[0m\n\u001b[1;32m   2143\u001b[0m     \"\"\"\n\u001b[1;32m   2144\u001b[0m     \u001b[0;31m# pylint: enable=line-too-long\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2145\u001b[0;31m     save.save_model(self, filepath, overwrite, include_optimizer, save_format,\n\u001b[0m\u001b[1;32m   2146\u001b[0m                     signatures, options, save_traces)\n\u001b[1;32m   2147\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/new_ml_stuff/lib/python3.8/site-packages/keras/saving/save.py\u001b[0m in \u001b[0;36msave_model\u001b[0;34m(model, filepath, overwrite, include_optimizer, save_format, signatures, options, save_traces)\u001b[0m\n\u001b[1;32m    147\u001b[0m   \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    148\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mgeneric_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSharedObjectSavingScope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 149\u001b[0;31m       saved_model_save.save(model, filepath, overwrite, include_optimizer,\n\u001b[0m\u001b[1;32m    150\u001b[0m                             signatures, options, save_traces)\n\u001b[1;32m    151\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/new_ml_stuff/lib/python3.8/site-packages/keras/saving/saved_model/save.py\u001b[0m in \u001b[0;36msave\u001b[0;34m(model, filepath, overwrite, include_optimizer, signatures, options, save_traces)\u001b[0m\n\u001b[1;32m     88\u001b[0m   \u001b[0;32mwith\u001b[0m \u001b[0mK\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdeprecated_internal_learning_phase_scope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     89\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras_option_scope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msave_traces\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 90\u001b[0;31m       saved_nodes, node_paths = save_lib.save_and_return_nodes(\n\u001b[0m\u001b[1;32m     91\u001b[0m           model, filepath, signatures, options)\n\u001b[1;32m     92\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/new_ml_stuff/lib/python3.8/site-packages/tensorflow/python/saved_model/save.py\u001b[0m in \u001b[0;36msave_and_return_nodes\u001b[0;34m(obj, export_dir, signatures, options, experimental_skip_checkpoint)\u001b[0m\n\u001b[1;32m   1226\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1227\u001b[0m   _, exported_graph, object_saver, asset_info, saved_nodes, node_paths = (\n\u001b[0;32m-> 1228\u001b[0;31m       _build_meta_graph(obj, signatures, options, meta_graph_def))\n\u001b[0m\u001b[1;32m   1229\u001b[0m   saved_model.saved_model_schema_version = (\n\u001b[1;32m   1230\u001b[0m       pywrap_libexport.SAVED_MODEL_SCHEMA_VERSION)\n",
      "\u001b[0;32m~/.pyenv/versions/new_ml_stuff/lib/python3.8/site-packages/tensorflow/python/saved_model/save.py\u001b[0m in \u001b[0;36m_build_meta_graph\u001b[0;34m(obj, signatures, options, meta_graph_def)\u001b[0m\n\u001b[1;32m   1397\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1398\u001b[0m   \u001b[0;32mwith\u001b[0m \u001b[0msave_context\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1399\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_build_meta_graph_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msignatures\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmeta_graph_def\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/.pyenv/versions/new_ml_stuff/lib/python3.8/site-packages/tensorflow/python/saved_model/save.py\u001b[0m in \u001b[0;36m_build_meta_graph_impl\u001b[0;34m(obj, signatures, options, meta_graph_def)\u001b[0m\n\u001b[1;32m   1333\u001b[0m   \u001b[0mcheckpoint_graph_view\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_AugmentedGraphView\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1334\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0msignatures\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1335\u001b[0;31m     signatures = signature_serialization.find_function_to_export(\n\u001b[0m\u001b[1;32m   1336\u001b[0m         checkpoint_graph_view)\n\u001b[1;32m   1337\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/new_ml_stuff/lib/python3.8/site-packages/tensorflow/python/saved_model/signature_serialization.py\u001b[0m in \u001b[0;36mfind_function_to_export\u001b[0;34m(saveable_view)\u001b[0m\n\u001b[1;32m     97\u001b[0m   \u001b[0;31m# If the user did not specify signatures, check the root object for a function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     98\u001b[0m   \u001b[0;31m# that can be made into a signature.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 99\u001b[0;31m   \u001b[0mfunctions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msaveable_view\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlist_functions\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msaveable_view\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mroot\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    100\u001b[0m   \u001b[0msignature\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunctions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mDEFAULT_SIGNATURE_ATTR\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    101\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0msignature\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/new_ml_stuff/lib/python3.8/site-packages/tensorflow/python/saved_model/save.py\u001b[0m in \u001b[0;36mlist_functions\u001b[0;34m(self, obj)\u001b[0m\n\u001b[1;32m    161\u001b[0m     \u001b[0mobj_functions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_functions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    162\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mobj_functions\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 163\u001b[0;31m       obj_functions = obj._list_functions_for_serialization(  # pylint: disable=protected-access\n\u001b[0m\u001b[1;32m    164\u001b[0m           self._serialization_cache)\n\u001b[1;32m    165\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_functions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mobj_functions\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/new_ml_stuff/lib/python3.8/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36m_list_functions_for_serialization\u001b[0;34m(self, serialization_cache)\u001b[0m\n\u001b[1;32m   2810\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2811\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_tf_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2812\u001b[0;31m     functions = super(\n\u001b[0m\u001b[1;32m   2813\u001b[0m         Model, self)._list_functions_for_serialization(serialization_cache)\n\u001b[1;32m   2814\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/new_ml_stuff/lib/python3.8/site-packages/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m_list_functions_for_serialization\u001b[0;34m(self, serialization_cache)\u001b[0m\n\u001b[1;32m   3083\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3084\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_list_functions_for_serialization\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mserialization_cache\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3085\u001b[0;31m     return (self._trackable_saved_model_saver\n\u001b[0m\u001b[1;32m   3086\u001b[0m             .list_functions_for_serialization(serialization_cache))\n\u001b[1;32m   3087\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/new_ml_stuff/lib/python3.8/site-packages/keras/saving/saved_model/base_serialization.py\u001b[0m in \u001b[0;36mlist_functions_for_serialization\u001b[0;34m(self, serialization_cache)\u001b[0m\n\u001b[1;32m     91\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     92\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 93\u001b[0;31m     \u001b[0mfns\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunctions_to_serialize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mserialization_cache\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     94\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m     \u001b[0;31m# The parent AutoTrackable class saves all user-defined tf.functions, and\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/new_ml_stuff/lib/python3.8/site-packages/keras/saving/saved_model/layer_serialization.py\u001b[0m in \u001b[0;36mfunctions_to_serialize\u001b[0;34m(self, serialization_cache)\u001b[0m\n\u001b[1;32m     71\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mfunctions_to_serialize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mserialization_cache\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 73\u001b[0;31m     return (self._get_serialized_attributes(\n\u001b[0m\u001b[1;32m     74\u001b[0m         serialization_cache).functions_to_serialize)\n\u001b[1;32m     75\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/new_ml_stuff/lib/python3.8/site-packages/keras/saving/saved_model/layer_serialization.py\u001b[0m in \u001b[0;36m_get_serialized_attributes\u001b[0;34m(self, serialization_cache)\u001b[0m\n\u001b[1;32m     87\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mserialized_attr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     88\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 89\u001b[0;31m     object_dict, function_dict = self._get_serialized_attributes_internal(\n\u001b[0m\u001b[1;32m     90\u001b[0m         serialization_cache)\n\u001b[1;32m     91\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/new_ml_stuff/lib/python3.8/site-packages/keras/saving/saved_model/model_serialization.py\u001b[0m in \u001b[0;36m_get_serialized_attributes_internal\u001b[0;34m(self, serialization_cache)\u001b[0m\n\u001b[1;32m     54\u001b[0m     \u001b[0;31m# the ones serialized by Layer.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     55\u001b[0m     objects, functions = (\n\u001b[0;32m---> 56\u001b[0;31m         super(ModelSavedModelSaver, self)._get_serialized_attributes_internal(\n\u001b[0m\u001b[1;32m     57\u001b[0m             serialization_cache))\n\u001b[1;32m     58\u001b[0m     \u001b[0mfunctions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'_default_save_signature'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdefault_signature\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/new_ml_stuff/lib/python3.8/site-packages/keras/saving/saved_model/layer_serialization.py\u001b[0m in \u001b[0;36m_get_serialized_attributes_internal\u001b[0;34m(self, serialization_cache)\u001b[0m\n\u001b[1;32m     97\u001b[0m     \u001b[0;34m\"\"\"Returns dictionary of serialized attributes.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     98\u001b[0m     \u001b[0mobjects\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msave_impl\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrap_layer_objects\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mserialization_cache\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 99\u001b[0;31m     \u001b[0mfunctions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msave_impl\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrap_layer_functions\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mserialization_cache\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    100\u001b[0m     \u001b[0;31m# Attribute validator requires that the default save signature is added to\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    101\u001b[0m     \u001b[0;31m# function dict, even if the value is None.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/new_ml_stuff/lib/python3.8/site-packages/keras/saving/saved_model/save_impl.py\u001b[0m in \u001b[0;36mwrap_layer_functions\u001b[0;34m(layer, serialization_cache)\u001b[0m\n\u001b[1;32m    147\u001b[0m   \u001b[0;31m# Reset the losses of the layer and its children. The call function in each\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    148\u001b[0m   \u001b[0;31m# child layer is replaced with tf.functions.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 149\u001b[0;31m   \u001b[0moriginal_fns\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_replace_child_layer_functions\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlayer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mserialization_cache\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    150\u001b[0m   \u001b[0moriginal_losses\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_reset_layer_losses\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlayer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    151\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/new_ml_stuff/lib/python3.8/site-packages/keras/saving/saved_model/save_impl.py\u001b[0m in \u001b[0;36m_replace_child_layer_functions\u001b[0;34m(layer, serialization_cache)\u001b[0m\n\u001b[1;32m    274\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchild_layer\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mserialization_cache\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mconstants\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mKERAS_CACHE_KEY\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    275\u001b[0m       serialized_functions = (\n\u001b[0;32m--> 276\u001b[0;31m           child_layer._trackable_saved_model_saver._get_serialized_attributes(\n\u001b[0m\u001b[1;32m    277\u001b[0m               serialization_cache).functions)\n\u001b[1;32m    278\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/new_ml_stuff/lib/python3.8/site-packages/keras/saving/saved_model/layer_serialization.py\u001b[0m in \u001b[0;36m_get_serialized_attributes\u001b[0;34m(self, serialization_cache)\u001b[0m\n\u001b[1;32m     87\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mserialized_attr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     88\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 89\u001b[0;31m     object_dict, function_dict = self._get_serialized_attributes_internal(\n\u001b[0m\u001b[1;32m     90\u001b[0m         serialization_cache)\n\u001b[1;32m     91\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/new_ml_stuff/lib/python3.8/site-packages/keras/saving/saved_model/model_serialization.py\u001b[0m in \u001b[0;36m_get_serialized_attributes_internal\u001b[0;34m(self, serialization_cache)\u001b[0m\n\u001b[1;32m     54\u001b[0m     \u001b[0;31m# the ones serialized by Layer.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     55\u001b[0m     objects, functions = (\n\u001b[0;32m---> 56\u001b[0;31m         super(ModelSavedModelSaver, self)._get_serialized_attributes_internal(\n\u001b[0m\u001b[1;32m     57\u001b[0m             serialization_cache))\n\u001b[1;32m     58\u001b[0m     \u001b[0mfunctions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'_default_save_signature'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdefault_signature\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/new_ml_stuff/lib/python3.8/site-packages/keras/saving/saved_model/layer_serialization.py\u001b[0m in \u001b[0;36m_get_serialized_attributes_internal\u001b[0;34m(self, serialization_cache)\u001b[0m\n\u001b[1;32m     97\u001b[0m     \u001b[0;34m\"\"\"Returns dictionary of serialized attributes.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     98\u001b[0m     \u001b[0mobjects\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msave_impl\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrap_layer_objects\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mserialization_cache\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 99\u001b[0;31m     \u001b[0mfunctions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msave_impl\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrap_layer_functions\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mserialization_cache\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    100\u001b[0m     \u001b[0;31m# Attribute validator requires that the default save signature is added to\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    101\u001b[0m     \u001b[0;31m# function dict, even if the value is None.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/new_ml_stuff/lib/python3.8/site-packages/keras/saving/saved_model/save_impl.py\u001b[0m in \u001b[0;36mwrap_layer_functions\u001b[0;34m(layer, serialization_cache)\u001b[0m\n\u001b[1;32m    195\u001b[0m       \u001b[0;32mfor\u001b[0m \u001b[0mfn\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mfns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    196\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mfn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mLayerCall\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 197\u001b[0;31m           \u001b[0mfn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_concrete_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    198\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    199\u001b[0m   \u001b[0;31m# Restore overwritten functions and losses\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.8.5/lib/python3.8/contextlib.py\u001b[0m in \u001b[0;36m__exit__\u001b[0;34m(self, type, value, traceback)\u001b[0m\n\u001b[1;32m    118\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mtype\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    119\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 120\u001b[0;31m                 \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgen\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    121\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mStopIteration\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    122\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/new_ml_stuff/lib/python3.8/site-packages/keras/saving/saved_model/save_impl.py\u001b[0m in \u001b[0;36mtracing_scope\u001b[0;34m()\u001b[0m\n\u001b[1;32m    357\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mtraining\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    358\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mK\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdeprecated_internal_learning_phase_scope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtraining\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 359\u001b[0;31m           \u001b[0mfn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_concrete_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    360\u001b[0m       \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    361\u001b[0m         \u001b[0mfn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_concrete_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/new_ml_stuff/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36mget_concrete_function\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1231\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mget_concrete_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1232\u001b[0m     \u001b[0;31m# Implements GenericFunction.get_concrete_function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1233\u001b[0;31m     \u001b[0mconcrete\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_concrete_function_garbage_collected\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1234\u001b[0m     \u001b[0mconcrete\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_garbage_collector\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelease\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1235\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mconcrete\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/new_ml_stuff/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_get_concrete_function_garbage_collected\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1222\u001b[0m       \u001b[0;31m# In this case we have not created variables on the first call. So we can\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1223\u001b[0m       \u001b[0;31m# run the first trace but we should fail if variables are created.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1224\u001b[0;31m       concrete = self._stateful_fn._get_concrete_function_garbage_collected(  # pylint: disable=protected-access\n\u001b[0m\u001b[1;32m   1225\u001b[0m           *args, **kwargs)\n\u001b[1;32m   1226\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_created_variables\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/new_ml_stuff/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_get_concrete_function_garbage_collected\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   3114\u001b[0m       \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3115\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3116\u001b[0;31m       \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3117\u001b[0m       \u001b[0mseen_names\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3118\u001b[0m       captured = object_identity.ObjectIdentitySet(\n",
      "\u001b[0;32m~/.pyenv/versions/new_ml_stuff/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_maybe_define_function\u001b[0;34m(self, args, kwargs)\u001b[0m\n\u001b[1;32m   3461\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3462\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmissed\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcall_context_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3463\u001b[0;31m           \u001b[0mgraph_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_create_graph_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3464\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprimary\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcache_key\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3465\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/new_ml_stuff/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_create_graph_function\u001b[0;34m(self, args, kwargs, override_flat_arg_shapes)\u001b[0m\n\u001b[1;32m   3296\u001b[0m     \u001b[0marg_names\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbase_arg_names\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mmissing_arg_names\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3297\u001b[0m     graph_function = ConcreteFunction(\n\u001b[0;32m-> 3298\u001b[0;31m         func_graph_module.func_graph_from_py_func(\n\u001b[0m\u001b[1;32m   3299\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_name\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3300\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_python_function\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/new_ml_stuff/lib/python3.8/site-packages/tensorflow/python/framework/func_graph.py\u001b[0m in \u001b[0;36mfunc_graph_from_py_func\u001b[0;34m(name, python_func, args, kwargs, signature, func_graph, autograph, autograph_options, add_control_dependencies, arg_names, op_return_value, collections, capture_by_value, override_flat_arg_shapes, acd_record_initial_resource_uses)\u001b[0m\n\u001b[1;32m   1005\u001b[0m         \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moriginal_func\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_decorator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munwrap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpython_func\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1006\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1007\u001b[0;31m       \u001b[0mfunc_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpython_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mfunc_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfunc_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1008\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1009\u001b[0m       \u001b[0;31m# invariant: `func_outputs` contains only Tensors, CompositeTensors,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/new_ml_stuff/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36mwrapped_fn\u001b[0;34m(*args, **kwds)\u001b[0m\n\u001b[1;32m    666\u001b[0m         \u001b[0;31m# the function a weak reference to itself to avoid a reference cycle.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    667\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcompile_with_xla\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 668\u001b[0;31m           \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mweak_wrapped_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__wrapped__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    669\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    670\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/new_ml_stuff/lib/python3.8/site-packages/keras/saving/saved_model/save_impl.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    570\u001b[0m       with autocast_variable.enable_auto_cast_variables(\n\u001b[1;32m    571\u001b[0m           layer._compute_dtype_object):  # pylint: disable=protected-access\n\u001b[0;32m--> 572\u001b[0;31m         \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    573\u001b[0m     \u001b[0m_restore_layer_losses\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moriginal_losses\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    574\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mret\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/new_ml_stuff/lib/python3.8/site-packages/keras/saving/saved_model/utils.py\u001b[0m in \u001b[0;36mwrap_with_training_arg\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    162\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mwrapped_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    163\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 164\u001b[0;31m     return control_flow_util.smart_cond(\n\u001b[0m\u001b[1;32m    165\u001b[0m         \u001b[0mtraining\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mlambda\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mreplace_training_and_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    166\u001b[0m         lambda: replace_training_and_call(False))\n",
      "\u001b[0;32m~/.pyenv/versions/new_ml_stuff/lib/python3.8/site-packages/keras/utils/control_flow_util.py\u001b[0m in \u001b[0;36msmart_cond\u001b[0;34m(pred, true_fn, false_fn, name)\u001b[0m\n\u001b[1;32m    103\u001b[0m     return tf.cond(\n\u001b[1;32m    104\u001b[0m         pred, true_fn=true_fn, false_fn=false_fn, name=name)\n\u001b[0;32m--> 105\u001b[0;31m   return tf.__internal__.smart_cond.smart_cond(\n\u001b[0m\u001b[1;32m    106\u001b[0m       pred, true_fn=true_fn, false_fn=false_fn, name=name)\n\u001b[1;32m    107\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/new_ml_stuff/lib/python3.8/site-packages/tensorflow/python/framework/smart_cond.py\u001b[0m in \u001b[0;36msmart_cond\u001b[0;34m(pred, true_fn, false_fn, name)\u001b[0m\n\u001b[1;32m     54\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mpred_value\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     55\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mpred_value\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 56\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mtrue_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     57\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mfalse_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/new_ml_stuff/lib/python3.8/site-packages/keras/saving/saved_model/utils.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    163\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    164\u001b[0m     return control_flow_util.smart_cond(\n\u001b[0;32m--> 165\u001b[0;31m         \u001b[0mtraining\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mlambda\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mreplace_training_and_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    166\u001b[0m         lambda: replace_training_and_call(False))\n\u001b[1;32m    167\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/new_ml_stuff/lib/python3.8/site-packages/keras/saving/saved_model/utils.py\u001b[0m in \u001b[0;36mreplace_training_and_call\u001b[0;34m(training)\u001b[0m\n\u001b[1;32m    160\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mreplace_training_and_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtraining\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    161\u001b[0m       \u001b[0mset_training_arg\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtraining\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining_arg_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 162\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mwrapped_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    163\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    164\u001b[0m     return control_flow_util.smart_cond(\n",
      "\u001b[0;32m~/.pyenv/versions/new_ml_stuff/lib/python3.8/site-packages/keras/saving/saved_model/save_impl.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(inputs, *args, **kwargs)\u001b[0m\n\u001b[1;32m    649\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mlayer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras_api\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__call__\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    650\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mcall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 651\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mcall_and_return_conditional_losses\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    652\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0m_create_call_fn_decorator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlayer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcall\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    653\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/new_ml_stuff/lib/python3.8/site-packages/keras/saving/saved_model/save_impl.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    607\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    608\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_trace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 609\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrapped_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    610\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    611\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mget_concrete_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/new_ml_stuff/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    883\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    884\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 885\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    886\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    887\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/new_ml_stuff/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    922\u001b[0m       \u001b[0;31m# In this case we have not created variables on the first call. So we can\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    923\u001b[0m       \u001b[0;31m# run the first trace but we should fail if variables are created.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 924\u001b[0;31m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    925\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_created_variables\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mALLOW_DYNAMIC_VARIABLE_CREATION\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    926\u001b[0m         raise ValueError(\"Creating variables on a non-first call to a function\"\n",
      "\u001b[0;32m~/.pyenv/versions/new_ml_stuff/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   3037\u001b[0m       (graph_function,\n\u001b[1;32m   3038\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[0;32m-> 3039\u001b[0;31m     return graph_function._call_flat(\n\u001b[0m\u001b[1;32m   3040\u001b[0m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[1;32m   3041\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/new_ml_stuff/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1975\u001b[0m           {\"PartitionedCall\": self._get_gradient_function(),\n\u001b[1;32m   1976\u001b[0m            \"StatefulPartitionedCall\": self._get_gradient_function()}):\n\u001b[0;32m-> 1977\u001b[0;31m         \u001b[0mflat_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mforward_function\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mctx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs_with_tangents\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1978\u001b[0m     \u001b[0mforward_backward\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecord\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mflat_outputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1979\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_build_call_outputs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mflat_outputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/new_ml_stuff/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    617\u001b[0m           \u001b[0;31m# forwardprop code (GradientTape manages to ignore it).\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    618\u001b[0m           \u001b[0;32mwith\u001b[0m \u001b[0mtape\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstop_recording\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 619\u001b[0;31m             outputs = functional_ops.partitioned_call(\n\u001b[0m\u001b[1;32m    620\u001b[0m                 \u001b[0margs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    621\u001b[0m                 \u001b[0mf\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/new_ml_stuff/lib/python3.8/site-packages/tensorflow/python/ops/functional_ops.py\u001b[0m in \u001b[0;36mpartitioned_call\u001b[0;34m(args, f, tout, executing_eagerly, config, executor_type)\u001b[0m\n\u001b[1;32m   1219\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mxla_compile_attr\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdefinition\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mattr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1220\u001b[0m     \u001b[0mop_attrs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mxla_compile_attr\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdefinition\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mattr\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mxla_compile_attr\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1221\u001b[0;31m   \u001b[0mop\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgraph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreate_op\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mop_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mop_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mop_attrs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1222\u001b[0m   \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1223\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"graph\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/new_ml_stuff/lib/python3.8/site-packages/tensorflow/python/util/deprecation.py\u001b[0m in \u001b[0;36mnew_func\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    547\u001b[0m                 \u001b[0;34m'in a future version'\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mdate\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m'after %s'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mdate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    548\u001b[0m                 instructions)\n\u001b[0;32m--> 549\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    550\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    551\u001b[0m     doc = _add_deprecated_arg_notice_to_docstring(\n",
      "\u001b[0;32m~/.pyenv/versions/new_ml_stuff/lib/python3.8/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36mcreate_op\u001b[0;34m(***failed resolving arguments***)\u001b[0m\n\u001b[1;32m   3497\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3498\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Input #%d is not a tensor: %s\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ma\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3499\u001b[0;31m     return self._create_op_internal(op_type, inputs, dtypes, input_types, name,\n\u001b[0m\u001b[1;32m   3500\u001b[0m                                     attrs, op_def, compute_device)\n\u001b[1;32m   3501\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/new_ml_stuff/lib/python3.8/site-packages/tensorflow/python/framework/func_graph.py\u001b[0m in \u001b[0;36m_create_op_internal\u001b[0;34m(self, op_type, inputs, dtypes, input_types, name, attrs, op_def, compute_device)\u001b[0m\n\u001b[1;32m    597\u001b[0m       \u001b[0minp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcapture\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    598\u001b[0m       \u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 599\u001b[0;31m     return super(FuncGraph, self)._create_op_internal(  # pylint: disable=protected-access\n\u001b[0m\u001b[1;32m    600\u001b[0m         \u001b[0mop_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtypes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_types\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop_def\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    601\u001b[0m         compute_device)\n",
      "\u001b[0;32m~/.pyenv/versions/new_ml_stuff/lib/python3.8/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36m_create_op_internal\u001b[0;34m(self, op_type, inputs, dtypes, input_types, name, attrs, op_def, compute_device)\u001b[0m\n\u001b[1;32m   3559\u001b[0m     \u001b[0;31m# Session.run call cannot occur between creating and mutating the op.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3560\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_mutation_lock\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3561\u001b[0;31m       ret = Operation(\n\u001b[0m\u001b[1;32m   3562\u001b[0m           \u001b[0mnode_def\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3563\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/new_ml_stuff/lib/python3.8/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, node_def, g, inputs, output_types, control_inputs, input_types, original_op, op_def)\u001b[0m\n\u001b[1;32m   2038\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2039\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mop_def\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2040\u001b[0;31m         \u001b[0mop_def\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_graph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_op_def\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode_def\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mop\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2041\u001b[0m       self._c_op = _create_c_op(self._graph, node_def, inputs,\n\u001b[1;32m   2042\u001b[0m                                 control_input_ops, op_def)\n",
      "\u001b[0;32m~/.pyenv/versions/new_ml_stuff/lib/python3.8/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36m_get_op_def\u001b[0;34m(self, type)\u001b[0m\n\u001b[1;32m   3969\u001b[0m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpywrap_tf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbuf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3970\u001b[0m       \u001b[0mop_def\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mop_def_pb2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpDef\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3971\u001b[0;31m       \u001b[0mop_def\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mParseFromString\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_bytes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3972\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_op_def_cache\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mop_def\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3973\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mop_def\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "importlib.reload(eu)\n",
    "ds, _ = get_stl10(batch_size=5, split='train')\n",
    "ds_small = ds.take(5)\n",
    "config = conf.get_byol()\n",
    "experiment = eu.Experiment(config)\n",
    "experiment.train(ds_small, 'saved_model', epochs=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5, 128)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[ 3.31537202e-02, -5.36188558e-02, -1.87725574e-02,\n",
       "         5.00399433e-02, -6.07553916e-03,  1.54159106e-02,\n",
       "         4.35693860e-02,  5.63887060e-02, -2.96695232e-02,\n",
       "         9.03071836e-03,  5.76402545e-02,  5.48327342e-02,\n",
       "         2.57254932e-02, -3.85051034e-03,  2.17803158e-02,\n",
       "        -3.79391015e-04,  4.20477986e-02,  7.78120477e-03,\n",
       "        -1.62516944e-02, -7.28299469e-02, -6.71901740e-04,\n",
       "        -8.38991255e-05,  3.69728096e-02,  7.65915634e-03,\n",
       "        -1.66247226e-03, -4.38600741e-02,  1.05069047e-02,\n",
       "         1.80620179e-02,  3.87496836e-02, -2.79563610e-02,\n",
       "        -4.26811948e-02, -6.25194237e-03, -4.92621548e-02,\n",
       "        -4.89186607e-02,  2.87935827e-02, -1.71239190e-02,\n",
       "         4.41903137e-02,  3.95971090e-02, -4.88426350e-02,\n",
       "         3.55689460e-03,  2.83920784e-02, -7.92761706e-03,\n",
       "         1.09058619e-02, -3.30093987e-02, -3.07188965e-02,\n",
       "         4.03139368e-03,  3.47156487e-02,  4.15029377e-03,\n",
       "         2.20839325e-02, -1.06048528e-02, -2.68328236e-04,\n",
       "        -9.09530558e-03, -3.86053659e-02, -5.12494706e-02,\n",
       "         3.90910953e-02,  3.20237800e-02,  2.48414073e-02,\n",
       "        -2.43671201e-02,  2.39363313e-03, -1.40804965e-02,\n",
       "        -2.01352648e-02,  1.50572713e-02, -9.19572264e-03,\n",
       "        -6.94013685e-02, -4.35110833e-03,  1.25841694e-02,\n",
       "        -4.11614291e-02,  1.09876972e-03, -2.75402069e-02,\n",
       "        -5.40009281e-03, -6.39783666e-02, -3.69158685e-02,\n",
       "        -5.49481018e-03,  2.26154290e-02, -1.38096865e-02,\n",
       "         3.12629268e-02, -1.28996084e-02, -5.10636158e-02,\n",
       "        -3.06625105e-03,  1.32296868e-02, -1.42411012e-02,\n",
       "         4.60438803e-03, -8.30799118e-02,  1.32372975e-02,\n",
       "        -2.91632265e-02,  2.06277799e-02, -8.95127933e-03,\n",
       "         3.97168919e-02,  3.10776085e-02,  6.54692389e-03,\n",
       "        -3.29990080e-03,  5.12013957e-03,  2.80587003e-04,\n",
       "        -1.03430282e-02, -3.92366499e-02, -8.02176632e-03,\n",
       "         1.12787727e-02, -3.32782529e-02,  4.33826074e-02,\n",
       "        -1.56130791e-02, -6.34146109e-03, -1.80711783e-03,\n",
       "         2.64728069e-02, -9.30968113e-03,  1.27417408e-02,\n",
       "        -1.06650637e-03, -3.28008682e-02, -5.48623689e-02,\n",
       "         6.42099325e-03, -1.67569239e-02,  7.60367140e-03,\n",
       "         1.97169781e-02, -3.05965748e-02,  2.10059676e-02,\n",
       "        -8.76831114e-02, -3.68584096e-02,  1.54668773e-02,\n",
       "         1.53905228e-02,  1.29373763e-02,  3.14123742e-02,\n",
       "         2.12460402e-02,  5.76977283e-02,  4.07452136e-03,\n",
       "        -8.03245977e-03,  7.42796715e-03, -1.90831386e-02,\n",
       "        -3.67148146e-02,  5.68297207e-02],\n",
       "       [ 3.98950987e-02, -5.77412769e-02, -1.17613999e-02,\n",
       "         5.07464521e-02, -3.36011546e-03,  2.00871713e-02,\n",
       "         4.94009256e-02,  6.18459433e-02, -3.33079174e-02,\n",
       "         7.76200322e-03,  6.23843670e-02,  5.99659011e-02,\n",
       "         3.09745595e-02, -4.25485708e-03,  1.94870662e-02,\n",
       "        -2.82556168e-03,  5.10859266e-02,  4.50035278e-03,\n",
       "        -1.80068146e-02, -8.28420296e-02,  1.92531012e-03,\n",
       "        -1.75738567e-03,  4.32039499e-02,  1.11510288e-02,\n",
       "        -3.32592428e-03, -5.45831770e-02,  6.05668500e-03,\n",
       "         1.71822552e-02,  3.82055677e-02, -3.22696753e-02,\n",
       "        -4.87894416e-02, -1.15663521e-02, -5.17833270e-02,\n",
       "        -5.27531803e-02,  3.90263423e-02, -2.20391750e-02,\n",
       "         5.15583381e-02,  4.80002090e-02, -4.59318012e-02,\n",
       "         2.34554429e-03,  2.75645852e-02, -1.51271187e-03,\n",
       "         1.88164860e-02, -3.53721231e-02, -2.94911936e-02,\n",
       "         7.95174763e-03,  3.88967432e-02, -1.61017105e-03,\n",
       "         3.38090397e-02, -1.17511163e-02, -2.57948972e-03,\n",
       "        -8.63099284e-03, -4.75720465e-02, -6.12158142e-02,\n",
       "         4.38517146e-02,  4.43634465e-02,  2.75716782e-02,\n",
       "        -3.18055078e-02,  2.24934891e-04, -1.49455070e-02,\n",
       "        -2.57744659e-02,  1.94371901e-02, -6.03955798e-03,\n",
       "        -8.24505985e-02, -1.13854501e-02,  2.10981555e-02,\n",
       "        -4.82613854e-02, -2.75487546e-04, -2.95941923e-02,\n",
       "        -1.32722454e-03, -7.56413266e-02, -4.25238982e-02,\n",
       "        -5.90243516e-03,  2.63427608e-02, -1.57744084e-02,\n",
       "         3.46911326e-02, -1.03335036e-02, -5.22835031e-02,\n",
       "        -2.13255174e-04,  1.81529559e-02, -1.25682950e-02,\n",
       "         5.83968312e-03, -8.90391469e-02,  1.59002803e-02,\n",
       "        -3.56830806e-02,  2.34574303e-02, -6.20693993e-03,\n",
       "         4.53177392e-02,  3.58311534e-02,  2.59828521e-03,\n",
       "        -5.97913843e-03,  7.00223632e-03,  6.26550987e-04,\n",
       "        -9.01173800e-03, -4.40826304e-02, -6.85839541e-03,\n",
       "         2.02313662e-02, -3.58522683e-02,  4.87998202e-02,\n",
       "        -2.07709484e-02, -8.77412781e-03, -3.27902474e-03,\n",
       "         3.26170772e-02, -7.74009898e-03,  1.50404237e-02,\n",
       "        -4.34173876e-03, -3.26161310e-02, -5.74674085e-02,\n",
       "         8.88585299e-03, -1.62239671e-02,  1.46415681e-02,\n",
       "         2.46095080e-02, -3.17924097e-02,  2.57027224e-02,\n",
       "        -1.00171201e-01, -3.77121568e-02,  1.20960698e-02,\n",
       "         2.63381898e-02,  1.67600978e-02,  2.90021002e-02,\n",
       "         2.39175837e-02,  6.44787624e-02,  1.16894674e-03,\n",
       "        -8.87188874e-03,  8.48065410e-03, -2.02170182e-02,\n",
       "        -4.82466593e-02,  6.67031482e-02],\n",
       "       [ 2.87319291e-02, -4.60317880e-02, -1.09290667e-02,\n",
       "         4.12269942e-02, -4.72886115e-03,  1.43320160e-02,\n",
       "         4.55629975e-02,  4.83859256e-02, -2.75592133e-02,\n",
       "         8.00323021e-03,  5.44697605e-02,  4.72499952e-02,\n",
       "         2.76092291e-02,  9.58820805e-04,  1.76899936e-02,\n",
       "        -3.58972978e-03,  4.02945951e-02,  7.82869011e-03,\n",
       "        -1.37483664e-02, -6.64006919e-02, -3.40450648e-03,\n",
       "         5.90677839e-04,  3.17542255e-02,  9.09262523e-03,\n",
       "         3.04784998e-03, -4.16422971e-02,  7.35793635e-03,\n",
       "         1.44524490e-02,  3.48981656e-02, -2.60446593e-02,\n",
       "        -3.46791856e-02, -7.98846409e-03, -4.16691825e-02,\n",
       "        -4.48202901e-02,  2.86847018e-02, -1.62786525e-02,\n",
       "         3.81091237e-02,  3.64270359e-02, -4.07736748e-02,\n",
       "         6.24851836e-03,  2.36657243e-02, -6.82563148e-03,\n",
       "         1.50657203e-02, -3.26728001e-02, -2.66905930e-02,\n",
       "         3.70021723e-03,  3.04009505e-02,  8.08916800e-03,\n",
       "         2.10473277e-02, -8.50364193e-03,  4.91441227e-04,\n",
       "        -8.60966183e-03, -3.67422365e-02, -4.67571169e-02,\n",
       "         3.28952372e-02,  2.96886005e-02,  2.22937763e-02,\n",
       "        -2.46305037e-02,  1.69608183e-03, -1.04898661e-02,\n",
       "        -1.75306723e-02,  1.24857984e-02, -5.41565474e-03,\n",
       "        -6.56653047e-02, -5.65098319e-03,  1.10326046e-02,\n",
       "        -3.54919657e-02, -2.96116341e-04, -2.48667244e-02,\n",
       "        -4.25984804e-03, -5.93903475e-02, -3.50055769e-02,\n",
       "        -1.10676466e-03,  2.20546164e-02, -1.27541646e-02,\n",
       "         2.63948664e-02, -1.64692122e-02, -4.46232930e-02,\n",
       "        -5.88942738e-03,  1.25315292e-02, -1.44781377e-02,\n",
       "         2.54938751e-03, -7.42767453e-02,  1.51733821e-02,\n",
       "        -3.36394943e-02,  1.54844411e-02, -2.53282208e-03,\n",
       "         3.45233381e-02,  2.88761966e-02,  4.78934171e-03,\n",
       "        -4.58678184e-03,  7.48631917e-03,  2.53651850e-03,\n",
       "        -7.72997737e-03, -3.46808843e-02, -6.82322122e-03,\n",
       "         8.62260722e-03, -2.58248635e-02,  3.98648046e-02,\n",
       "        -1.20633682e-02, -7.81556964e-03,  4.74121980e-03,\n",
       "         2.54295617e-02, -8.79604183e-03,  1.08225020e-02,\n",
       "        -3.90621310e-04, -2.37395130e-02, -4.91733253e-02,\n",
       "         5.46770450e-03, -1.61307193e-02,  1.37016242e-02,\n",
       "         1.98849030e-02, -2.74076685e-02,  1.95824094e-02,\n",
       "        -8.08520392e-02, -2.84346901e-02,  1.33817093e-02,\n",
       "         1.49733741e-02,  1.27994008e-02,  2.75967550e-02,\n",
       "         2.14712154e-02,  5.40600009e-02,  6.23696856e-03,\n",
       "        -7.79910758e-03,  8.70461762e-03, -2.10412908e-02,\n",
       "        -3.29693668e-02,  5.17960042e-02],\n",
       "       [ 2.83374209e-02, -4.81251404e-02, -1.46989301e-02,\n",
       "         4.16697189e-02, -6.13676570e-03,  1.68839060e-02,\n",
       "         4.55299541e-02,  4.96952608e-02, -2.70044655e-02,\n",
       "         9.73267574e-03,  5.19978777e-02,  4.79944646e-02,\n",
       "         2.55201608e-02, -2.72440724e-03,  1.87040046e-02,\n",
       "        -1.61037664e-03,  4.02768552e-02,  7.23704416e-03,\n",
       "        -1.23606166e-02, -6.60310984e-02, -1.40773784e-03,\n",
       "         4.14697453e-04,  3.39019224e-02,  9.71313380e-03,\n",
       "         3.21909785e-04, -3.96704003e-02,  8.09273403e-03,\n",
       "         1.40203545e-02,  3.46538238e-02, -2.72118077e-02,\n",
       "        -3.34872492e-02, -8.19438137e-03, -4.16219607e-02,\n",
       "        -4.54619154e-02,  2.61558648e-02, -1.62228346e-02,\n",
       "         3.73289026e-02,  3.19285318e-02, -3.98238450e-02,\n",
       "         2.97073135e-03,  2.07050368e-02, -7.22086430e-03,\n",
       "         1.34737995e-02, -3.13520357e-02, -2.99818143e-02,\n",
       "         4.38405201e-03,  2.95884106e-02,  4.86375950e-03,\n",
       "         1.85053200e-02, -8.89237411e-03,  1.58047886e-03,\n",
       "        -8.64462182e-03, -3.34611349e-02, -4.80611846e-02,\n",
       "         3.54591385e-02,  2.64158379e-02,  2.42349505e-02,\n",
       "        -2.17688847e-02,  1.68226473e-03, -1.00254584e-02,\n",
       "        -1.40764499e-02,  1.03629846e-02, -8.68735928e-03,\n",
       "        -6.53998852e-02, -6.00652117e-03,  1.03375427e-02,\n",
       "        -3.68058495e-02, -2.64830422e-04, -2.38314942e-02,\n",
       "        -6.60046749e-03, -5.77409565e-02, -3.46882902e-02,\n",
       "        -3.53791565e-03,  2.09362507e-02, -1.38850566e-02,\n",
       "         2.55462863e-02, -1.22002997e-02, -4.55082580e-02,\n",
       "        -5.55272028e-03,  1.11684892e-02, -1.46661494e-02,\n",
       "         3.57886963e-03, -7.14921951e-02,  1.28944423e-02,\n",
       "        -2.85542775e-02,  1.80345662e-02, -2.90812552e-03,\n",
       "         3.31925564e-02,  2.65427362e-02,  6.31957827e-03,\n",
       "        -3.95884924e-03,  3.57767753e-03,  2.07231939e-03,\n",
       "        -9.48436372e-03, -3.43948752e-02, -7.44062476e-03,\n",
       "         8.55595432e-03, -2.76151653e-02,  3.93728726e-02,\n",
       "        -1.33410674e-02, -6.29593059e-03,  6.21736050e-04,\n",
       "         2.57213712e-02, -7.76339881e-03,  1.10259177e-02,\n",
       "        -2.10211903e-04, -2.77462099e-02, -4.80099842e-02,\n",
       "         7.18325190e-03, -1.42296348e-02,  1.04098506e-02,\n",
       "         1.81291141e-02, -2.95179971e-02,  1.91359110e-02,\n",
       "        -7.64205605e-02, -2.92539150e-02,  1.31644197e-02,\n",
       "         1.24757104e-02,  1.15162414e-02,  2.92769074e-02,\n",
       "         1.98943913e-02,  5.27927689e-02,  6.64264569e-03,\n",
       "        -7.91781582e-03,  8.92706960e-03, -1.77201778e-02,\n",
       "        -3.20142098e-02,  5.22835255e-02],\n",
       "       [ 2.32708417e-02, -3.72418500e-02, -1.26975598e-02,\n",
       "         3.38123217e-02, -4.59962059e-03,  1.40995402e-02,\n",
       "         3.46907638e-02,  3.68313976e-02, -2.30883900e-02,\n",
       "         7.83486571e-03,  4.14691269e-02,  3.92376557e-02,\n",
       "         2.11000685e-02, -5.46215288e-03,  1.60553977e-02,\n",
       "        -2.30190298e-03,  3.10653262e-02,  5.08109992e-03,\n",
       "        -1.29995914e-02, -5.20804301e-02, -3.49896029e-04,\n",
       "        -9.95081849e-04,  2.44706199e-02,  5.81554975e-03,\n",
       "        -1.93842314e-03, -2.80791223e-02,  8.90204310e-03,\n",
       "         9.74498689e-03,  2.82724816e-02, -2.09486894e-02,\n",
       "        -2.85342652e-02, -3.42167355e-03, -3.42226774e-02,\n",
       "        -3.54342014e-02,  2.00642943e-02, -7.90394656e-03,\n",
       "         3.08775920e-02,  2.59653740e-02, -3.35245803e-02,\n",
       "         4.16941708e-03,  2.00864505e-02, -9.36594699e-03,\n",
       "         7.92547688e-03, -2.14624852e-02, -2.43399292e-02,\n",
       "         1.84827670e-03,  2.54938286e-02,  4.12493199e-03,\n",
       "         1.35600120e-02, -8.68297368e-03,  1.57704088e-03,\n",
       "        -7.13058235e-03, -2.85740532e-02, -3.73592228e-02,\n",
       "         3.10182124e-02,  1.82418730e-02,  2.01779064e-02,\n",
       "        -1.72860883e-02,  1.17446575e-03, -8.37846659e-03,\n",
       "        -1.04758264e-02,  8.31173547e-03, -6.35214057e-03,\n",
       "        -4.64332476e-02, -2.14403728e-03,  7.52512831e-03,\n",
       "        -2.77813822e-02,  9.66438092e-04, -2.03099623e-02,\n",
       "        -6.49102265e-03, -4.15000990e-02, -2.92880312e-02,\n",
       "        -2.82142777e-03,  1.62037350e-02, -9.02314298e-03,\n",
       "         2.07057931e-02, -1.17784832e-02, -3.80663686e-02,\n",
       "        -2.61109555e-03,  5.60905784e-03, -1.08179711e-02,\n",
       "         2.56586634e-03, -5.34676276e-02,  7.09124282e-03,\n",
       "        -2.32788548e-02,  1.42490603e-02, -5.28932922e-03,\n",
       "         2.54409015e-02,  2.17769984e-02,  4.63688513e-03,\n",
       "        -2.64129881e-03,  2.51620263e-03,  2.87299603e-03,\n",
       "        -8.31096712e-03, -2.96041071e-02, -6.15366735e-03,\n",
       "         4.50216793e-03, -2.39114519e-02,  3.03785242e-02,\n",
       "        -7.43638258e-03, -4.96791117e-03, -4.11215238e-04,\n",
       "         1.92177780e-02, -3.62802669e-03,  9.78796277e-03,\n",
       "         1.26679102e-03, -2.30372641e-02, -4.07091975e-02,\n",
       "         5.00515942e-03, -1.40240118e-02,  4.18004859e-03,\n",
       "         1.08398087e-02, -2.84451973e-02,  1.42864762e-02,\n",
       "        -5.92048876e-02, -2.36376040e-02,  1.47434771e-02,\n",
       "         9.37294029e-03,  8.72260984e-03,  2.49186810e-02,\n",
       "         1.45605933e-02,  3.84982675e-02,  3.69897485e-03,\n",
       "        -7.16760755e-03,  4.75822203e-03, -1.25826346e-02,\n",
       "        -2.51255482e-02,  4.09725979e-02]], dtype=float32)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "test = np.array(experiment.test[0])\n",
    "print(test.shape)\n",
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(5,), dtype=float32, numpy=\n",
       "array([-0.6404567 , -0.45835656, -0.47579864, -0.5814763 , -0.68898994],\n",
       "      dtype=float32)>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "tfm = tf.math\n",
    "test = tfm.l2_normalize(test, axis=-1)\n",
    "tfm.reduce_sum(test, axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[[[0.16078432 0.2784314  0.5058824 ]\n",
      "   [0.16190477 0.2784314  0.50756305]\n",
      "   [0.16526611 0.2784314  0.5126051 ]\n",
      "   ...\n",
      "   [0.22072832 0.34733894 0.5501401 ]\n",
      "   [0.22577035 0.34565824 0.55518216]\n",
      "   [0.22745098 0.34509805 0.5568628 ]]\n",
      "\n",
      "  [[0.16134454 0.27787116 0.5086835 ]\n",
      "   [0.16230492 0.27795118 0.5096439 ]\n",
      "   [0.16518608 0.2781913  0.512525  ]\n",
      "   ...\n",
      "   [0.2219288  0.34757903 0.5519808 ]\n",
      "   [0.22649063 0.34613845 0.5560625 ]\n",
      "   [0.2280112  0.34565827 0.557423  ]]\n",
      "\n",
      "  [[0.16302522 0.2761905  0.51708686]\n",
      "   [0.1635054  0.27651063 0.51588637]\n",
      "   [0.16494599 0.277471   0.51228493]\n",
      "   ...\n",
      "   [0.22553024 0.34829932 0.55750304]\n",
      "   [0.2286515  0.34757903 0.55870354]\n",
      "   [0.22969188 0.34733894 0.55910367]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[0.3154061  0.3507001  0.292997  ]\n",
      "   [0.29147652 0.31476575 0.26538596]\n",
      "   [0.21968776 0.20696265 0.18255284]\n",
      "   ...\n",
      "   [0.16182502 0.1238098  0.12372968]\n",
      "   [0.23457438 0.18599492 0.16454615]\n",
      "   [0.2588233  0.20672254 0.17815116]]\n",
      "\n",
      "  [[0.30532205 0.31708652 0.25266066]\n",
      "   [0.2770707  0.28163233 0.22601001]\n",
      "   [0.19231667 0.1752698  0.14605805]\n",
      "   ...\n",
      "   [0.14549829 0.11540632 0.11916777]\n",
      "   [0.1951982  0.16246523 0.14701891]\n",
      "   [0.21176423 0.17815098 0.1563023 ]]\n",
      "\n",
      "  [[0.3019608  0.30588236 0.23921569]\n",
      "   [0.27226892 0.27058825 0.21288516]\n",
      "   [0.1831933  0.16470589 0.13389356]\n",
      "   ...\n",
      "   [0.14005624 0.11260526 0.11764719]\n",
      "   [0.18207327 0.15462229 0.14117672]\n",
      "   [0.19607843 0.16862746 0.14901961]]]\n",
      "\n",
      "\n",
      " [[[0.         0.         0.        ]\n",
      "   [0.         0.         0.        ]\n",
      "   [0.         0.         0.        ]\n",
      "   ...\n",
      "   [0.         0.         0.        ]\n",
      "   [0.         0.         0.        ]\n",
      "   [0.         0.         0.        ]]\n",
      "\n",
      "  [[0.         0.         0.        ]\n",
      "   [0.         0.         0.        ]\n",
      "   [0.         0.         0.        ]\n",
      "   ...\n",
      "   [0.         0.         0.        ]\n",
      "   [0.         0.         0.        ]\n",
      "   [0.         0.         0.        ]]\n",
      "\n",
      "  [[0.         0.         0.        ]\n",
      "   [0.         0.         0.        ]\n",
      "   [0.         0.         0.        ]\n",
      "   ...\n",
      "   [0.         0.         0.        ]\n",
      "   [0.         0.         0.        ]\n",
      "   [0.         0.         0.        ]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[0.         0.         0.        ]\n",
      "   [0.         0.         0.        ]\n",
      "   [0.         0.         0.        ]\n",
      "   ...\n",
      "   [0.         0.         0.        ]\n",
      "   [0.         0.         0.        ]\n",
      "   [0.         0.         0.        ]]\n",
      "\n",
      "  [[0.         0.         0.        ]\n",
      "   [0.         0.         0.        ]\n",
      "   [0.         0.         0.        ]\n",
      "   ...\n",
      "   [0.         0.         0.        ]\n",
      "   [0.         0.         0.        ]\n",
      "   [0.         0.         0.        ]]\n",
      "\n",
      "  [[0.         0.         0.        ]\n",
      "   [0.         0.         0.        ]\n",
      "   [0.         0.         0.        ]\n",
      "   ...\n",
      "   [0.         0.         0.        ]\n",
      "   [0.         0.         0.        ]\n",
      "   [0.         0.         0.        ]]]\n",
      "\n",
      "\n",
      " [[[0.5254902  0.65882355 0.8392157 ]\n",
      "   [0.52605045 0.6593838  0.8392157 ]\n",
      "   [0.5277311  0.66106445 0.8392157 ]\n",
      "   ...\n",
      "   [0.16022411 0.22184873 0.36694685]\n",
      "   [0.16358547 0.22016805 0.3770309 ]\n",
      "   [0.16470589 0.21960784 0.38039216]]\n",
      "\n",
      "  [[0.5271709  0.6605042  0.84089637]\n",
      "   [0.5277311  0.6609844  0.8407363 ]\n",
      "   [0.5294118  0.662425   0.8402561 ]\n",
      "   ...\n",
      "   [0.16126452 0.22296917 0.3691077 ]\n",
      "   [0.16510609 0.2212885  0.3779913 ]\n",
      "   [0.16638656 0.2207283  0.3809524 ]]\n",
      "\n",
      "  [[0.5322129  0.66554624 0.8459384 ]\n",
      "   [0.53277314 0.6657863  0.8452981 ]\n",
      "   [0.5344538  0.66650665 0.84337735]\n",
      "   ...\n",
      "   [0.16438578 0.22633052 0.37559026]\n",
      "   [0.16966793 0.22464985 0.3808724 ]\n",
      "   [0.17142858 0.22408964 0.38263306]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[0.16134447 0.20392157 0.29075623]\n",
      "   [0.15878347 0.20240097 0.28675464]\n",
      "   [0.15110044 0.19783916 0.27474988]\n",
      "   ...\n",
      "   [1.         1.         0.99215686]\n",
      "   [1.         1.         0.99215686]\n",
      "   [1.         1.         0.99215686]]\n",
      "\n",
      "  [[0.14621834 0.20392157 0.27563012]\n",
      "   [0.14725879 0.20312126 0.2737894 ]\n",
      "   [0.15038015 0.20072033 0.26826724]\n",
      "   ...\n",
      "   [1.         1.         0.99215686]\n",
      "   [1.         1.         0.99215686]\n",
      "   [1.         1.         0.99215686]]\n",
      "\n",
      "  [[0.14117648 0.20392157 0.27058825]\n",
      "   [0.14341737 0.20336135 0.2694678 ]\n",
      "   [0.15014006 0.20168068 0.26610646]\n",
      "   ...\n",
      "   [1.         1.         0.99215686]\n",
      "   [1.         1.         0.99215686]\n",
      "   [1.         1.         0.99215686]]]\n",
      "\n",
      "\n",
      " ...\n",
      "\n",
      "\n",
      " [[[0.04705882 0.05882353 0.07450981]\n",
      "   [0.04313726 0.05378151 0.06722689]\n",
      "   [0.03137255 0.03865547 0.04537816]\n",
      "   ...\n",
      "   [0.01736696 0.0453782  0.00784314]\n",
      "   [0.01904764 0.05546229 0.00784314]\n",
      "   [0.01960784 0.05882353 0.00784314]]\n",
      "\n",
      "  [[0.06778711 0.08291316 0.10588236]\n",
      "   [0.06218488 0.07635054 0.09595839]\n",
      "   [0.04537815 0.05666267 0.06618648]\n",
      "   ...\n",
      "   [0.05418158 0.09763899 0.03657454]\n",
      "   [0.03497379 0.08491383 0.01880734]\n",
      "   [0.02857143 0.08067226 0.01288515]]\n",
      "\n",
      "  [[0.12997198 0.15518206 0.20000002]\n",
      "   [0.11932774 0.14405762 0.18215287]\n",
      "   [0.08739496 0.11068427 0.12861145]\n",
      "   ...\n",
      "   [0.16462544 0.25442135 0.12276874]\n",
      "   [0.08275227 0.17326847 0.05169995]\n",
      "   [0.05546219 0.14621848 0.0280112 ]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[0.05882335 0.05882335 0.07843114]\n",
      "   [0.05978373 0.05914348 0.07915142]\n",
      "   [0.06266487 0.06010386 0.08131227]\n",
      "   ...\n",
      "   [0.07066809 0.07034798 0.10051997]\n",
      "   [0.08027194 0.08355328 0.11756681]\n",
      "   [0.08347312 0.08795489 0.12324889]]\n",
      "\n",
      "  [[0.02352905 0.02352905 0.03137207]\n",
      "   [0.02376914 0.02360908 0.03113197]\n",
      "   [0.02448941 0.02384917 0.03041165]\n",
      "   ...\n",
      "   [0.02649016 0.02472945 0.03521346]\n",
      "   [0.02889106 0.02929121 0.04073557]\n",
      "   [0.02969133 0.03081174 0.04257621]]\n",
      "\n",
      "  [[0.01176471 0.01176471 0.01568628]\n",
      "   [0.01176471 0.01176471 0.01512605]\n",
      "   [0.01176471 0.01176471 0.01344538]\n",
      "   ...\n",
      "   [0.01176471 0.00952382 0.01344539]\n",
      "   [0.01176471 0.0112045  0.01512607]\n",
      "   [0.01176471 0.01176471 0.01568628]]]\n",
      "\n",
      "\n",
      " [[[0.34117648 0.3529412  0.3372549 ]\n",
      "   [0.34509805 0.35742298 0.34117648]\n",
      "   [0.35686275 0.37086836 0.3529412 ]\n",
      "   ...\n",
      "   [0.25490192 0.22801125 0.17535017]\n",
      "   [0.24313714 0.23641466 0.18207291]\n",
      "   [0.23921569 0.23921569 0.18431373]]\n",
      "\n",
      "  [[0.329972   0.34341738 0.32829133]\n",
      "   [0.3334934  0.347499   0.33181274]\n",
      "   [0.34405762 0.3597439  0.34237695]\n",
      "   ...\n",
      "   [0.2577831  0.23401365 0.17727095]\n",
      "   [0.24889947 0.24169676 0.18423377]\n",
      "   [0.24593838 0.2442577  0.18655463]]\n",
      "\n",
      "  [[0.29635856 0.31484595 0.30140057]\n",
      "   [0.29867947 0.3177271  0.3037215 ]\n",
      "   [0.30564228 0.32637057 0.3106843 ]\n",
      "   ...\n",
      "   [0.26642656 0.25202084 0.18303326]\n",
      "   [0.26618648 0.2575431  0.19071637]\n",
      "   [0.26610646 0.25938377 0.19327731]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[0.         0.         0.        ]\n",
      "   [0.         0.         0.        ]\n",
      "   [0.         0.         0.        ]\n",
      "   ...\n",
      "   [0.         0.         0.        ]\n",
      "   [0.         0.         0.        ]\n",
      "   [0.         0.         0.        ]]\n",
      "\n",
      "  [[0.         0.         0.        ]\n",
      "   [0.         0.         0.        ]\n",
      "   [0.         0.         0.        ]\n",
      "   ...\n",
      "   [0.         0.         0.        ]\n",
      "   [0.         0.         0.        ]\n",
      "   [0.         0.         0.        ]]\n",
      "\n",
      "  [[0.         0.         0.        ]\n",
      "   [0.         0.         0.        ]\n",
      "   [0.         0.         0.        ]\n",
      "   ...\n",
      "   [0.         0.         0.        ]\n",
      "   [0.         0.         0.        ]\n",
      "   [0.         0.         0.        ]]]\n",
      "\n",
      "\n",
      " [[[0.34901962 0.41960785 0.22745098]\n",
      "   [0.34229693 0.41288516 0.22352941]\n",
      "   [0.32212886 0.3927171  0.21176471]\n",
      "   ...\n",
      "   [0.29971996 0.33893564 0.22016811]\n",
      "   [0.31316543 0.3523811  0.22857152]\n",
      "   [0.31764707 0.35686275 0.23137255]]\n",
      "\n",
      "  [[0.33389357 0.40560225 0.21512605]\n",
      "   [0.32877153 0.4004802  0.21264505]\n",
      "   [0.31340536 0.38511404 0.20520209]\n",
      "   ...\n",
      "   [0.30444184 0.34645864 0.21760708]\n",
      "   [0.31644672 0.35846353 0.2245699 ]\n",
      "   [0.3204482  0.362465   0.22689076]]\n",
      "\n",
      "  [[0.28851542 0.36358544 0.17815126]\n",
      "   [0.28819528 0.3632653  0.179992  ]\n",
      "   [0.2872349  0.36230493 0.18551421]\n",
      "   ...\n",
      "   [0.3186075  0.36902767 0.20992398]\n",
      "   [0.3262906  0.37671077 0.21256506]\n",
      "   [0.32885155 0.37927172 0.21344538]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[0.48683485 0.38655475 0.2812326 ]\n",
      "   [0.49899969 0.39871958 0.2932374 ]\n",
      "   [0.53549427 0.43521413 0.3292517 ]\n",
      "   ...\n",
      "   [0.6199278  0.5146057  0.37831116]\n",
      "   [0.60288095 0.4975588  0.360544  ]\n",
      "   [0.59719884 0.49187672 0.3546218 ]]\n",
      "\n",
      "  [[0.507003   0.40840358 0.29972008]\n",
      "   [0.51508623 0.41648677 0.3069229 ]\n",
      "   [0.5393358  0.44073635 0.3285314 ]\n",
      "   ...\n",
      "   [0.6045616  0.49587813 0.36054397]\n",
      "   [0.5939974  0.4853139  0.3485392 ]\n",
      "   [0.59047616 0.48179263 0.34453773]]\n",
      "\n",
      "  [[0.5137255  0.41568628 0.30588236]\n",
      "   [0.5204482  0.42240897 0.3114846 ]\n",
      "   [0.5406163  0.44257703 0.32829133]\n",
      "   ...\n",
      "   [0.59943974 0.48963583 0.3546218 ]\n",
      "   [0.5910364  0.4812324  0.34453773]\n",
      "   [0.5882353  0.47843137 0.34117648]]]], shape=(128, 224, 224, 3), dtype=float32)\n",
      "tf.Tensor(\n",
      "[[[[0.9411765  0.95686275 0.98039216]\n",
      "   [0.93837535 0.95462185 0.97815126]\n",
      "   [0.929972   0.94789916 0.9714286 ]\n",
      "   ...\n",
      "   [0.5210085  0.5943979  0.33501413]\n",
      "   [0.53613466 0.61624676 0.36022437]\n",
      "   [0.5411765  0.62352943 0.36862746]]\n",
      "\n",
      "  [[0.9366947  0.9512605  0.9770308 ]\n",
      "   [0.9339736  0.94909966 0.9747899 ]\n",
      "   [0.92581034 0.94261706 0.9680672 ]\n",
      "   ...\n",
      "   [0.5252502  0.6048021  0.33973604]\n",
      "   [0.546859   0.63145286 0.3702284 ]\n",
      "   [0.55406165 0.64033616 0.38039216]]\n",
      "\n",
      "  [[0.9232493  0.9344538  0.9669468 ]\n",
      "   [0.9207683  0.932533   0.9647059 ]\n",
      "   [0.9133253  0.9267707  0.9579832 ]\n",
      "   ...\n",
      "   [0.53797543 0.63601464 0.3539018 ]\n",
      "   [0.57903206 0.6770713  0.40024057]\n",
      "   [0.5927171  0.6907563  0.41568628]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[0.752941   0.79999983 0.5809523 ]\n",
      "   [0.7435773  0.7923168  0.5711884 ]\n",
      "   [0.71548617 0.7692677  0.54189676]\n",
      "   ...\n",
      "   [0.65778303 0.6244897  0.57334924]\n",
      "   [0.6707482  0.6355341  0.5853541 ]\n",
      "   [0.6750698  0.63921547 0.5893555 ]]\n",
      "\n",
      "  [[0.7176467  0.76470554 0.55406135]\n",
      "   [0.71404535 0.76278484 0.54909945]\n",
      "   [0.70324117 0.7570227  0.53421366]\n",
      "   ...\n",
      "   [0.6236892  0.59183645 0.5399757 ]\n",
      "   [0.6244093  0.5920764  0.5454979 ]\n",
      "   [0.62464935 0.5921564  0.54733855]]\n",
      "\n",
      "  [[0.7058824  0.7529412  0.54509807]\n",
      "   [0.7042017  0.7529412  0.5417367 ]\n",
      "   [0.6991597  0.7529412  0.5316527 ]\n",
      "   ...\n",
      "   [0.61232495 0.5809524  0.52885157]\n",
      "   [0.60896355 0.577591   0.532213  ]\n",
      "   [0.60784316 0.5764706  0.53333336]]]\n",
      "\n",
      "\n",
      " [[[0.84313726 0.84705883 0.8901961 ]\n",
      "   [0.84257704 0.84761906 0.8885154 ]\n",
      "   [0.84089637 0.8492997  0.8834734 ]\n",
      "   ...\n",
      "   [0.         0.         0.        ]\n",
      "   [0.         0.         0.        ]\n",
      "   [0.         0.         0.        ]]\n",
      "\n",
      "  [[0.8436975  0.84985995 0.89131653]\n",
      "   [0.84361744 0.8503401  0.889956  ]\n",
      "   [0.84337735 0.8517807  0.88587433]\n",
      "   ...\n",
      "   [0.         0.         0.        ]\n",
      "   [0.         0.         0.        ]\n",
      "   [0.         0.         0.        ]]\n",
      "\n",
      "  [[0.84537816 0.8582633  0.8946779 ]\n",
      "   [0.8467387  0.8585034  0.8942777 ]\n",
      "   [0.85082036 0.8592237  0.89307725]\n",
      "   ...\n",
      "   [0.         0.         0.        ]\n",
      "   [0.         0.         0.        ]\n",
      "   [0.         0.         0.        ]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[0.4162464  0.4291316  0.34229684]\n",
      "   [0.41552615 0.42753097 0.34085625]\n",
      "   [0.4133653  0.42272905 0.33653453]\n",
      "   ...\n",
      "   [0.         0.         0.        ]\n",
      "   [0.         0.         0.        ]\n",
      "   [0.         0.         0.        ]]\n",
      "\n",
      "  [[0.4011203  0.41904753 0.32380936]\n",
      "   [0.4013604  0.41696668 0.32260886]\n",
      "   [0.4020807  0.41072416 0.31900743]\n",
      "   ...\n",
      "   [0.         0.         0.        ]\n",
      "   [0.         0.         0.        ]\n",
      "   [0.         0.         0.        ]]\n",
      "\n",
      "  [[0.39607844 0.41568628 0.31764707]\n",
      "   [0.39663866 0.41344538 0.31652662]\n",
      "   [0.39831933 0.4067227  0.31316528]\n",
      "   ...\n",
      "   [0.         0.         0.        ]\n",
      "   [0.         0.         0.        ]\n",
      "   [0.         0.         0.        ]]]\n",
      "\n",
      "\n",
      " [[[0.27450982 0.28627452 0.30980393]\n",
      "   [0.29411766 0.30588236 0.32885155]\n",
      "   [0.3529412  0.3647059  0.3859944 ]\n",
      "   ...\n",
      "   [0.31596658 0.3098041  0.3243699 ]\n",
      "   [0.34958017 0.3450984  0.35462216]\n",
      "   [0.36078432 0.35686275 0.3647059 ]]\n",
      "\n",
      "  [[0.27226892 0.28403363 0.30588236]\n",
      "   [0.2909964  0.30260104 0.32404962]\n",
      "   [0.34717888 0.35830334 0.37855142]\n",
      "   ...\n",
      "   [0.31372568 0.30796337 0.3215688 ]\n",
      "   [0.34565857 0.34085667 0.35014033]\n",
      "   [0.35630253 0.35182074 0.35966387]]\n",
      "\n",
      "  [[0.26554623 0.27731094 0.29411766]\n",
      "   [0.28163266 0.29275712 0.30964386]\n",
      "   [0.32989198 0.33909565 0.3562225 ]\n",
      "   ...\n",
      "   [0.30700296 0.30244112 0.3131654 ]\n",
      "   [0.33389384 0.32813153 0.33669493]\n",
      "   [0.34285715 0.3366947  0.34453782]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[0.5098041  0.41680688 0.3299722 ]\n",
      "   [0.50980407 0.4168869  0.33061245]\n",
      "   [0.50980407 0.41712692 0.33253318]\n",
      "   ...\n",
      "   [0.35230103 0.35398164 0.28419375]\n",
      "   [0.3292516  0.3208481  0.25970373]\n",
      "   [0.3215687  0.309804   0.25154066]]\n",
      "\n",
      "  [[0.5450984  0.44537845 0.37366992]\n",
      "   [0.541737   0.4416169  0.37046862]\n",
      "   [0.5316529  0.43033227 0.36086464]\n",
      "   ...\n",
      "   [0.39479813 0.39647874 0.32525027]\n",
      "   [0.3486992  0.34029576 0.2762702 ]\n",
      "   [0.33333346 0.32156876 0.25994408]]\n",
      "\n",
      "  [[0.5568628  0.45490196 0.3882353 ]\n",
      "   [0.552381   0.44985995 0.3837535 ]\n",
      "   [0.5389356  0.4347339  0.37030813]\n",
      "   ...\n",
      "   [0.40896332 0.41064394 0.3389353 ]\n",
      "   [0.35518155 0.34677806 0.28179216]\n",
      "   [0.3372549  0.3254902  0.2627451 ]]]\n",
      "\n",
      "\n",
      " ...\n",
      "\n",
      "\n",
      " [[[0.48235294 0.44705883 0.36862746]\n",
      "   [0.48907563 0.45658264 0.37927172]\n",
      "   [0.5092437  0.4851541  0.4112045 ]\n",
      "   ...\n",
      "   [0.5921569  0.46834734 0.25938374]\n",
      "   [0.5921569  0.47002804 0.2560224 ]\n",
      "   [0.5921569  0.47058824 0.25490198]]\n",
      "\n",
      "  [[0.48235294 0.44705883 0.36806723]\n",
      "   [0.48827532 0.4555422  0.37791118]\n",
      "   [0.5060424  0.48099244 0.407443  ]\n",
      "   ...\n",
      "   [0.5925571  0.46882755 0.2609844 ]\n",
      "   [0.5935174  0.47098842 0.25810322]\n",
      "   [0.59383756 0.4717087  0.25714287]]\n",
      "\n",
      "  [[0.48235294 0.44705883 0.36638656]\n",
      "   [0.48587435 0.45242098 0.37382954]\n",
      "   [0.4964386  0.4685074  0.39615846]\n",
      "   ...\n",
      "   [0.59375757 0.47026813 0.26578632]\n",
      "   [0.5975991  0.4738696  0.26434574]\n",
      "   [0.5988796  0.47507003 0.26386556]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[0.25266126 0.13557434 0.05490202]\n",
      "   [0.26194495 0.1419769  0.06034419]\n",
      "   [0.28979602 0.16118452 0.07667068]\n",
      "   ...\n",
      "   [0.44761902 0.27482986 0.13109232]\n",
      "   [0.4324929  0.2561023  0.10924348]\n",
      "   [0.42745104 0.24985999 0.10196079]]\n",
      "\n",
      "  [[0.28963625 0.1574232  0.06666679]\n",
      "   [0.29363778 0.16070448 0.06970798]\n",
      "   [0.30564243 0.17054832 0.07883155]\n",
      "   ...\n",
      "   [0.4593838  0.27963182 0.13109232]\n",
      "   [0.44425768 0.26234484 0.10924348]\n",
      "   [0.4392158  0.2565827  0.10196079]]\n",
      "\n",
      "  [[0.3019608  0.16470589 0.07058824]\n",
      "   [0.3042017  0.16694678 0.07282913]\n",
      "   [0.31092438 0.17366947 0.07955182]\n",
      "   ...\n",
      "   [0.46330523 0.28123242 0.13109232]\n",
      "   [0.44817913 0.2644256  0.10924348]\n",
      "   [0.44313726 0.25882354 0.10196079]]]\n",
      "\n",
      "\n",
      " [[[0.68235296 0.68235296 0.68235296]\n",
      "   [0.68235296 0.68235296 0.68235296]\n",
      "   [0.68235296 0.68235296 0.68235296]\n",
      "   ...\n",
      "   [0.6627451  0.6627451  0.6666667 ]\n",
      "   [0.6627451  0.6627451  0.6666667 ]\n",
      "   [0.6627451  0.6627451  0.6666667 ]]\n",
      "\n",
      "  [[0.6829132  0.6829132  0.6829132 ]\n",
      "   [0.68283314 0.68283314 0.68283314]\n",
      "   [0.68259305 0.68259305 0.68259305]\n",
      "   ...\n",
      "   [0.6627451  0.6627451  0.66658664]\n",
      "   [0.6627451  0.6627451  0.6670669 ]\n",
      "   [0.6627451  0.6627451  0.6672269 ]]\n",
      "\n",
      "  [[0.68459386 0.68459386 0.68459386]\n",
      "   [0.6842737  0.6842737  0.6842737 ]\n",
      "   [0.68331337 0.68331337 0.68331337]\n",
      "   ...\n",
      "   [0.6627451  0.6627451  0.66634655]\n",
      "   [0.6627451  0.6627451  0.66826737]\n",
      "   [0.6627451  0.6627451  0.6689076 ]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[0.7019608  0.7019608  0.7019608 ]\n",
      "   [0.7026011  0.7026011  0.7026011 ]\n",
      "   [0.70452183 0.70452183 0.70452183]\n",
      "   ...\n",
      "   [0.6929972  0.6917167  0.70212084]\n",
      "   [0.6929972  0.6926771  0.70116043]\n",
      "   [0.6929972  0.6929972  0.70084035]]\n",
      "\n",
      "  [[0.7019608  0.7019608  0.7019608 ]\n",
      "   [0.70212084 0.70212084 0.70212084]\n",
      "   [0.702601   0.702601   0.702601  ]\n",
      "   ...\n",
      "   [0.68795514 0.687635   0.6961184 ]\n",
      "   [0.68795514 0.6878751  0.6958783 ]\n",
      "   [0.68795514 0.68795514 0.6957983 ]]\n",
      "\n",
      "  [[0.7019608  0.7019608  0.7019608 ]\n",
      "   [0.7019608  0.7019608  0.7019608 ]\n",
      "   [0.7019608  0.7019608  0.7019608 ]\n",
      "   ...\n",
      "   [0.6862745  0.6862745  0.69411767]\n",
      "   [0.6862745  0.6862745  0.69411767]\n",
      "   [0.6862745  0.6862745  0.69411767]]]\n",
      "\n",
      "\n",
      " [[[0.49411765 0.3137255  0.22745098]\n",
      "   [0.4952381  0.30812326 0.22857143]\n",
      "   [0.49859947 0.29131654 0.23193277]\n",
      "   ...\n",
      "   [0.97310925 0.83641446 0.52324927]\n",
      "   [0.96974784 0.817927   0.5131652 ]\n",
      "   [0.96862745 0.8117647  0.50980395]]\n",
      "\n",
      "  [[0.4694678  0.3137255  0.21904762]\n",
      "   [0.470028   0.30868348 0.22016807]\n",
      "   [0.47170871 0.29355744 0.22352941]\n",
      "   ...\n",
      "   [0.97511005 0.8384953  0.5248499 ]\n",
      "   [0.97150856 0.81928754 0.5135653 ]\n",
      "   [0.9703081  0.81288517 0.50980395]]\n",
      "\n",
      "  [[0.3955182  0.3137255  0.19383754]\n",
      "   [0.39439777 0.31036416 0.19495799]\n",
      "   [0.39103645 0.30028012 0.19831933]\n",
      "   ...\n",
      "   [0.9811124  0.84473777 0.5296518 ]\n",
      "   [0.97679067 0.82336915 0.5147658 ]\n",
      "   [0.97535014 0.8162465  0.50980395]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[0.37422982 0.36190486 0.33445388]\n",
      "   [0.37543032 0.36094448 0.33485404]\n",
      "   [0.37903175 0.35806334 0.33605453]\n",
      "   ...\n",
      "   [0.5718287  0.54085636 0.47787115]\n",
      "   [0.57278913 0.54109645 0.4728291 ]\n",
      "   [0.57310927 0.5411765  0.4711485 ]]\n",
      "\n",
      "  [[0.39944005 0.37871167 0.3512607 ]\n",
      "   [0.4001603  0.37847158 0.35262123]\n",
      "   [0.40232116 0.37775132 0.3567029 ]\n",
      "   ...\n",
      "   [0.5694278  0.5427772  0.48627457]\n",
      "   [0.5696679  0.5415767  0.48123252]\n",
      "   [0.56974787 0.5411765  0.4795519 ]]\n",
      "\n",
      "  [[0.40784314 0.38431373 0.35686275]\n",
      "   [0.40840337 0.38431373 0.35854343]\n",
      "   [0.41008404 0.38431373 0.36358544]\n",
      "   ...\n",
      "   [0.5686275  0.5434174  0.4890756 ]\n",
      "   [0.5686275  0.5417367  0.48403355]\n",
      "   [0.5686275  0.5411765  0.48235294]]]], shape=(128, 224, 224, 3), dtype=float32)\n",
      "tf.Tensor(\n",
      "[[[[0.7647059  0.7294118  0.67058825]\n",
      "   [0.7697479  0.73333335 0.67282915]\n",
      "   [0.78487396 0.74509805 0.67955184]\n",
      "   ...\n",
      "   [0.41736695 0.38375354 0.35630256]\n",
      "   [0.41904765 0.38711488 0.3596639 ]\n",
      "   [0.41960785 0.3882353  0.36078432]]\n",
      "\n",
      "  [[0.76638657 0.7305322  0.67058825]\n",
      "   [0.77110845 0.7342137  0.67282915]\n",
      "   [0.78527415 0.7452581  0.67955184]\n",
      "   ...\n",
      "   [0.41904762 0.38599443 0.357423  ]\n",
      "   [0.42072833 0.38935578 0.36078435]\n",
      "   [0.42128852 0.3904762  0.36190477]]\n",
      "\n",
      "  [[0.7714286  0.7338936  0.67058825]\n",
      "   [0.7751901  0.73685473 0.67282915]\n",
      "   [0.7864746  0.7457383  0.67955184]\n",
      "   ...\n",
      "   [0.42408964 0.39271712 0.36078435]\n",
      "   [0.42577034 0.39607847 0.3641457 ]\n",
      "   [0.42633054 0.3971989  0.3652661 ]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[0.6134454  0.5742297  0.5058824 ]\n",
      "   [0.6184874  0.5785515  0.5101241 ]\n",
      "   [0.63361347 0.5915166  0.52284914]\n",
      "   ...\n",
      "   [0.7555023  0.717247   0.62040824]\n",
      "   [0.7502202  0.7112446  0.617287  ]\n",
      "   [0.7484595  0.70924383 0.61624664]]\n",
      "\n",
      "  [[0.6151261  0.5759104  0.5058824 ]\n",
      "   [0.6184874  0.57783115 0.50820327]\n",
      "   [0.6285714  0.58359337 0.51516604]\n",
      "   ...\n",
      "   [0.7737497  0.7364548  0.6357745 ]\n",
      "   [0.77495027 0.73621476 0.6362547 ]\n",
      "   [0.77535045 0.73613477 0.63641477]]\n",
      "\n",
      "  [[0.6156863  0.5764706  0.5058824 ]\n",
      "   [0.6184874  0.57759106 0.50756305]\n",
      "   [0.6268908  0.5809524  0.5126051 ]\n",
      "   ...\n",
      "   [0.77983195 0.74285716 0.6408964 ]\n",
      "   [0.78319335 0.74453783 0.64257705]\n",
      "   [0.78431374 0.74509805 0.6431373 ]]]\n",
      "\n",
      "\n",
      " [[[0.         0.         0.        ]\n",
      "   [0.         0.         0.        ]\n",
      "   [0.         0.         0.        ]\n",
      "   ...\n",
      "   [0.         0.         0.        ]\n",
      "   [0.         0.         0.        ]\n",
      "   [0.         0.         0.        ]]\n",
      "\n",
      "  [[0.         0.         0.        ]\n",
      "   [0.         0.         0.        ]\n",
      "   [0.         0.         0.        ]\n",
      "   ...\n",
      "   [0.         0.         0.        ]\n",
      "   [0.         0.         0.        ]\n",
      "   [0.         0.         0.        ]]\n",
      "\n",
      "  [[0.         0.         0.        ]\n",
      "   [0.         0.         0.        ]\n",
      "   [0.         0.         0.        ]\n",
      "   ...\n",
      "   [0.         0.         0.        ]\n",
      "   [0.         0.         0.        ]\n",
      "   [0.         0.         0.        ]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[0.14341736 0.34733894 0.5372549 ]\n",
      "   [0.14341736 0.34789917 0.537335  ]\n",
      "   [0.14341736 0.34957984 0.53757507]\n",
      "   ...\n",
      "   [0.1267707  0.30588236 0.49243698]\n",
      "   [0.12581033 0.30588236 0.49075627]\n",
      "   [0.1254902  0.30588236 0.49019608]]\n",
      "\n",
      "  [[0.14173669 0.34565824 0.5372549 ]\n",
      "   [0.14173669 0.34621847 0.53685474]\n",
      "   [0.14173669 0.34789914 0.53565425]\n",
      "   ...\n",
      "   [0.12581033 0.30588236 0.49243698]\n",
      "   [0.12557024 0.30588236 0.49075627]\n",
      "   [0.1254902  0.30588236 0.49019608]]\n",
      "\n",
      "  [[0.14117648 0.34509805 0.5372549 ]\n",
      "   [0.14117648 0.34565827 0.5366947 ]\n",
      "   [0.14117648 0.34733894 0.53501403]\n",
      "   ...\n",
      "   [0.1254902  0.30588236 0.49243698]\n",
      "   [0.1254902  0.30588236 0.49075627]\n",
      "   [0.1254902  0.30588236 0.49019608]]]\n",
      "\n",
      "\n",
      " [[[0.6901961  0.70980394 0.7019608 ]\n",
      "   [0.6806723  0.702521   0.68907565]\n",
      "   [0.65210086 0.6806723  0.6504202 ]\n",
      "   ...\n",
      "   [0.5254902  0.52436984 0.51204485]\n",
      "   [0.5254902  0.5310925  0.5103642 ]\n",
      "   [0.5254902  0.53333336 0.50980395]]\n",
      "\n",
      "  [[0.692437   0.7137255  0.7047619 ]\n",
      "   [0.68435377 0.707483   0.6934774 ]\n",
      "   [0.66010404 0.6887555  0.65962386]\n",
      "   ...\n",
      "   [0.50860345 0.5094038  0.49307725]\n",
      "   [0.50740296 0.51348543 0.49259707]\n",
      "   [0.50700283 0.51484597 0.492437  ]]\n",
      "\n",
      "  [[0.6991597  0.7254902  0.7131653 ]\n",
      "   [0.69539815 0.72236896 0.7066827 ]\n",
      "   [0.6841137  0.71300524 0.68723494]\n",
      "   ...\n",
      "   [0.45794317 0.46450582 0.4361745 ]\n",
      "   [0.4531412  0.46066424 0.43929577]\n",
      "   [0.45154065 0.4593838  0.44033617]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[0.         0.         0.        ]\n",
      "   [0.         0.         0.        ]\n",
      "   [0.         0.         0.        ]\n",
      "   ...\n",
      "   [0.         0.         0.        ]\n",
      "   [0.         0.         0.        ]\n",
      "   [0.         0.         0.        ]]\n",
      "\n",
      "  [[0.         0.         0.        ]\n",
      "   [0.         0.         0.        ]\n",
      "   [0.         0.         0.        ]\n",
      "   ...\n",
      "   [0.         0.         0.        ]\n",
      "   [0.         0.         0.        ]\n",
      "   [0.         0.         0.        ]]\n",
      "\n",
      "  [[0.         0.         0.        ]\n",
      "   [0.         0.         0.        ]\n",
      "   [0.         0.         0.        ]\n",
      "   ...\n",
      "   [0.         0.         0.        ]\n",
      "   [0.         0.         0.        ]\n",
      "   [0.         0.         0.        ]]]\n",
      "\n",
      "\n",
      " ...\n",
      "\n",
      "\n",
      " [[[0.34117648 0.3372549  0.30980393]\n",
      "   [0.30868348 0.30476192 0.28011206]\n",
      "   [0.21120448 0.20728292 0.19103643]\n",
      "   ...\n",
      "   [0.25266084 0.2616244  0.2521006 ]\n",
      "   [0.20728245 0.20952329 0.19831878]\n",
      "   [0.19215687 0.19215687 0.18039216]]\n",
      "\n",
      "  [[0.3579832  0.35406163 0.32605043]\n",
      "   [0.32685074 0.32284915 0.29739898]\n",
      "   [0.23345338 0.22921169 0.21144459]\n",
      "   ...\n",
      "   [0.25682256 0.26314506 0.25362125]\n",
      "   [0.22176835 0.22208843 0.2125646 ]\n",
      "   [0.21008404 0.20840336 0.19887955]]\n",
      "\n",
      "  [[0.40840337 0.4044818  0.37478992]\n",
      "   [0.38135254 0.37711084 0.3492597 ]\n",
      "   [0.30020007 0.294998   0.27266908]\n",
      "   ...\n",
      "   [0.26930773 0.26770705 0.25818327]\n",
      "   [0.26522607 0.25978386 0.2553021 ]\n",
      "   [0.26386556 0.25714287 0.25434175]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[0.35294113 0.35574222 0.37254903]\n",
      "   [0.3609443  0.3616646  0.37743098]\n",
      "   [0.3849539  0.37943166 0.39207682]\n",
      "   ...\n",
      "   [0.31188375 0.31700572 0.31732586]\n",
      "   [0.19687724 0.20319976 0.20832181]\n",
      "   [0.15854314 0.1652658  0.1719884 ]]\n",
      "\n",
      "  [[0.34117636 0.3389354  0.37254903]\n",
      "   [0.34653848 0.342937   0.37671068]\n",
      "   [0.36262482 0.35494173 0.38919565]\n",
      "   ...\n",
      "   [0.22208747 0.2183259  0.21336383]\n",
      "   [0.13157104 0.13189116 0.12308745]\n",
      "   [0.10139999 0.10308061 0.09299639]]\n",
      "\n",
      "  [[0.3372549  0.33333334 0.37254903]\n",
      "   [0.3417367  0.3366947  0.3764706 ]\n",
      "   [0.35518208 0.34677872 0.3882353 ]\n",
      "   ...\n",
      "   [0.19215645 0.18543379 0.17871106]\n",
      "   [0.10980308 0.10812247 0.09467702]\n",
      "   [0.08235294 0.08235294 0.06666667]]]\n",
      "\n",
      "\n",
      " [[[0.         0.         0.        ]\n",
      "   [0.         0.         0.        ]\n",
      "   [0.         0.         0.        ]\n",
      "   ...\n",
      "   [0.         0.         0.        ]\n",
      "   [0.         0.         0.        ]\n",
      "   [0.         0.         0.        ]]\n",
      "\n",
      "  [[0.         0.         0.        ]\n",
      "   [0.         0.         0.        ]\n",
      "   [0.         0.         0.        ]\n",
      "   ...\n",
      "   [0.         0.         0.        ]\n",
      "   [0.         0.         0.        ]\n",
      "   [0.         0.         0.        ]]\n",
      "\n",
      "  [[0.         0.         0.        ]\n",
      "   [0.         0.         0.        ]\n",
      "   [0.         0.         0.        ]\n",
      "   ...\n",
      "   [0.         0.         0.        ]\n",
      "   [0.         0.         0.        ]\n",
      "   [0.         0.         0.        ]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[0.         0.         0.        ]\n",
      "   [0.         0.         0.        ]\n",
      "   [0.         0.         0.        ]\n",
      "   ...\n",
      "   [0.         0.         0.        ]\n",
      "   [0.         0.         0.        ]\n",
      "   [0.         0.         0.        ]]\n",
      "\n",
      "  [[0.         0.         0.        ]\n",
      "   [0.         0.         0.        ]\n",
      "   [0.         0.         0.        ]\n",
      "   ...\n",
      "   [0.         0.         0.        ]\n",
      "   [0.         0.         0.        ]\n",
      "   [0.         0.         0.        ]]\n",
      "\n",
      "  [[0.         0.         0.        ]\n",
      "   [0.         0.         0.        ]\n",
      "   [0.         0.         0.        ]\n",
      "   ...\n",
      "   [0.         0.         0.        ]\n",
      "   [0.         0.         0.        ]\n",
      "   [0.         0.         0.        ]]]\n",
      "\n",
      "\n",
      " [[[0.10588235 0.5372549  0.6745098 ]\n",
      "   [0.1070028  0.5383754  0.6756303 ]\n",
      "   [0.11036415 0.5417367  0.6789916 ]\n",
      "   ...\n",
      "   [0.11820733 0.4605042  0.51708686]\n",
      "   [0.12661074 0.4621849  0.52044827]\n",
      "   [0.12941177 0.4627451  0.52156866]]\n",
      "\n",
      "  [[0.10420168 0.53501403 0.6711485 ]\n",
      "   [0.10516207 0.53597444 0.6721089 ]\n",
      "   [0.10804322 0.53885555 0.67499   ]\n",
      "   ...\n",
      "   [0.11660668 0.45346138 0.50700283]\n",
      "   [0.12284921 0.4537015  0.50868356]\n",
      "   [0.12492998 0.45378152 0.5092437 ]]\n",
      "\n",
      "  [[0.09915967 0.52829134 0.66106445]\n",
      "   [0.09963986 0.5287715  0.6615446 ]\n",
      "   [0.10108043 0.5302121  0.6629852 ]\n",
      "   ...\n",
      "   [0.11180472 0.43233293 0.4767507 ]\n",
      "   [0.11156463 0.42825127 0.47338936]\n",
      "   [0.1114846  0.42689076 0.47226894]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[0.10420161 0.46386552 0.58431363]\n",
      "   [0.10380146 0.46218485 0.58207273]\n",
      "   [0.10260099 0.45714283 0.57535005]\n",
      "   ...\n",
      "   [0.10364147 0.49579832 0.62128854]\n",
      "   [0.10364147 0.49579832 0.62128854]\n",
      "   [0.10364147 0.49579832 0.62128854]]\n",
      "\n",
      "  [[0.09075617 0.4571428  0.5607841 ]\n",
      "   [0.0910763  0.45546213 0.5585432 ]\n",
      "   [0.09203671 0.4504201  0.5518205 ]\n",
      "   ...\n",
      "   [0.10532214 0.49747902 0.6229692 ]\n",
      "   [0.10532214 0.49747902 0.6229692 ]\n",
      "   [0.10532214 0.49747902 0.6229692 ]]\n",
      "\n",
      "  [[0.08627451 0.45490196 0.5529412 ]\n",
      "   [0.08683474 0.4532213  0.5507003 ]\n",
      "   [0.08851541 0.44817927 0.5439776 ]\n",
      "   ...\n",
      "   [0.10588235 0.49803922 0.62352943]\n",
      "   [0.10588235 0.49803922 0.62352943]\n",
      "   [0.10588235 0.49803922 0.62352943]]]], shape=(128, 224, 224, 3), dtype=float32)\n",
      "tf.Tensor(\n",
      "[[[[0.9647059  0.96862745 0.9843137 ]\n",
      "   [0.9652661  0.96862745 0.98487395]\n",
      "   [0.9669468  0.96862745 0.9865546 ]\n",
      "   ...\n",
      "   [0.99383754 0.99383754 0.99383754]\n",
      "   [0.9955182  0.9955182  0.9955182 ]\n",
      "   [0.99607843 0.99607843 0.99607843]]\n",
      "\n",
      "  [[0.96582633 0.9697479  0.98487395]\n",
      "   [0.96638656 0.9697479  0.9853541 ]\n",
      "   [0.9680672  0.9697479  0.9867947 ]\n",
      "   ...\n",
      "   [0.9932773  0.9932773  0.9932773 ]\n",
      "   [0.994958   0.994958   0.994958  ]\n",
      "   [0.9955182  0.9955182  0.9955182 ]]\n",
      "\n",
      "  [[0.9691877  0.97310925 0.9865546 ]\n",
      "   [0.9697479  0.97310925 0.9867947 ]\n",
      "   [0.9714286  0.97310925 0.98751503]\n",
      "   ...\n",
      "   [0.99159664 0.99159664 0.99159664]\n",
      "   [0.9932773  0.9932773  0.9932773 ]\n",
      "   [0.99383754 0.99383754 0.99383754]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[0.8918767  0.8705882  0.8823529 ]\n",
      "   [0.8891556  0.8685073  0.8797118 ]\n",
      "   [0.88099235 0.8622649  0.8717887 ]\n",
      "   ...\n",
      "   [0.8460985  0.8189676  0.8280113 ]\n",
      "   [0.8484994  0.8211285  0.83137256]\n",
      "   [0.8492997  0.82184875 0.83249295]]\n",
      "\n",
      "  [[0.8817926  0.8588234  0.8705881 ]\n",
      "   [0.88027203 0.8574629  0.86866736]\n",
      "   [0.87571025 0.8533813  0.8629051 ]\n",
      "   ...\n",
      "   [0.85018015 0.8211285  0.8280112 ]\n",
      "   [0.84825927 0.82040817 0.8263304 ]\n",
      "   [0.84761906 0.8201681  0.82577026]]\n",
      "\n",
      "  [[0.8784314  0.85490197 0.8666667 ]\n",
      "   [0.87731093 0.8537815  0.864986  ]\n",
      "   [0.8739496  0.8504202  0.859944  ]\n",
      "   ...\n",
      "   [0.8515406  0.82184875 0.8280112 ]\n",
      "   [0.8481792  0.8201681  0.8246498 ]\n",
      "   [0.84705883 0.81960785 0.8235294 ]]]\n",
      "\n",
      "\n",
      " [[[0.9411765  0.98039216 0.9843137 ]\n",
      "   [0.92661065 0.9607843  0.967507  ]\n",
      "   [0.8829132  0.9019608  0.91708684]\n",
      "   ...\n",
      "   [0.7445378  0.7910364  0.7221289 ]\n",
      "   [0.7361344  0.78599435 0.7305323 ]\n",
      "   [0.73333335 0.78431374 0.73333335]]\n",
      "\n",
      "  [[0.9462185  0.98263305 0.9859944 ]\n",
      "   [0.9331733  0.96534616 0.9713485 ]\n",
      "   [0.8940376  0.9134854  0.92741096]\n",
      "   ...\n",
      "   [0.740216   0.7880752  0.7156463 ]\n",
      "   [0.7308523  0.78231287 0.7226091 ]\n",
      "   [0.7277311  0.78039217 0.72493   ]]\n",
      "\n",
      "  [[0.96134454 0.98935574 0.9910364 ]\n",
      "   [0.95286113 0.9790316  0.98287314]\n",
      "   [0.92741096 0.9480592  0.9583833 ]\n",
      "   ...\n",
      "   [0.7272509  0.7791917  0.6961985 ]\n",
      "   [0.7150059  0.7712684  0.6988396 ]\n",
      "   [0.7109244  0.76862746 0.6997199 ]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[0.         0.         0.        ]\n",
      "   [0.         0.         0.        ]\n",
      "   [0.         0.         0.        ]\n",
      "   ...\n",
      "   [0.         0.         0.        ]\n",
      "   [0.         0.         0.        ]\n",
      "   [0.         0.         0.        ]]\n",
      "\n",
      "  [[0.         0.         0.        ]\n",
      "   [0.         0.         0.        ]\n",
      "   [0.         0.         0.        ]\n",
      "   ...\n",
      "   [0.         0.         0.        ]\n",
      "   [0.         0.         0.        ]\n",
      "   [0.         0.         0.        ]]\n",
      "\n",
      "  [[0.         0.         0.        ]\n",
      "   [0.         0.         0.        ]\n",
      "   [0.         0.         0.        ]\n",
      "   ...\n",
      "   [0.         0.         0.        ]\n",
      "   [0.         0.         0.        ]\n",
      "   [0.         0.         0.        ]]]\n",
      "\n",
      "\n",
      " [[[0.45882353 0.53333336 0.627451  ]\n",
      "   [0.45882353 0.5338936  0.62857145]\n",
      "   [0.45882353 0.53557426 0.6319328 ]\n",
      "   ...\n",
      "   [0.46666667 0.54733896 0.6392157 ]\n",
      "   [0.46666667 0.5456583  0.6392157 ]\n",
      "   [0.46666667 0.54509807 0.6392157 ]]\n",
      "\n",
      "  [[0.4582633  0.5338936  0.6280112 ]\n",
      "   [0.4582633  0.5344538  0.6290516 ]\n",
      "   [0.4582633  0.5361345  0.6321729 ]\n",
      "   ...\n",
      "   [0.46554622 0.54733896 0.63953584]\n",
      "   [0.46554622 0.5456583  0.63929576]\n",
      "   [0.46554622 0.54509807 0.6392157 ]]\n",
      "\n",
      "  [[0.45658264 0.53557426 0.6296919 ]\n",
      "   [0.45658264 0.5361345  0.6304922 ]\n",
      "   [0.45658264 0.53781515 0.6328932 ]\n",
      "   ...\n",
      "   [0.46218488 0.54733896 0.6404962 ]\n",
      "   [0.46218488 0.5456583  0.63953584]\n",
      "   [0.46218488 0.54509807 0.6392157 ]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[0.3764703  0.35462156 0.2184872 ]\n",
      "   [0.37903133 0.35710257 0.22168848]\n",
      "   [0.3867144  0.36454552 0.23129234]\n",
      "   ...\n",
      "   [0.58375317 0.6005599  0.59759873]\n",
      "   [0.6156862  0.6291315  0.6271307 ]\n",
      "   [0.62633014 0.638655   0.63697433]]\n",
      "\n",
      "  [[0.31764647 0.29747844 0.17815086]\n",
      "   [0.3199674  0.3001995  0.18231253]\n",
      "   [0.32693017 0.30836278 0.19479755]\n",
      "   ...\n",
      "   [0.4896351  0.5030804  0.49939895]\n",
      "   [0.52661014 0.5366941  0.5332527 ]\n",
      "   [0.5389347  0.5478983  0.5445369 ]]\n",
      "\n",
      "  [[0.29803923 0.2784314  0.16470589]\n",
      "   [0.30028012 0.2812325  0.16918768]\n",
      "   [0.3070028  0.28963587 0.18263306]\n",
      "   ...\n",
      "   [0.45826352 0.47058845 0.46666688]\n",
      "   [0.49691918 0.50588274 0.5019612 ]\n",
      "   [0.50980395 0.5176471  0.5137255 ]]]\n",
      "\n",
      "\n",
      " ...\n",
      "\n",
      "\n",
      " [[[1.         1.         1.        ]\n",
      "   [1.         1.         1.        ]\n",
      "   [1.         1.         1.        ]\n",
      "   ...\n",
      "   [0.         0.         0.        ]\n",
      "   [0.         0.         0.        ]\n",
      "   [0.         0.         0.        ]]\n",
      "\n",
      "  [[1.         1.         1.        ]\n",
      "   [1.         1.         1.        ]\n",
      "   [1.         1.         1.        ]\n",
      "   ...\n",
      "   [0.         0.         0.        ]\n",
      "   [0.         0.         0.        ]\n",
      "   [0.         0.         0.        ]]\n",
      "\n",
      "  [[1.         1.         1.        ]\n",
      "   [1.         1.         1.        ]\n",
      "   [1.         1.         1.        ]\n",
      "   ...\n",
      "   [0.         0.         0.        ]\n",
      "   [0.         0.         0.        ]\n",
      "   [0.         0.         0.        ]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[1.         1.         1.        ]\n",
      "   [1.         1.         1.        ]\n",
      "   [1.         1.         1.        ]\n",
      "   ...\n",
      "   [0.         0.         0.        ]\n",
      "   [0.         0.         0.        ]\n",
      "   [0.         0.         0.        ]]\n",
      "\n",
      "  [[1.         1.         1.        ]\n",
      "   [1.         1.         1.        ]\n",
      "   [1.         1.         1.        ]\n",
      "   ...\n",
      "   [0.         0.         0.        ]\n",
      "   [0.         0.         0.        ]\n",
      "   [0.         0.         0.        ]]\n",
      "\n",
      "  [[1.         1.         1.        ]\n",
      "   [1.         1.         1.        ]\n",
      "   [1.         1.         1.        ]\n",
      "   ...\n",
      "   [0.         0.         0.        ]\n",
      "   [0.         0.         0.        ]\n",
      "   [0.         0.         0.        ]]]\n",
      "\n",
      "\n",
      " [[[0.74509805 0.6156863  0.32941177]\n",
      "   [0.7389356  0.60952383 0.3277311 ]\n",
      "   [0.7204482  0.59103644 0.3226891 ]\n",
      "   ...\n",
      "   [0.8229692  0.74229693 0.41008404]\n",
      "   [0.8263306  0.747339   0.40840334]\n",
      "   [0.827451   0.7490196  0.40784314]]\n",
      "\n",
      "  [[0.7490196  0.61904764 0.33277312]\n",
      "   [0.742537   0.6128852  0.3306923 ]\n",
      "   [0.7230893  0.5943978  0.32444978]\n",
      "   ...\n",
      "   [0.82104844 0.739976   0.40816328]\n",
      "   [0.82416975 0.7454983  0.40624246]\n",
      "   [0.8252101  0.74733895 0.40560225]]\n",
      "\n",
      "  [[0.7607843  0.6291317  0.34285715]\n",
      "   [0.7533414  0.6229692  0.33957583]\n",
      "   [0.7310124  0.6044818  0.3297319 ]\n",
      "   ...\n",
      "   [0.8152861  0.7330133  0.40240094]\n",
      "   [0.8176871  0.73997605 0.3997599 ]\n",
      "   [0.8184874  0.74229693 0.39887956]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[0.5747898  0.54173666 0.2605041 ]\n",
      "   [0.58079225 0.54565823 0.26258495]\n",
      "   [0.5987995  0.557423   0.26882753]\n",
      "   ...\n",
      "   [0.6850741  0.6145659  0.3727891 ]\n",
      "   [0.6620246  0.592717   0.36126444]\n",
      "   [0.65434176 0.58543426 0.357423  ]]\n",
      "\n",
      "  [[0.5495796  0.5266105  0.23865524]\n",
      "   [0.5599038  0.53389347 0.24505785]\n",
      "   [0.5908763  0.5557423  0.2642657 ]\n",
      "   ...\n",
      "   [0.7124451  0.6515408  0.3831133 ]\n",
      "   [0.67138827 0.61456573 0.370148  ]\n",
      "   [0.65770316 0.6022411  0.36582643]]\n",
      "\n",
      "  [[0.5411765  0.52156866 0.23137255]\n",
      "   [0.5529412  0.529972   0.23921569]\n",
      "   [0.5882353  0.5551821  0.2627451 ]\n",
      "   ...\n",
      "   [0.7215684  0.6638653  0.38655457]\n",
      "   [0.67450935 0.62184834 0.3731091 ]\n",
      "   [0.65882355 0.60784316 0.36862746]]]\n",
      "\n",
      "\n",
      " [[[0.5411765  0.6627451  0.63529414]\n",
      "   [0.5411765  0.664986   0.63529414]\n",
      "   [0.5411765  0.6717087  0.63529414]\n",
      "   ...\n",
      "   [0.5591037  0.66834736 0.63305324]\n",
      "   [0.5691878  0.67002803 0.6347339 ]\n",
      "   [0.57254905 0.67058825 0.63529414]]\n",
      "\n",
      "  [[0.5383754  0.66106445 0.63081235]\n",
      "   [0.5384554  0.6633854  0.6308924 ]\n",
      "   [0.5386955  0.67034817 0.6311325 ]\n",
      "   ...\n",
      "   [0.5603042  0.6686675  0.63361347]\n",
      "   [0.5699081  0.6701081  0.63529414]\n",
      "   [0.57310927 0.67058825 0.63585436]]\n",
      "\n",
      "  [[0.529972   0.6560224  0.61736697]\n",
      "   [0.53029215 0.65858346 0.6176871 ]\n",
      "   [0.5312525  0.6662665  0.61864746]\n",
      "   ...\n",
      "   [0.56390566 0.66962785 0.63529414]\n",
      "   [0.5720689  0.67034817 0.6369748 ]\n",
      "   [0.57478994 0.67058825 0.63753504]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[0.45882365 0.65266114 0.48123267]\n",
      "   [0.462185   0.6517008  0.48195297]\n",
      "   [0.4722691  0.6488197  0.4841138 ]\n",
      "   ...\n",
      "   [0.40007997 0.62136847 0.35518202]\n",
      "   [0.38783494 0.6124849  0.33501375]\n",
      "   [0.38375342 0.6095237  0.32829124]]\n",
      "\n",
      "  [[0.48235318 0.6661066  0.5114849 ]\n",
      "   [0.48739523 0.6692279  0.5129255 ]\n",
      "   [0.50252134 0.6785917  0.51724726]\n",
      "   ...\n",
      "   [0.39623833 0.6158462  0.36526603]\n",
      "   [0.3717483  0.59471756 0.32492948]\n",
      "   [0.36358523 0.58767486 0.31148443]]\n",
      "\n",
      "  [[0.49019608 0.67058825 0.52156866]\n",
      "   [0.49579832 0.67507005 0.5232493 ]\n",
      "   [0.5126051  0.6885154  0.52829134]\n",
      "   ...\n",
      "   [0.39495784 0.6140055  0.36862722]\n",
      "   [0.36638626 0.5887953  0.32156816]\n",
      "   [0.35686275 0.5803922  0.30588236]]]], shape=(128, 224, 224, 3), dtype=float32)\n",
      "tf.Tensor(\n",
      "[[[[0.3764706  0.32156864 0.14509805]\n",
      "   [0.3719888  0.3159664  0.14229693]\n",
      "   [0.35854343 0.29915968 0.13389356]\n",
      "   ...\n",
      "   [0.4442578  0.38991603 0.21232504]\n",
      "   [0.4610646  0.4033615  0.2324932 ]\n",
      "   [0.46666667 0.40784314 0.23921569]]\n",
      "\n",
      "  [[0.38711485 0.33165267 0.15742297]\n",
      "   [0.38231292 0.32581034 0.1542217 ]\n",
      "   [0.36790717 0.30828333 0.14461786]\n",
      "   ...\n",
      "   [0.4432974  0.3888756  0.21144466]\n",
      "   [0.45746315 0.4001602  0.22849157]\n",
      "   [0.46218488 0.40392157 0.23417367]]\n",
      "\n",
      "  [[0.41904762 0.36190477 0.19439776]\n",
      "   [0.41328532 0.35534215 0.189996  ]\n",
      "   [0.39599842 0.33565426 0.17679071]\n",
      "   ...\n",
      "   [0.44041622 0.38575435 0.20880356]\n",
      "   [0.44665873 0.39055628 0.21648668]\n",
      "   [0.4487395  0.39215687 0.21904762]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[0.70644313 0.7030817  0.6974795 ]\n",
      "   [0.71428627 0.70948434 0.703722  ]\n",
      "   [0.7378157  0.728692   0.72244954]\n",
      "   ...\n",
      "   [0.7294914  0.72556984 0.7315722 ]\n",
      "   [0.69707817 0.6914759  0.7001194 ]\n",
      "   [0.6862742  0.6801117  0.68963546]]\n",
      "\n",
      "  [[0.8089646  0.8022419  0.794959  ]\n",
      "   [0.81680775 0.80888456 0.80240196]\n",
      "   [0.84033716 0.82881254 0.82473093]\n",
      "   ...\n",
      "   [0.68195206 0.67971116 0.67658985]\n",
      "   [0.6322518  0.6283302  0.6271297 ]\n",
      "   [0.6156856  0.6112038  0.6106435 ]]\n",
      "\n",
      "  [[0.84313726 0.8352941  0.827451  ]\n",
      "   [0.8509804  0.8420168  0.8352941 ]\n",
      "   [0.8745098  0.8621849  0.85882354]\n",
      "   ...\n",
      "   [0.66610616 0.6644255  0.658263  ]\n",
      "   [0.61064374 0.60728234 0.6028006 ]\n",
      "   [0.5921569  0.5882353  0.58431375]]]\n",
      "\n",
      "\n",
      " [[[0.12941177 0.13725491 0.14117648]\n",
      "   [0.12661065 0.13109244 0.1439776 ]\n",
      "   [0.11820729 0.11260505 0.15238096]\n",
      "   ...\n",
      "   [0.23697463 0.20224106 0.31204516]\n",
      "   [0.203361   0.23585469 0.38095307]\n",
      "   [0.19215687 0.24705882 0.40392157]]\n",
      "\n",
      "  [[0.12885155 0.14117648 0.13725491]\n",
      "   [0.12669069 0.13445379 0.13989596]\n",
      "   [0.12020809 0.11428572 0.14781913]\n",
      "   ...\n",
      "   [0.23697463 0.20512217 0.30212113]\n",
      "   [0.203361   0.2298522  0.36166528]\n",
      "   [0.19215687 0.23809524 0.3815126 ]]\n",
      "\n",
      "  [[0.12717088 0.15294118 0.1254902 ]\n",
      "   [0.12693077 0.14453782 0.12765107]\n",
      "   [0.1262105  0.11932774 0.13413367]\n",
      "   ...\n",
      "   [0.23697463 0.2137655  0.2723491 ]\n",
      "   [0.203361   0.21184473 0.30380183]\n",
      "   [0.19215687 0.21120448 0.31428573]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[0.15910357 0.1484594  0.14173669]\n",
      "   [0.16030407 0.15174071 0.16078429]\n",
      "   [0.16390553 0.16158463 0.21792708]\n",
      "   ...\n",
      "   [0.23697464 0.26490593 0.33253324]\n",
      "   [0.2268906  0.25362137 0.33733517]\n",
      "   [0.22352935 0.24985999 0.33893576]]\n",
      "\n",
      "  [[0.14565814 0.15182076 0.13837533]\n",
      "   [0.1480591  0.15390159 0.15406156]\n",
      "   [0.15526202 0.16014405 0.20112029]\n",
      "   ...\n",
      "   [0.21848719 0.2687475  0.36758745]\n",
      "   [0.2134452  0.25962383 0.37382996]\n",
      "   [0.21176459 0.2565827  0.37591076]]\n",
      "\n",
      "  [[0.14117648 0.15294118 0.13725491]\n",
      "   [0.1439776  0.15462185 0.15182073]\n",
      "   [0.15238096 0.15966387 0.19551821]\n",
      "   ...\n",
      "   [0.21232492 0.270028   0.37927175]\n",
      "   [0.20896356 0.26162457 0.38599446]\n",
      "   [0.20784314 0.25882354 0.3882353 ]]]\n",
      "\n",
      "\n",
      " [[[0.1254902  0.20784314 0.22352941]\n",
      "   [0.1277311  0.19887955 0.19551821]\n",
      "   [0.13445379 0.1719888  0.1114846 ]\n",
      "   ...\n",
      "   [0.10700282 0.1221289  0.01904764]\n",
      "   [0.11204487 0.13053231 0.022409  ]\n",
      "   [0.11372549 0.13333334 0.02352941]]\n",
      "\n",
      "  [[0.12492998 0.2022409  0.22464986]\n",
      "   [0.12669069 0.19415766 0.19639856]\n",
      "   [0.13197279 0.16990797 0.11164466]\n",
      "   ...\n",
      "   [0.11972791 0.13181278 0.02873153]\n",
      "   [0.12404966 0.14093648 0.03617455]\n",
      "   [0.12549019 0.1439776  0.03865546]]\n",
      "\n",
      "  [[0.1232493  0.18543418 0.2280112 ]\n",
      "   [0.12356943 0.179992   0.19903962]\n",
      "   [0.12452982 0.16366547 0.11212486]\n",
      "   ...\n",
      "   [0.15790316 0.16086441 0.05778321]\n",
      "   [0.16006404 0.17214897 0.07747119]\n",
      "   [0.1607843  0.17591037 0.08403362]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[0.49467793 0.48683476 0.41288525]\n",
      "   [0.4920369  0.48187283 0.41032425]\n",
      "   [0.4841138  0.46698695 0.40264124]\n",
      "   ...\n",
      "   [0.5092437  0.46634647 0.34701866]\n",
      "   [0.5159664  0.46154448 0.3338133 ]\n",
      "   [0.5182072  0.4599439  0.32941166]]\n",
      "\n",
      "  [[0.5030813  0.49523818 0.42969206]\n",
      "   [0.50620264 0.49483806 0.4307325 ]\n",
      "   [0.5155666  0.49363774 0.43385386]\n",
      "   ...\n",
      "   [0.50084025 0.45650244 0.3321326 ]\n",
      "   [0.5025209  0.4452178  0.3124446 ]\n",
      "   [0.5030811  0.4414564  0.30588213]]\n",
      "\n",
      "  [[0.5058824  0.49803922 0.43529412]\n",
      "   [0.5109244  0.49915966 0.43753502]\n",
      "   [0.52605045 0.50252104 0.4442577 ]\n",
      "   ...\n",
      "   [0.49803922 0.45322123 0.32717076]\n",
      "   [0.49803922 0.43977576 0.30532193]\n",
      "   [0.49803922 0.43529412 0.29803923]]]\n",
      "\n",
      "\n",
      " ...\n",
      "\n",
      "\n",
      " [[[0.92156863 0.9607843  0.9647059 ]\n",
      "   [0.9232493  0.962465   0.96638656]\n",
      "   [0.9282913  0.967507   0.9714286 ]\n",
      "   ...\n",
      "   [1.         1.         1.        ]\n",
      "   [1.         1.         1.        ]\n",
      "   [1.         1.         1.        ]]\n",
      "\n",
      "  [[0.9226891  0.96134454 0.9652661 ]\n",
      "   [0.9242097  0.96294516 0.96686673]\n",
      "   [0.9287715  0.9677471  0.97166866]\n",
      "   ...\n",
      "   [1.         1.         1.        ]\n",
      "   [1.         1.         1.        ]\n",
      "   [1.         1.         1.        ]]\n",
      "\n",
      "  [[0.9260504  0.9630252  0.9669468 ]\n",
      "   [0.9270908  0.96438575 0.9683073 ]\n",
      "   [0.9302121  0.9684674  0.972389  ]\n",
      "   ...\n",
      "   [1.         1.         1.        ]\n",
      "   [1.         1.         1.        ]\n",
      "   [1.         1.         1.        ]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[0.         0.         0.        ]\n",
      "   [0.         0.         0.        ]\n",
      "   [0.         0.         0.        ]\n",
      "   ...\n",
      "   [0.         0.         0.        ]\n",
      "   [0.         0.         0.        ]\n",
      "   [0.         0.         0.        ]]\n",
      "\n",
      "  [[0.         0.         0.        ]\n",
      "   [0.         0.         0.        ]\n",
      "   [0.         0.         0.        ]\n",
      "   ...\n",
      "   [0.         0.         0.        ]\n",
      "   [0.         0.         0.        ]\n",
      "   [0.         0.         0.        ]]\n",
      "\n",
      "  [[0.         0.         0.        ]\n",
      "   [0.         0.         0.        ]\n",
      "   [0.         0.         0.        ]\n",
      "   ...\n",
      "   [0.         0.         0.        ]\n",
      "   [0.         0.         0.        ]\n",
      "   [0.         0.         0.        ]]]\n",
      "\n",
      "\n",
      " [[[0.6431373  0.6431373  0.6431373 ]\n",
      "   [0.6420168  0.6420168  0.6420168 ]\n",
      "   [0.6386555  0.6386555  0.6386555 ]\n",
      "   ...\n",
      "   [0.53445375 0.53445375 0.53445375]\n",
      "   [0.52773106 0.52773106 0.52773106]\n",
      "   [0.5254902  0.5254902  0.5254902 ]]\n",
      "\n",
      "  [[0.64481795 0.64481795 0.64481795]\n",
      "   [0.6436975  0.6436975  0.6436975 ]\n",
      "   [0.64033616 0.64033616 0.64033616]\n",
      "   ...\n",
      "   [0.53445375 0.53445375 0.53445375]\n",
      "   [0.52773106 0.52773106 0.52773106]\n",
      "   [0.5254902  0.5254902  0.5254902 ]]\n",
      "\n",
      "  [[0.64985996 0.64985996 0.64985996]\n",
      "   [0.6487395  0.6487395  0.6487395 ]\n",
      "   [0.6453782  0.6453782  0.6453782 ]\n",
      "   ...\n",
      "   [0.53445375 0.53445375 0.53445375]\n",
      "   [0.52773106 0.52773106 0.52773106]\n",
      "   [0.5254902  0.5254902  0.5254902 ]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[0.3344537  0.3344537  0.3344537 ]\n",
      "   [0.32557017 0.32557017 0.32557017]\n",
      "   [0.2989195  0.2989195  0.2989195 ]\n",
      "   ...\n",
      "   [0.27507007 0.27507007 0.27507007]\n",
      "   [0.270028   0.270028   0.270028  ]\n",
      "   [0.26834735 0.26834735 0.26834735]]\n",
      "\n",
      "  [[0.31596622 0.31596622 0.31596622]\n",
      "   [0.30828315 0.30828315 0.30828315]\n",
      "   [0.28523397 0.28523397 0.28523397]\n",
      "   ...\n",
      "   [0.28347343 0.28347343 0.28347343]\n",
      "   [0.2733893  0.2733893  0.2733893 ]\n",
      "   [0.27002805 0.27002805 0.27002805]]\n",
      "\n",
      "  [[0.30980393 0.30980393 0.30980393]\n",
      "   [0.30252102 0.30252102 0.30252102]\n",
      "   [0.28067228 0.28067228 0.28067228]\n",
      "   ...\n",
      "   [0.28627446 0.28627446 0.28627446]\n",
      "   [0.2745097  0.2745097  0.2745097 ]\n",
      "   [0.27058825 0.27058825 0.27058825]]]\n",
      "\n",
      "\n",
      " [[[0.7058824  0.6784314  0.26666668]\n",
      "   [0.7036415  0.6761905  0.264986  ]\n",
      "   [0.6969188  0.6694678  0.259944  ]\n",
      "   ...\n",
      "   [0.782633   0.73949575 0.32436967]\n",
      "   [0.76918757 0.7260503  0.30756286]\n",
      "   [0.7647059  0.72156864 0.3019608 ]]\n",
      "\n",
      "  [[0.7014006  0.67058825 0.26834735]\n",
      "   [0.70028013 0.6694678  0.267467  ]\n",
      "   [0.6969188  0.66610646 0.26482594]\n",
      "   ...\n",
      "   [0.7694277  0.7261304  0.3149259 ]\n",
      "   [0.7579031  0.7138855  0.30100027]\n",
      "   [0.75406164 0.70980394 0.29635856]]\n",
      "\n",
      "  [[0.6879552  0.64705884 0.27338937]\n",
      "   [0.6901961  0.64929974 0.27490997]\n",
      "   [0.6969188  0.6560224  0.2794718 ]\n",
      "   ...\n",
      "   [0.7298119  0.68603444 0.28659463]\n",
      "   [0.72404957 0.6773909  0.28131247]\n",
      "   [0.72212887 0.6745098  0.27955183]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[0.7798319  0.6683473  0.59607846]\n",
      "   [0.75958383 0.64345735 0.56902766]\n",
      "   [0.69883955 0.5687875  0.4878752 ]\n",
      "   ...\n",
      "   [0.44993997 0.4128051  0.1610244 ]\n",
      "   [0.4494598  0.40992397 0.15790313]\n",
      "   [0.44929972 0.40896362 0.15686275]]\n",
      "\n",
      "  [[0.7714285  0.6582632  0.59607846]\n",
      "   [0.7516606  0.63481385 0.569988  ]\n",
      "   [0.6923569  0.56446576 0.49171674]\n",
      "   ...\n",
      "   [0.45114043 0.41496602 0.16294518]\n",
      "   [0.44849938 0.41424572 0.15838332]\n",
      "   [0.44761902 0.41400567 0.15686275]]\n",
      "\n",
      "  [[0.76862746 0.654902   0.59607846]\n",
      "   [0.7490196  0.6319328  0.57030815]\n",
      "   [0.6901961  0.56302524 0.49299723]\n",
      "   ...\n",
      "   [0.4515406  0.41568628 0.16358541]\n",
      "   [0.44817924 0.41568628 0.15854338]\n",
      "   [0.44705883 0.41568628 0.15686275]]]], shape=(128, 224, 224, 3), dtype=float32)\n",
      "tf.Tensor(\n",
      "[[[[0.         0.         0.        ]\n",
      "   [0.         0.         0.        ]\n",
      "   [0.         0.         0.        ]\n",
      "   ...\n",
      "   [0.         0.         0.        ]\n",
      "   [0.         0.         0.        ]\n",
      "   [0.         0.         0.        ]]\n",
      "\n",
      "  [[0.         0.         0.        ]\n",
      "   [0.         0.         0.        ]\n",
      "   [0.         0.         0.        ]\n",
      "   ...\n",
      "   [0.         0.         0.        ]\n",
      "   [0.         0.         0.        ]\n",
      "   [0.         0.         0.        ]]\n",
      "\n",
      "  [[0.         0.         0.        ]\n",
      "   [0.         0.         0.        ]\n",
      "   [0.         0.         0.        ]\n",
      "   ...\n",
      "   [0.         0.         0.        ]\n",
      "   [0.         0.         0.        ]\n",
      "   [0.         0.         0.        ]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[0.         0.         0.        ]\n",
      "   [0.         0.         0.        ]\n",
      "   [0.         0.         0.        ]\n",
      "   ...\n",
      "   [0.         0.         0.        ]\n",
      "   [0.         0.         0.        ]\n",
      "   [0.         0.         0.        ]]\n",
      "\n",
      "  [[0.         0.         0.        ]\n",
      "   [0.         0.         0.        ]\n",
      "   [0.         0.         0.        ]\n",
      "   ...\n",
      "   [0.         0.         0.        ]\n",
      "   [0.         0.         0.        ]\n",
      "   [0.         0.         0.        ]]\n",
      "\n",
      "  [[0.         0.         0.        ]\n",
      "   [0.         0.         0.        ]\n",
      "   [0.         0.         0.        ]\n",
      "   ...\n",
      "   [0.         0.         0.        ]\n",
      "   [0.         0.         0.        ]\n",
      "   [0.         0.         0.        ]]]\n",
      "\n",
      "\n",
      " [[[0.         0.         0.        ]\n",
      "   [0.         0.         0.        ]\n",
      "   [0.         0.         0.        ]\n",
      "   ...\n",
      "   [0.         0.         0.        ]\n",
      "   [0.         0.         0.        ]\n",
      "   [0.         0.         0.        ]]\n",
      "\n",
      "  [[0.         0.         0.        ]\n",
      "   [0.         0.         0.        ]\n",
      "   [0.         0.         0.        ]\n",
      "   ...\n",
      "   [0.         0.         0.        ]\n",
      "   [0.         0.         0.        ]\n",
      "   [0.         0.         0.        ]]\n",
      "\n",
      "  [[0.         0.         0.        ]\n",
      "   [0.         0.         0.        ]\n",
      "   [0.         0.         0.        ]\n",
      "   ...\n",
      "   [0.         0.         0.        ]\n",
      "   [0.         0.         0.        ]\n",
      "   [0.         0.         0.        ]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[0.         0.         0.        ]\n",
      "   [0.         0.         0.        ]\n",
      "   [0.         0.         0.        ]\n",
      "   ...\n",
      "   [0.         0.         0.        ]\n",
      "   [0.         0.         0.        ]\n",
      "   [0.         0.         0.        ]]\n",
      "\n",
      "  [[0.         0.         0.        ]\n",
      "   [0.         0.         0.        ]\n",
      "   [0.         0.         0.        ]\n",
      "   ...\n",
      "   [0.         0.         0.        ]\n",
      "   [0.         0.         0.        ]\n",
      "   [0.         0.         0.        ]]\n",
      "\n",
      "  [[0.         0.         0.        ]\n",
      "   [0.         0.         0.        ]\n",
      "   [0.         0.         0.        ]\n",
      "   ...\n",
      "   [0.         0.         0.        ]\n",
      "   [0.         0.         0.        ]\n",
      "   [0.         0.         0.        ]]]\n",
      "\n",
      "\n",
      " [[[0.42352942 0.5803922  0.27450982]\n",
      "   [0.41456583 0.57030815 0.264986  ]\n",
      "   [0.38767508 0.54005605 0.23641458]\n",
      "   ...\n",
      "   [0.3619045  0.46050394 0.23081212]\n",
      "   [0.30812272 0.40336078 0.18711442]\n",
      "   [0.2901961  0.38431373 0.17254902]]\n",
      "\n",
      "  [[0.43641457 0.5882353  0.29411766]\n",
      "   [0.42713085 0.5787115  0.28187275]\n",
      "   [0.3992797  0.5501401  0.24513806]\n",
      "   ...\n",
      "   [0.36006385 0.4601839  0.22937162]\n",
      "   [0.32404926 0.42008764 0.20104013]\n",
      "   [0.31204483 0.4067227  0.19159664]]\n",
      "\n",
      "  [[0.47507006 0.6117647  0.3529412 ]\n",
      "   [0.46482596 0.6039216  0.332533  ]\n",
      "   [0.43409365 0.5803922  0.27130854]\n",
      "   ...\n",
      "   [0.35454193 0.45922378 0.22505012]\n",
      "   [0.3718289  0.47026822 0.24281731]\n",
      "   [0.37759104 0.4739496  0.24873951]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[0.5820728  0.71204495 0.43025208]\n",
      "   [0.58239293 0.7149261  0.4318527 ]\n",
      "   [0.5833533  0.7235696  0.43665463]\n",
      "   ...\n",
      "   [0.385274   0.60064024 0.21632637]\n",
      "   [0.37615025 0.5951179  0.19231664]\n",
      "   [0.3731091  0.5932772  0.18431367]]\n",
      "\n",
      "  [[0.5719887  0.7338938  0.42521003]\n",
      "   [0.57206875 0.73629475 0.42561018]\n",
      "   [0.57230884 0.7434976  0.42681062]\n",
      "   ...\n",
      "   [0.3727889  0.5917566  0.20744276]\n",
      "   [0.35286072 0.57903135 0.18127213]\n",
      "   [0.34621823 0.57478976 0.1725489 ]]\n",
      "\n",
      "  [[0.5686275  0.7411765  0.42352942]\n",
      "   [0.5686275  0.7434174  0.42352942]\n",
      "   [0.5686275  0.7501401  0.42352942]\n",
      "   ...\n",
      "   [0.36862734 0.5887955  0.20448166]\n",
      "   [0.3450978  0.5736693  0.17759077]\n",
      "   [0.3372549  0.5686275  0.16862746]]]\n",
      "\n",
      "\n",
      " ...\n",
      "\n",
      "\n",
      " [[[0.         0.         0.        ]\n",
      "   [0.         0.         0.        ]\n",
      "   [0.         0.         0.        ]\n",
      "   ...\n",
      "   [0.         0.         0.        ]\n",
      "   [0.         0.         0.        ]\n",
      "   [0.         0.         0.        ]]\n",
      "\n",
      "  [[0.         0.         0.        ]\n",
      "   [0.         0.         0.        ]\n",
      "   [0.         0.         0.        ]\n",
      "   ...\n",
      "   [0.         0.         0.        ]\n",
      "   [0.         0.         0.        ]\n",
      "   [0.         0.         0.        ]]\n",
      "\n",
      "  [[0.         0.         0.        ]\n",
      "   [0.         0.         0.        ]\n",
      "   [0.         0.         0.        ]\n",
      "   ...\n",
      "   [0.         0.         0.        ]\n",
      "   [0.         0.         0.        ]\n",
      "   [0.         0.         0.        ]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[0.19327728 0.29523808 0.29635856]\n",
      "   [0.19199677 0.2945178  0.2939576 ]\n",
      "   [0.18815525 0.29235694 0.28675473]\n",
      "   ...\n",
      "   [0.13461384 0.26178473 0.23633455]\n",
      "   [0.14205687 0.26754707 0.25026017]\n",
      "   [0.14453778 0.26946777 0.25490192]]\n",
      "\n",
      "  [[0.18655455 0.28851536 0.29467785]\n",
      "   [0.18623444 0.28875545 0.2932373 ]\n",
      "   [0.18527408 0.28947577 0.2889156 ]\n",
      "   ...\n",
      "   [0.12525004 0.2557823  0.22168861]\n",
      "   [0.13341337 0.26226494 0.23777515]\n",
      "   [0.13613437 0.26442572 0.24313714]]\n",
      "\n",
      "  [[0.18431373 0.28627452 0.29411766]\n",
      "   [0.18431373 0.28683475 0.2929972 ]\n",
      "   [0.18431373 0.28851542 0.28963587]\n",
      "   ...\n",
      "   [0.1221289  0.25378156 0.21680681]\n",
      "   [0.13053231 0.26050428 0.23361361]\n",
      "   [0.13333334 0.2627451  0.23921569]]]\n",
      "\n",
      "\n",
      " [[[0.21176471 0.18039216 0.14509805]\n",
      "   [0.20728292 0.17927171 0.14453782]\n",
      "   [0.19383754 0.17591037 0.14285715]\n",
      "   ...\n",
      "   [0.85882366 0.86834747 0.7658264 ]\n",
      "   [0.8823532  0.89355767 0.78263324]\n",
      "   [0.8901961  0.9019608  0.7882353 ]]\n",
      "\n",
      "  [[0.22408964 0.1859944  0.14901961]\n",
      "   [0.21960784 0.18487395 0.14837936]\n",
      "   [0.20616247 0.18151261 0.1464586 ]\n",
      "   ...\n",
      "   [0.8482594  0.86082447 0.739976  ]\n",
      "   [0.8679474  0.88747525 0.7421369 ]\n",
      "   [0.8745098  0.89635855 0.74285716]]\n",
      "\n",
      "  [[0.26106444 0.20280112 0.16078432]\n",
      "   [0.25658265 0.20168068 0.15990397]\n",
      "   [0.24313726 0.19831933 0.1572629 ]\n",
      "   ...\n",
      "   [0.8165667  0.83825547 0.6624248 ]\n",
      "   [0.82473    0.869228   0.62064785]\n",
      "   [0.827451   0.8795518  0.6067227 ]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[0.         0.         0.        ]\n",
      "   [0.         0.         0.        ]\n",
      "   [0.         0.         0.        ]\n",
      "   ...\n",
      "   [0.         0.         0.        ]\n",
      "   [0.         0.         0.        ]\n",
      "   [0.         0.         0.        ]]\n",
      "\n",
      "  [[0.         0.         0.        ]\n",
      "   [0.         0.         0.        ]\n",
      "   [0.         0.         0.        ]\n",
      "   ...\n",
      "   [0.         0.         0.        ]\n",
      "   [0.         0.         0.        ]\n",
      "   [0.         0.         0.        ]]\n",
      "\n",
      "  [[0.         0.         0.        ]\n",
      "   [0.         0.         0.        ]\n",
      "   [0.         0.         0.        ]\n",
      "   ...\n",
      "   [0.         0.         0.        ]\n",
      "   [0.         0.         0.        ]\n",
      "   [0.         0.         0.        ]]]\n",
      "\n",
      "\n",
      " [[[0.2509804  0.20392157 0.18039216]\n",
      "   [0.25210086 0.20168068 0.17815126]\n",
      "   [0.2554622  0.19495799 0.17142858]\n",
      "   ...\n",
      "   [0.32941172 0.19327734 0.18095243]\n",
      "   [0.31764695 0.19831938 0.18935584]\n",
      "   [0.3137255  0.2        0.19215687]]\n",
      "\n",
      "  [[0.2532213  0.2044818  0.18095239]\n",
      "   [0.25450182 0.20328131 0.17951182]\n",
      "   [0.25834334 0.19967988 0.17519008]\n",
      "   ...\n",
      "   [0.32757097 0.19423772 0.18383358]\n",
      "   [0.31508592 0.19855946 0.19343747]\n",
      "   [0.31092438 0.2        0.19663866]]\n",
      "\n",
      "  [[0.259944   0.20616247 0.18263306]\n",
      "   [0.26170468 0.20808324 0.18359344]\n",
      "   [0.26698682 0.21384554 0.18647459]\n",
      "   ...\n",
      "   [0.32204875 0.19711886 0.19247706]\n",
      "   [0.30740282 0.19927974 0.20568241]\n",
      "   [0.30252102 0.2        0.21008404]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[0.5826316  0.5535     0.538374  ]\n",
      "   [0.58351195 0.5549406  0.53829396]\n",
      "   [0.58615303 0.5592623  0.5380539 ]\n",
      "   ...\n",
      "   [0.46298414 0.4543407  0.43041113]\n",
      "   [0.47498894 0.46778607 0.44289616]\n",
      "   [0.47899038 0.47226775 0.4470577 ]]\n",
      "\n",
      "  [[0.29859656 0.279549   0.27282643]\n",
      "   [0.29923677 0.2807495  0.27322656]\n",
      "   [0.30115753 0.28435093 0.27442706]\n",
      "   ...\n",
      "   [0.23297092 0.22744873 0.21264291]\n",
      "   [0.23849306 0.23585209 0.22080612]\n",
      "   [0.2403337  0.2386531  0.22352713]]\n",
      "\n",
      "  [[0.20392157 0.1882353  0.18431373]\n",
      "   [0.2044818  0.18935575 0.18487395]\n",
      "   [0.20616247 0.19271709 0.18655463]\n",
      "   ...\n",
      "   [0.15630254 0.15182076 0.14005606]\n",
      "   [0.1596639  0.1585435  0.14677879]\n",
      "   [0.16078432 0.16078432 0.14901961]]]], shape=(128, 224, 224, 3), dtype=float32)\n",
      "tf.Tensor(\n",
      "[[[[0.         0.         0.        ]\n",
      "   [0.         0.         0.        ]\n",
      "   [0.         0.         0.        ]\n",
      "   ...\n",
      "   [0.         0.         0.        ]\n",
      "   [0.         0.         0.        ]\n",
      "   [0.         0.         0.        ]]\n",
      "\n",
      "  [[0.         0.         0.        ]\n",
      "   [0.         0.         0.        ]\n",
      "   [0.         0.         0.        ]\n",
      "   ...\n",
      "   [0.         0.         0.        ]\n",
      "   [0.         0.         0.        ]\n",
      "   [0.         0.         0.        ]]\n",
      "\n",
      "  [[0.         0.         0.        ]\n",
      "   [0.         0.         0.        ]\n",
      "   [0.         0.         0.        ]\n",
      "   ...\n",
      "   [0.         0.         0.        ]\n",
      "   [0.         0.         0.        ]\n",
      "   [0.         0.         0.        ]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[0.         0.         0.        ]\n",
      "   [0.         0.         0.        ]\n",
      "   [0.         0.         0.        ]\n",
      "   ...\n",
      "   [0.         0.         0.        ]\n",
      "   [0.         0.         0.        ]\n",
      "   [0.         0.         0.        ]]\n",
      "\n",
      "  [[0.         0.         0.        ]\n",
      "   [0.         0.         0.        ]\n",
      "   [0.         0.         0.        ]\n",
      "   ...\n",
      "   [0.         0.         0.        ]\n",
      "   [0.         0.         0.        ]\n",
      "   [0.         0.         0.        ]]\n",
      "\n",
      "  [[0.         0.         0.        ]\n",
      "   [0.         0.         0.        ]\n",
      "   [0.         0.         0.        ]\n",
      "   ...\n",
      "   [0.         0.         0.        ]\n",
      "   [0.         0.         0.        ]\n",
      "   [0.         0.         0.        ]]]\n",
      "\n",
      "\n",
      " [[[0.38039216 0.48235294 0.3529412 ]\n",
      "   [0.37759104 0.47955182 0.34733894]\n",
      "   [0.36918768 0.47114846 0.33053222]\n",
      "   ...\n",
      "   [0.496919   0.6005605  0.47282937]\n",
      "   [0.538936   0.64425814 0.5182078 ]\n",
      "   [0.5529412  0.65882355 0.53333336]]\n",
      "\n",
      "  [[0.3652661  0.46666667 0.3394958 ]\n",
      "   [0.36414567 0.46562624 0.33533415]\n",
      "   [0.36078432 0.462505   0.32284915]\n",
      "   ...\n",
      "   [0.49747917 0.59927994 0.47090855]\n",
      "   [0.5277314  0.6321732  0.5042821 ]\n",
      "   [0.53781515 0.6431373  0.5154062 ]]\n",
      "\n",
      "  [[0.31988797 0.41960785 0.29915968]\n",
      "   [0.32380953 0.42384955 0.29931974]\n",
      "   [0.33557424 0.43657464 0.29979992]\n",
      "   ...\n",
      "   [0.49915963 0.5954382  0.46514603]\n",
      "   [0.49411762 0.59591836 0.462505  ]\n",
      "   [0.492437   0.59607846 0.46162468]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[0.5294118  0.72044826 0.4039215 ]\n",
      "   [0.52909166 0.7211685  0.40848336]\n",
      "   [0.5281313  0.7233294  0.42216885]\n",
      "   ...\n",
      "   [0.34749883 0.445378   0.2561023 ]\n",
      "   [0.3465387  0.45210096 0.2505803 ]\n",
      "   [0.34621865 0.4543419  0.24873969]]\n",
      "\n",
      "  [[0.5294118  0.72717094 0.39215675]\n",
      "   [0.52933174 0.7286115  0.39791906]\n",
      "   [0.52909166 0.7329333  0.41520602]\n",
      "   ...\n",
      "   [0.31460574 0.4050419  0.23545417]\n",
      "   [0.35974452 0.46218556 0.27314988]\n",
      "   [0.37479022 0.48123276 0.2857147 ]]\n",
      "\n",
      "  [[0.5294118  0.7294118  0.3882353 ]\n",
      "   [0.5294118  0.73109245 0.39439777]\n",
      "   [0.5294118  0.73613447 0.41288516]\n",
      "   ...\n",
      "   [0.30364177 0.39159703 0.2285717 ]\n",
      "   [0.3641463  0.46554697 0.28067282]\n",
      "   [0.38431373 0.49019608 0.29803923]]]\n",
      "\n",
      "\n",
      " [[[0.39607844 0.3882353  0.3254902 ]\n",
      "   [0.3904762  0.38263306 0.31876752]\n",
      "   [0.37366948 0.36582634 0.29859945]\n",
      "   ...\n",
      "   [0.36470583 0.36134446 0.3182072 ]\n",
      "   [0.35294107 0.34621835 0.3030811 ]\n",
      "   [0.34901962 0.34117648 0.29803923]]\n",
      "\n",
      "  [[0.38879552 0.38039216 0.31932774]\n",
      "   [0.38343337 0.37519008 0.31316528]\n",
      "   [0.36734694 0.35958385 0.29467788]\n",
      "   ...\n",
      "   [0.37022802 0.367667   0.3239695 ]\n",
      "   [0.3572628  0.35158047 0.307883  ]\n",
      "   [0.3529412  0.3462185  0.30252102]]\n",
      "\n",
      "  [[0.3669468  0.35686275 0.30084035]\n",
      "   [0.36230493 0.35286117 0.29635856]\n",
      "   [0.34837937 0.34085634 0.28291318]\n",
      "   ...\n",
      "   [0.38679466 0.38663456 0.3412564 ]\n",
      "   [0.37022793 0.3676669  0.32228875]\n",
      "   [0.3647059  0.36134455 0.3159664 ]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[0.42296916 0.42464983 0.3053221 ]\n",
      "   [0.42833132 0.43113244 0.3090036 ]\n",
      "   [0.44441774 0.45058024 0.320048  ]\n",
      "   ...\n",
      "   [0.3884754  0.4        0.20056024]\n",
      "   [0.3870348  0.3983193  0.20392159]\n",
      "   [0.38655463 0.3977591  0.20504199]]\n",
      "\n",
      "  [[0.41456574 0.41792712 0.2969187 ]\n",
      "   [0.42136848 0.4258503  0.30204076]\n",
      "   [0.4417767  0.44961983 0.31740695]\n",
      "   ...\n",
      "   [0.38871548 0.4016807  0.20056023]\n",
      "   [0.3858343  0.4        0.1988795 ]\n",
      "   [0.38487393 0.3994398  0.19831926]]\n",
      "\n",
      "  [[0.4117647  0.41568628 0.29411766]\n",
      "   [0.41904762 0.42408964 0.2997199 ]\n",
      "   [0.44089636 0.44929972 0.31652662]\n",
      "   ...\n",
      "   [0.3887955  0.4022409  0.20056021]\n",
      "   [0.38543415 0.4005602  0.19719885]\n",
      "   [0.38431373 0.4        0.19607843]]]\n",
      "\n",
      "\n",
      " ...\n",
      "\n",
      "\n",
      " [[[0.5294118  0.6039216  0.25882354]\n",
      "   [0.567507   0.6442577  0.30868348]\n",
      "   [0.68179274 0.7652661  0.4582633 ]\n",
      "   ...\n",
      "   [0.14677867 0.20000018 0.33165312]\n",
      "   [0.13669458 0.23529448 0.42409056]\n",
      "   [0.13333334 0.24705882 0.45490196]]\n",
      "\n",
      "  [[0.5535014  0.6268908  0.28851542]\n",
      "   [0.5839936  0.66010404 0.32933176]\n",
      "   [0.67547023 0.7597439  0.4517807 ]\n",
      "   ...\n",
      "   [0.1511804  0.20168085 0.3366151 ]\n",
      "   [0.13485378 0.23697515 0.4244907 ]\n",
      "   [0.12941177 0.2487395  0.45378152]]\n",
      "\n",
      "  [[0.62577033 0.69579834 0.37759104]\n",
      "   [0.63345337 0.7076431  0.3912765 ]\n",
      "   [0.6565026  0.7431773  0.43233293]\n",
      "   ...\n",
      "   [0.16438559 0.20672289 0.35150096]\n",
      "   [0.12933138 0.24201718 0.42569104]\n",
      "   [0.11764707 0.25378153 0.45042017]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[0.07114851 0.06946783 0.06834741]\n",
      "   [0.06674673 0.06474593 0.06266512]\n",
      "   [0.05354142 0.05058023 0.04561826]\n",
      "   ...\n",
      "   [0.03433374 0.14221689 0.32709083]\n",
      "   [0.03337335 0.1426971  0.32757103]\n",
      "   [0.03305323 0.14285716 0.3277311 ]]\n",
      "\n",
      "  [[0.07955191 0.07619055 0.08179285]\n",
      "   [0.07298926 0.06954787 0.0732294 ]\n",
      "   [0.05330132 0.04961984 0.04753904]\n",
      "   ...\n",
      "   [0.03505403 0.14101641 0.322529  ]\n",
      "   [0.03481394 0.1436575  0.32517007]\n",
      "   [0.03473391 0.14453784 0.3260504 ]]\n",
      "\n",
      "  [[0.08235294 0.07843138 0.08627451]\n",
      "   [0.07507003 0.07114846 0.0767507 ]\n",
      "   [0.05322129 0.04929972 0.04817927]\n",
      "   ...\n",
      "   [0.03529412 0.14061627 0.32100844]\n",
      "   [0.03529412 0.14397763 0.3243698 ]\n",
      "   [0.03529412 0.14509805 0.3254902 ]]]\n",
      "\n",
      "\n",
      " [[[0.         0.         0.        ]\n",
      "   [0.         0.         0.        ]\n",
      "   [0.         0.         0.        ]\n",
      "   ...\n",
      "   [0.         0.         0.        ]\n",
      "   [0.         0.         0.        ]\n",
      "   [0.         0.         0.        ]]\n",
      "\n",
      "  [[0.         0.         0.        ]\n",
      "   [0.         0.         0.        ]\n",
      "   [0.         0.         0.        ]\n",
      "   ...\n",
      "   [0.         0.         0.        ]\n",
      "   [0.         0.         0.        ]\n",
      "   [0.         0.         0.        ]]\n",
      "\n",
      "  [[0.         0.         0.        ]\n",
      "   [0.         0.         0.        ]\n",
      "   [0.         0.         0.        ]\n",
      "   ...\n",
      "   [0.         0.         0.        ]\n",
      "   [0.         0.         0.        ]\n",
      "   [0.         0.         0.        ]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[0.         0.         0.        ]\n",
      "   [0.         0.         0.        ]\n",
      "   [0.         0.         0.        ]\n",
      "   ...\n",
      "   [0.         0.         0.        ]\n",
      "   [0.         0.         0.        ]\n",
      "   [0.         0.         0.        ]]\n",
      "\n",
      "  [[0.         0.         0.        ]\n",
      "   [0.         0.         0.        ]\n",
      "   [0.         0.         0.        ]\n",
      "   ...\n",
      "   [0.         0.         0.        ]\n",
      "   [0.         0.         0.        ]\n",
      "   [0.         0.         0.        ]]\n",
      "\n",
      "  [[0.         0.         0.        ]\n",
      "   [0.         0.         0.        ]\n",
      "   [0.         0.         0.        ]\n",
      "   ...\n",
      "   [0.         0.         0.        ]\n",
      "   [0.         0.         0.        ]\n",
      "   [0.         0.         0.        ]]]\n",
      "\n",
      "\n",
      " [[[0.87058824 0.8745098  0.85490197]\n",
      "   [0.87282914 0.8767507  0.85714287]\n",
      "   [0.8795518  0.8834734  0.86386555]\n",
      "   ...\n",
      "   [0.7915968  0.65826344 0.5523811 ]\n",
      "   [0.8184877  0.6851544  0.57927203]\n",
      "   [0.827451   0.69411767 0.5882353 ]]\n",
      "\n",
      "  [[0.8717087  0.87563026 0.8560224 ]\n",
      "   [0.8739496  0.87787116 0.8582633 ]\n",
      "   [0.8806723  0.88459384 0.864986  ]\n",
      "   ...\n",
      "   [0.7894359  0.6563427  0.5490998 ]\n",
      "   [0.8158466  0.68299353 0.5755105 ]\n",
      "   [0.8246499  0.69187677 0.58431375]]\n",
      "\n",
      "  [[0.87507004 0.8789916  0.85938376]\n",
      "   [0.87731093 0.8812325  0.86162466]\n",
      "   [0.8840336  0.8879552  0.86834735]\n",
      "   ...\n",
      "   [0.7829533  0.65058035 0.53925586]\n",
      "   [0.80792344 0.6765109  0.564226  ]\n",
      "   [0.8162465  0.6851541  0.57254905]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[0.65378165 0.51260513 0.3932774 ]\n",
      "   [0.65834343 0.51660675 0.39751908]\n",
      "   [0.67202884 0.5286115  0.4102441 ]\n",
      "   ...\n",
      "   [0.6291317  0.48347342 0.36750698]\n",
      "   [0.6257703  0.47843137 0.36414564]\n",
      "   [0.6246499  0.47675076 0.36302522]]\n",
      "\n",
      "  [[0.6722691  0.53109264 0.41008422]\n",
      "   [0.67298937 0.5312527  0.41072443]\n",
      "   [0.6751501  0.53173274 0.4126451 ]\n",
      "   ...\n",
      "   [0.63417375 0.4935575  0.36582628]\n",
      "   [0.63081235 0.48851544 0.36246493]\n",
      "   [0.62969196 0.48683482 0.36134452]]\n",
      "\n",
      "  [[0.6784314  0.5372549  0.41568628]\n",
      "   [0.67787117 0.5361345  0.41512606]\n",
      "   [0.6761905  0.53277314 0.41344538]\n",
      "   ...\n",
      "   [0.63585436 0.49691877 0.36526608]\n",
      "   [0.63249296 0.4918767  0.36190474]\n",
      "   [0.6313726  0.49019608 0.36078432]]]], shape=(128, 224, 224, 3), dtype=float32)\n",
      "tf.Tensor(\n",
      "[[[[0.7372549  0.5921569  0.49019608]\n",
      "   [0.7394958  0.60784316 0.5176471 ]\n",
      "   [0.7462185  0.654902   0.6       ]\n",
      "   ...\n",
      "   [0.5355741  0.605602   0.28403333]\n",
      "   [0.49859905 0.56022364 0.22689018]\n",
      "   [0.4862745  0.54509807 0.20784314]]\n",
      "\n",
      "  [[0.74005604 0.5927171  0.49019608]\n",
      "   [0.74205685 0.6088036  0.51772714]\n",
      "   [0.7480592  0.6570628  0.60032016]\n",
      "   ...\n",
      "   [0.5334933  0.60232073 0.27883127]\n",
      "   [0.49891922 0.5598235  0.22600988]\n",
      "   [0.48739496 0.5456583  0.20840336]]\n",
      "\n",
      "  [[0.7484594  0.5943978  0.49019608]\n",
      "   [0.7497399  0.6116847  0.5179672 ]\n",
      "   [0.75358146 0.6635454  0.6012805 ]\n",
      "   ...\n",
      "   [0.52725077 0.59247684 0.26322508]\n",
      "   [0.49987966 0.55862314 0.22336894]\n",
      "   [0.4907563  0.54733896 0.21008404]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[0.71092474 0.74173707 0.7624653 ]\n",
      "   [0.71308565 0.7443781  0.76150495]\n",
      "   [0.71956825 0.7523013  0.75862384]\n",
      "   ...\n",
      "   [0.6815532  0.70924425 0.7196483 ]\n",
      "   [0.6947586  0.7226898  0.7328538 ]\n",
      "   [0.6991602  0.7271714  0.7372554 ]]\n",
      "\n",
      "  [[0.7865554  0.80896425 0.8229698 ]\n",
      "   [0.7891965  0.81256574 0.82441044]\n",
      "   [0.7971196  0.8233701  0.82873225]\n",
      "   ...\n",
      "   [0.77711195 0.8033624  0.7984003 ]\n",
      "   [0.8018421  0.8268921  0.8231304 ]\n",
      "   [0.8100852  0.834735   0.8313735 ]]\n",
      "\n",
      "  [[0.8117647  0.83137256 0.84313726]\n",
      "   [0.81456584 0.8352941  0.84537816]\n",
      "   [0.8229692  0.84705883 0.85210085]\n",
      "   ...\n",
      "   [0.8089637  0.834734   0.82465   ]\n",
      "   [0.8375353  0.86162496 0.8532216 ]\n",
      "   [0.84705883 0.87058824 0.8627451 ]]]\n",
      "\n",
      "\n",
      " [[[0.7176471  0.6666667  0.6156863 ]\n",
      "   [0.7176471  0.6672269  0.6151261 ]\n",
      "   [0.7176471  0.6689076  0.6134454 ]\n",
      "   ...\n",
      "   [0.86162436 0.8016804  0.80280095]\n",
      "   [0.79775846 0.74453723 0.7624646 ]\n",
      "   [0.7764706  0.7254902  0.7490196 ]]\n",
      "\n",
      "  [[0.7165266  0.6666667  0.6162465 ]\n",
      "   [0.7169268  0.66738695 0.61584634]\n",
      "   [0.71812725 0.66954786 0.6146459 ]\n",
      "   ...\n",
      "   [0.8667464  0.8061622  0.8045617 ]\n",
      "   [0.8091231  0.7540611  0.7671065 ]\n",
      "   [0.789916   0.7366947  0.75462186]]\n",
      "\n",
      "  [[0.7131653  0.6666667  0.6179272 ]\n",
      "   [0.7147659  0.6678672  0.61800724]\n",
      "   [0.71956784 0.6714686  0.61824733]\n",
      "   ...\n",
      "   [0.8821127  0.8196077  0.8098438 ]\n",
      "   [0.8432169  0.78263265 0.78103215]\n",
      "   [0.8302521  0.77030814 0.7714286 ]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[0.         0.         0.        ]\n",
      "   [0.         0.         0.        ]\n",
      "   [0.         0.         0.        ]\n",
      "   ...\n",
      "   [0.         0.         0.        ]\n",
      "   [0.         0.         0.        ]\n",
      "   [0.         0.         0.        ]]\n",
      "\n",
      "  [[0.         0.         0.        ]\n",
      "   [0.         0.         0.        ]\n",
      "   [0.         0.         0.        ]\n",
      "   ...\n",
      "   [0.         0.         0.        ]\n",
      "   [0.         0.         0.        ]\n",
      "   [0.         0.         0.        ]]\n",
      "\n",
      "  [[0.         0.         0.        ]\n",
      "   [0.         0.         0.        ]\n",
      "   [0.         0.         0.        ]\n",
      "   ...\n",
      "   [0.         0.         0.        ]\n",
      "   [0.         0.         0.        ]\n",
      "   [0.         0.         0.        ]]]\n",
      "\n",
      "\n",
      " [[[0.78039217 0.7882353  0.7882353 ]\n",
      "   [0.7809524  0.78879553 0.78879553]\n",
      "   [0.78263307 0.7904762  0.7904762 ]\n",
      "   ...\n",
      "   [0.76134455 0.7691877  0.7652661 ]\n",
      "   [0.75798315 0.7658263  0.7619047 ]\n",
      "   [0.75686276 0.7647059  0.7607843 ]]\n",
      "\n",
      "  [[0.78263307 0.789916   0.7904762 ]\n",
      "   [0.7831933  0.7904762  0.7910364 ]\n",
      "   [0.78487396 0.7921569  0.7927171 ]\n",
      "   ...\n",
      "   [0.76542616 0.7732693  0.7693477 ]\n",
      "   [0.7627851  0.7706282  0.76670665]\n",
      "   [0.7619048  0.7697479  0.76582634]]\n",
      "\n",
      "  [[0.78935575 0.794958   0.7971989 ]\n",
      "   [0.789916   0.7955182  0.7977591 ]\n",
      "   [0.79159665 0.7971989  0.7994398 ]\n",
      "   ...\n",
      "   [0.7776711  0.78551424 0.78159267]\n",
      "   [0.77719086 0.785034   0.78111243]\n",
      "   [0.7770308  0.78487396 0.7809524 ]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[0.18543415 0.26386547 0.13613437]\n",
      "   [0.182633   0.2635453  0.13397348]\n",
      "   [0.17422956 0.26258487 0.1274908 ]\n",
      "   ...\n",
      "   [0.7405362  0.7486995  0.7405362 ]\n",
      "   [0.73765504 0.7489396  0.7359744 ]\n",
      "   [0.7366947  0.7490196  0.7344538 ]]\n",
      "\n",
      "  [[0.17871141 0.24537796 0.11932756]\n",
      "   [0.17086823 0.24025586 0.11164443]\n",
      "   [0.14733867 0.22488958 0.08859506]\n",
      "   ...\n",
      "   [0.74101645 0.7506203  0.7426971 ]\n",
      "   [0.7402961  0.7494198  0.7402962 ]\n",
      "   [0.7400561  0.7490196  0.7394959 ]]\n",
      "\n",
      "  [[0.1764706  0.23921569 0.11372549]\n",
      "   [0.16694678 0.232493   0.10420168]\n",
      "   [0.13837536 0.21232493 0.07563026]\n",
      "   ...\n",
      "   [0.7411765  0.7512605  0.7434174 ]\n",
      "   [0.7411765  0.74957985 0.7417367 ]\n",
      "   [0.7411765  0.7490196  0.7411765 ]]]\n",
      "\n",
      "\n",
      " ...\n",
      "\n",
      "\n",
      " [[[0.65882355 0.7176471  0.7882353 ]\n",
      "   [0.65882355 0.7176471  0.7882353 ]\n",
      "   [0.65882355 0.7176471  0.7882353 ]\n",
      "   ...\n",
      "   [0.92156863 0.935014   0.94509804]\n",
      "   [0.92156863 0.9366947  0.94509804]\n",
      "   [0.92156863 0.9372549  0.94509804]]\n",
      "\n",
      "  [[0.65882355 0.71708685 0.7876751 ]\n",
      "   [0.6587435  0.7169268  0.78751504]\n",
      "   [0.6585034  0.7164466  0.7870348 ]\n",
      "   ...\n",
      "   [0.9195678  0.9336535  0.9439776 ]\n",
      "   [0.9198079  0.93509406 0.9439776 ]\n",
      "   [0.91988796 0.93557423 0.9439776 ]]\n",
      "\n",
      "  [[0.65882355 0.7154062  0.7859944 ]\n",
      "   [0.6585034  0.7147659  0.78535414]\n",
      "   [0.65754306 0.71284515 0.7834334 ]\n",
      "   ...\n",
      "   [0.91356546 0.9295718  0.94061625]\n",
      "   [0.9145258  0.9302921  0.94061625]\n",
      "   [0.91484594 0.9305322  0.94061625]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[0.39439753 0.38879526 0.37815097]\n",
      "   [0.39767882 0.39183646 0.3815123 ]\n",
      "   [0.40752274 0.4009601  0.39159632]\n",
      "   ...\n",
      "   [0.30140045 0.287875   0.2608241 ]\n",
      "   [0.30644244 0.29003584 0.26394537]\n",
      "   [0.30812308 0.2907561  0.26498574]]\n",
      "\n",
      "  [[0.34565777 0.33837485 0.32100785]\n",
      "   [0.3477386  0.33997548 0.3226885 ]\n",
      "   [0.35398105 0.34477735 0.32773045]\n",
      "   ...\n",
      "   [0.27114818 0.25306088 0.21688631]\n",
      "   [0.2711481  0.25234056 0.21640608]\n",
      "   [0.2711481  0.25210047 0.21624601]]\n",
      "\n",
      "  [[0.32941177 0.32156864 0.3019608 ]\n",
      "   [0.33109245 0.3226891  0.30308124]\n",
      "   [0.33613446 0.32605043 0.3064426 ]\n",
      "   ...\n",
      "   [0.26106444 0.24145657 0.20224088]\n",
      "   [0.25938374 0.2397759  0.20056021]\n",
      "   [0.25882354 0.23921569 0.2       ]]]\n",
      "\n",
      "\n",
      " [[[0.27058825 0.16470589 0.29411766]\n",
      "   [0.31204483 0.19607843 0.33781514]\n",
      "   [0.43641457 0.29019606 0.46890756]\n",
      "   ...\n",
      "   [0.9803922  0.98823524 0.9843137 ]\n",
      "   [0.992157   0.9764705  0.9843137 ]\n",
      "   [0.99607843 0.972549   0.9843137 ]]\n",
      "\n",
      "  [[0.27058825 0.16526611 0.29411766]\n",
      "   [0.31204483 0.19655862 0.33789515]\n",
      "   [0.43641457 0.29043615 0.4692277 ]\n",
      "   ...\n",
      "   [0.9806323  0.9860744  0.9855942 ]\n",
      "   [0.99263716 0.9721487  0.98463386]\n",
      "   [0.99663866 0.967507   0.9843137 ]]\n",
      "\n",
      "  [[0.27058825 0.16694678 0.29411766]\n",
      "   [0.31204483 0.19799921 0.33813527]\n",
      "   [0.43641457 0.29115644 0.47018808]\n",
      "   ...\n",
      "   [0.9813526  0.9795917  0.98943573]\n",
      "   [0.99407774 0.95918345 0.9855942 ]\n",
      "   [0.9983193  0.95238096 0.9843137 ]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[0.26666668 0.16078432 0.29411766]\n",
      "   [0.3070028  0.1904762  0.33893558]\n",
      "   [0.4280112  0.2795518  0.47338936]\n",
      "   ...\n",
      "   [0.00392157 0.49899963 0.72132856]\n",
      "   [0.00392157 0.4982793  0.72276914]\n",
      "   [0.00392157 0.49803922 0.7232493 ]]\n",
      "\n",
      "  [[0.26666668 0.16078432 0.29411766]\n",
      "   [0.3070028  0.1904762  0.33893558]\n",
      "   [0.4280112  0.2795518  0.47338936]\n",
      "   ...\n",
      "   [0.00392157 0.49996    0.72108847]\n",
      "   [0.00392157 0.49851942 0.72396964]\n",
      "   [0.00392157 0.49803922 0.72493   ]]\n",
      "\n",
      "  [[0.26666668 0.16078432 0.29411766]\n",
      "   [0.3070028  0.1904762  0.33893558]\n",
      "   [0.4280112  0.2795518  0.47338936]\n",
      "   ...\n",
      "   [0.00392157 0.50028014 0.7210084 ]\n",
      "   [0.00392157 0.49859944 0.7243698 ]\n",
      "   [0.00392157 0.49803922 0.7254902 ]]]\n",
      "\n",
      "\n",
      " [[[0.09019608 0.09411765 0.08627451]\n",
      "   [0.09747899 0.10588235 0.09131653]\n",
      "   [0.11932773 0.14117646 0.10644258]\n",
      "   ...\n",
      "   [0.3294116  0.42016792 0.24369729]\n",
      "   [0.2941173  0.39327705 0.20504163]\n",
      "   [0.28235295 0.38431373 0.19215687]]\n",
      "\n",
      "  [[0.0952381  0.09915967 0.08851541]\n",
      "   [0.10156063 0.10964386 0.0932373 ]\n",
      "   [0.12052821 0.14109643 0.10740297]\n",
      "   ...\n",
      "   [0.32709068 0.41648647 0.24177653]\n",
      "   [0.29395726 0.39151636 0.20456146]\n",
      "   [0.28291318 0.38319328 0.19215687]]\n",
      "\n",
      "  [[0.11036415 0.11428572 0.0952381 ]\n",
      "   [0.11380553 0.12092838 0.0989996 ]\n",
      "   [0.12412965 0.14085634 0.11028411]\n",
      "   ...\n",
      "   [0.32012793 0.4054421  0.23601425]\n",
      "   [0.29347712 0.3862343  0.20312092]\n",
      "   [0.28459385 0.37983194 0.19215687]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[0.13781512 0.18207273 0.0851541 ]\n",
      "   [0.13565426 0.17671059 0.08587438]\n",
      "   [0.12917168 0.16062422 0.08803523]\n",
      "   ...\n",
      "   [0.19575834 0.27090847 0.12396958]\n",
      "   [0.18255302 0.25050023 0.102841  ]\n",
      "   [0.1781514  0.2436977  0.09579839]]\n",
      "\n",
      "  [[0.13445376 0.16022387 0.09187682]\n",
      "   [0.13349338 0.15846321 0.09163672]\n",
      "   [0.13061227 0.1531812  0.0909164 ]\n",
      "   ...\n",
      "   [0.21616663 0.31268543 0.14317735]\n",
      "   [0.20656277 0.29371774 0.11772698]\n",
      "   [0.2033616  0.28739542 0.10924383]]\n",
      "\n",
      "  [[0.13333334 0.15294118 0.09411765]\n",
      "   [0.13277312 0.15238096 0.09355742]\n",
      "   [0.13109244 0.15070029 0.09187675]\n",
      "   ...\n",
      "   [0.22296914 0.32661057 0.1495797 ]\n",
      "   [0.21456574 0.30812308 0.1226888 ]\n",
      "   [0.21176471 0.3019608  0.11372549]]]], shape=(128, 224, 224, 3), dtype=float32)\n",
      "tf.Tensor(\n",
      "[[[[0.05098039 0.05098039 0.06666667]\n",
      "   [0.04929972 0.04985994 0.06666667]\n",
      "   [0.0442577  0.0464986  0.06666667]\n",
      "   ...\n",
      "   [0.18655437 0.39831898 0.20224066]\n",
      "   [0.13781464 0.3260497  0.15350091]\n",
      "   [0.12156863 0.3019608  0.13725491]]\n",
      "\n",
      "  [[0.05098039 0.05042017 0.06610645]\n",
      "   [0.04953982 0.04953982 0.06626651]\n",
      "   [0.04521809 0.04689876 0.0667467 ]\n",
      "   ...\n",
      "   [0.1770306  0.38743466 0.1965584 ]\n",
      "   [0.1333329  0.32332867 0.15166022]\n",
      "   [0.11876751 0.3019608  0.13669468]]\n",
      "\n",
      "  [[0.05098039 0.0487395  0.06442577]\n",
      "   [0.0502601  0.04857943 0.06506603]\n",
      "   [0.04809924 0.04809924 0.0669868 ]\n",
      "   ...\n",
      "   [0.14845924 0.35478172 0.17951165]\n",
      "   [0.11988767 0.31516567 0.14613812]\n",
      "   [0.11036415 0.3019608  0.13501401]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[0.46834671 0.40840274 0.37030753]\n",
      "   [0.47306862 0.41224432 0.37310869]\n",
      "   [0.4872344  0.42376903 0.38151214]\n",
      "   ...\n",
      "   [0.24953926 0.36534536 0.24337637]\n",
      "   [0.20103966 0.29763806 0.16294402]\n",
      "   [0.1848737  0.27506977 0.13613419]]\n",
      "\n",
      "  [[0.34061497 0.28739372 0.2543406 ]\n",
      "   [0.3522997  0.29675755 0.26218376]\n",
      "   [0.38735396 0.32484895 0.28571332]\n",
      "   ...\n",
      "   [0.1875942  0.2774699  0.13269176]\n",
      "   [0.14773816 0.23785412 0.09619743]\n",
      "   [0.13445327 0.22464934 0.08403309]]\n",
      "\n",
      "  [[0.29803923 0.24705882 0.21568628]\n",
      "   [0.31204483 0.25826332 0.22521009]\n",
      "   [0.35406163 0.29187676 0.25378153]\n",
      "   ...\n",
      "   [0.16694659 0.24817912 0.09579821]\n",
      "   [0.12997162 0.21792686 0.07394936]\n",
      "   [0.11764706 0.20784314 0.06666667]]]\n",
      "\n",
      "\n",
      " [[[0.41568628 0.4509804  0.47843137]\n",
      "   [0.41568628 0.4509804  0.47843137]\n",
      "   [0.41568628 0.4509804  0.47843137]\n",
      "   ...\n",
      "   [0.40784314 0.44313726 0.47058824]\n",
      "   [0.40784314 0.44313726 0.47058824]\n",
      "   [0.40784314 0.44313726 0.47058824]]\n",
      "\n",
      "  [[0.41568628 0.4509804  0.47843137]\n",
      "   [0.41568628 0.4509804  0.47843137]\n",
      "   [0.41568628 0.4509804  0.47843137]\n",
      "   ...\n",
      "   [0.40728292 0.44257703 0.470028  ]\n",
      "   [0.40728292 0.44257703 0.470028  ]\n",
      "   [0.40728292 0.44257703 0.470028  ]]\n",
      "\n",
      "  [[0.41568628 0.4509804  0.47843137]\n",
      "   [0.41568628 0.4509804  0.47843137]\n",
      "   [0.41568628 0.4509804  0.47843137]\n",
      "   ...\n",
      "   [0.40560225 0.44089636 0.46834734]\n",
      "   [0.40560225 0.44089636 0.46834734]\n",
      "   [0.40560225 0.44089636 0.46834734]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[0.36358583 0.37535053 0.20056063]\n",
      "   [0.35590273 0.36766744 0.19423807]\n",
      "   [0.33285335 0.34461805 0.17527033]\n",
      "   ...\n",
      "   [0.18503396 0.1872749  0.04921973]\n",
      "   [0.16390526 0.16950758 0.03289302]\n",
      "   [0.15686263 0.16358535 0.02745098]]\n",
      "\n",
      "  [[0.44089717 0.45266187 0.27955264]\n",
      "   [0.42385024 0.43561494 0.26410636]\n",
      "   [0.3727095  0.38447422 0.21776755]\n",
      "   ...\n",
      "   [0.19415753 0.2031212  0.07322936]\n",
      "   [0.1485388  0.16086383 0.03889527]\n",
      "   [0.1333331  0.14677855 0.02745098]]\n",
      "\n",
      "  [[0.46666667 0.47843137 0.30588236]\n",
      "   [0.4464986  0.4582633  0.28739497]\n",
      "   [0.3859944  0.3977591  0.23193279]\n",
      "   ...\n",
      "   [0.19719861 0.20840311 0.08123229]\n",
      "   [0.14341682 0.15798268 0.04089595]\n",
      "   [0.1254902  0.14117648 0.02745098]]]\n",
      "\n",
      "\n",
      " [[[0.31764707 0.2901961  0.26666668]\n",
      "   [0.31428573 0.28683475 0.26330534]\n",
      "   [0.3042017  0.2767507  0.2532213 ]\n",
      "   ...\n",
      "   [0.         0.         0.        ]\n",
      "   [0.         0.         0.        ]\n",
      "   [0.         0.         0.        ]]\n",
      "\n",
      "  [[0.30868348 0.28179273 0.25826332]\n",
      "   [0.3057223  0.27875152 0.2552221 ]\n",
      "   [0.29683876 0.26962787 0.24609846]\n",
      "   ...\n",
      "   [0.         0.         0.        ]\n",
      "   [0.         0.         0.        ]\n",
      "   [0.         0.         0.        ]]\n",
      "\n",
      "  [[0.28179273 0.25658265 0.23305324]\n",
      "   [0.28003204 0.25450182 0.2309724 ]\n",
      "   [0.2747499  0.2482593  0.2247299 ]\n",
      "   ...\n",
      "   [0.         0.         0.        ]\n",
      "   [0.         0.         0.        ]\n",
      "   [0.         0.         0.        ]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[0.1994398  0.17591038 0.15238097]\n",
      "   [0.19663867 0.1734294  0.15014008]\n",
      "   [0.18823531 0.16598642 0.14341739]\n",
      "   ...\n",
      "   [0.         0.         0.        ]\n",
      "   [0.         0.         0.        ]\n",
      "   [0.         0.         0.        ]]\n",
      "\n",
      "  [[0.20280115 0.17927174 0.15574233]\n",
      "   [0.20000003 0.17655066 0.15350144]\n",
      "   [0.19159667 0.16838738 0.14677875]\n",
      "   ...\n",
      "   [0.         0.         0.        ]\n",
      "   [0.         0.         0.        ]\n",
      "   [0.         0.         0.        ]]\n",
      "\n",
      "  [[0.20392157 0.18039216 0.15686275]\n",
      "   [0.20112045 0.17759104 0.15462185]\n",
      "   [0.19271709 0.16918768 0.14789917]\n",
      "   ...\n",
      "   [0.         0.         0.        ]\n",
      "   [0.         0.         0.        ]\n",
      "   [0.         0.         0.        ]]]\n",
      "\n",
      "\n",
      " ...\n",
      "\n",
      "\n",
      " [[[1.         1.         1.        ]\n",
      "   [1.         1.         1.        ]\n",
      "   [1.         1.         1.        ]\n",
      "   ...\n",
      "   [1.         1.         1.        ]\n",
      "   [1.         1.         1.        ]\n",
      "   [1.         1.         1.        ]]\n",
      "\n",
      "  [[1.         1.         1.        ]\n",
      "   [0.99991995 1.         0.99991995]\n",
      "   [0.99967986 1.         0.99967986]\n",
      "   ...\n",
      "   [1.         1.         1.        ]\n",
      "   [1.         1.         1.        ]\n",
      "   [1.         1.         1.        ]]\n",
      "\n",
      "  [[1.         1.         1.        ]\n",
      "   [0.99967986 1.         0.99967986]\n",
      "   [0.9987195  1.         0.9987195 ]\n",
      "   ...\n",
      "   [1.         1.         1.        ]\n",
      "   [1.         1.         1.        ]\n",
      "   [1.         1.         1.        ]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[0.         0.         0.        ]\n",
      "   [0.         0.         0.        ]\n",
      "   [0.         0.         0.        ]\n",
      "   ...\n",
      "   [0.         0.         0.        ]\n",
      "   [0.         0.         0.        ]\n",
      "   [0.         0.         0.        ]]\n",
      "\n",
      "  [[0.         0.         0.        ]\n",
      "   [0.         0.         0.        ]\n",
      "   [0.         0.         0.        ]\n",
      "   ...\n",
      "   [0.         0.         0.        ]\n",
      "   [0.         0.         0.        ]\n",
      "   [0.         0.         0.        ]]\n",
      "\n",
      "  [[0.         0.         0.        ]\n",
      "   [0.         0.         0.        ]\n",
      "   [0.         0.         0.        ]\n",
      "   ...\n",
      "   [0.         0.         0.        ]\n",
      "   [0.         0.         0.        ]\n",
      "   [0.         0.         0.        ]]]\n",
      "\n",
      "\n",
      " [[[0.         0.         0.        ]\n",
      "   [0.         0.         0.        ]\n",
      "   [0.         0.         0.        ]\n",
      "   ...\n",
      "   [0.         0.         0.        ]\n",
      "   [0.         0.         0.        ]\n",
      "   [0.         0.         0.        ]]\n",
      "\n",
      "  [[0.         0.         0.        ]\n",
      "   [0.         0.         0.        ]\n",
      "   [0.         0.         0.        ]\n",
      "   ...\n",
      "   [0.         0.         0.        ]\n",
      "   [0.         0.         0.        ]\n",
      "   [0.         0.         0.        ]]\n",
      "\n",
      "  [[0.         0.         0.        ]\n",
      "   [0.         0.         0.        ]\n",
      "   [0.         0.         0.        ]\n",
      "   ...\n",
      "   [0.         0.         0.        ]\n",
      "   [0.         0.         0.        ]\n",
      "   [0.         0.         0.        ]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[0.6431373  0.6767507  0.7176471 ]\n",
      "   [0.6431373  0.67755103 0.7182073 ]\n",
      "   [0.6431373  0.679952   0.719888  ]\n",
      "   ...\n",
      "   [0.6913166  0.784794   0.87667066]\n",
      "   [0.6543415  0.76678663 0.8721088 ]\n",
      "   [0.642017   0.7607844  0.87058824]]\n",
      "\n",
      "  [[0.6431373  0.67507005 0.7176471 ]\n",
      "   [0.6431373  0.67611045 0.7182073 ]\n",
      "   [0.6431373  0.6792317  0.719888  ]\n",
      "   ...\n",
      "   [0.73501426 0.80712295 0.8805122 ]\n",
      "   [0.687955   0.78119236 0.87306917]\n",
      "   [0.6722692  0.77254915 0.87058824]]\n",
      "\n",
      "  [[0.6431373  0.6745098  0.7176471 ]\n",
      "   [0.6431373  0.6756303  0.7182073 ]\n",
      "   [0.6431373  0.6789916  0.719888  ]\n",
      "   ...\n",
      "   [0.7495796  0.8145657  0.88179266]\n",
      "   [0.69915915 0.7859941  0.8733893 ]\n",
      "   [0.68235296 0.7764706  0.87058824]]]\n",
      "\n",
      "\n",
      " [[[0.00784314 0.00784314 0.01176471]\n",
      "   [0.00840336 0.00840336 0.01232493]\n",
      "   [0.01008403 0.01008403 0.0140056 ]\n",
      "   ...\n",
      "   [0.45546195 0.4504199  0.4352938 ]\n",
      "   [0.40504152 0.39495742 0.36470518]\n",
      "   [0.3882353  0.3764706  0.34117648]]\n",
      "\n",
      "  [[0.00728291 0.00728291 0.01120448]\n",
      "   [0.00784314 0.00784314 0.01176471]\n",
      "   [0.00952381 0.00952381 0.01344538]\n",
      "   ...\n",
      "   [0.44465765 0.44073606 0.42368916]\n",
      "   [0.39687827 0.38791463 0.3571822 ]\n",
      "   [0.3809524  0.37030813 0.33501402]]\n",
      "\n",
      "  [[0.00560224 0.00560224 0.00952381]\n",
      "   [0.00616247 0.00616247 0.01008403]\n",
      "   [0.00784314 0.00784314 0.01176471]\n",
      "   ...\n",
      "   [0.4122447  0.41168445 0.3888753 ]\n",
      "   [0.37238857 0.36678627 0.33461332]\n",
      "   [0.35910365 0.35182074 0.31652662]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[0.2582635  0.30420187 0.14677896]\n",
      "   [0.2573031  0.30492213 0.14413787]\n",
      "   [0.2544219  0.30708292 0.13621461]\n",
      "   ...\n",
      "   [0.65866345 0.682673   0.69067615]\n",
      "   [0.6562623  0.68075204 0.68107206]\n",
      "   [0.6554619  0.6801117  0.67787075]]\n",
      "\n",
      "  [[0.29691917 0.33781546 0.1955187 ]\n",
      "   [0.291637   0.334214   0.1868752 ]\n",
      "   [0.27579054 0.32340953 0.16094464]\n",
      "   ...\n",
      "   [0.6512202  0.6656259  0.67603   ]\n",
      "   [0.60776216 0.62480897 0.618166  ]\n",
      "   [0.5932767  0.6112038  0.59887874]]\n",
      "\n",
      "  [[0.30980393 0.34901962 0.21176471]\n",
      "   [0.30308124 0.3439776  0.20112045]\n",
      "   [0.28291318 0.32885155 0.16918768]\n",
      "   ...\n",
      "   [0.6487392  0.6599437  0.6711481 ]\n",
      "   [0.59159607 0.60616195 0.5971981 ]\n",
      "   [0.57254905 0.5882353  0.57254905]]]], shape=(128, 224, 224, 3), dtype=float32)\n",
      "tf.Tensor(\n",
      "[[[[0.3764706  0.2901961  0.20392157]\n",
      "   [0.36862746 0.28627452 0.20560224]\n",
      "   [0.34509805 0.27450982 0.21064426]\n",
      "   ...\n",
      "   [0.3899159  0.3165266  0.22240894]\n",
      "   [0.37983185 0.31148455 0.2173669 ]\n",
      "   [0.3764706  0.30980393 0.21568628]]\n",
      "\n",
      "  [[0.3579832  0.28235295 0.20616247]\n",
      "   [0.3515006  0.2789916  0.20768307]\n",
      "   [0.33205283 0.26890758 0.2122449 ]\n",
      "   ...\n",
      "   [0.3847939  0.31292516 0.22152859]\n",
      "   [0.38023207 0.3110044  0.21672665]\n",
      "   [0.3787115  0.31036416 0.21512605]]\n",
      "\n",
      "  [[0.30252102 0.25882354 0.21288516]\n",
      "   [0.30012006 0.25714287 0.21392557]\n",
      "   [0.2929172  0.25210086 0.21704683]\n",
      "   ...\n",
      "   [0.36942783 0.3021209  0.21888754]\n",
      "   [0.3814327  0.3095639  0.21480589]\n",
      "   [0.38543418 0.31204483 0.21344538]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[0.25658277 0.4392158  0.5820729 ]\n",
      "   [0.26098454 0.44409776 0.5845539 ]\n",
      "   [0.27418986 0.45874366 0.5919969 ]\n",
      "   ...\n",
      "   [0.26938766 0.4488194  0.5833532 ]\n",
      "   [0.2749099  0.45170054 0.5823928 ]\n",
      "   [0.27675056 0.4526609  0.5820727 ]]\n",
      "\n",
      "  [[0.281793   0.46274534 0.59551835]\n",
      "   [0.28835562 0.4685877  0.5982395 ]\n",
      "   [0.30804357 0.48611474 0.60640275]\n",
      "   ...\n",
      "   [0.24801901 0.41808695 0.5555019 ]\n",
      "   [0.25066003 0.4188072  0.5502198 ]\n",
      "   [0.25154036 0.4190473  0.54845905]]\n",
      "\n",
      "  [[0.2901961  0.47058824 0.6       ]\n",
      "   [0.297479   0.4767507  0.60280114]\n",
      "   [0.31932774 0.49523813 0.6112045 ]\n",
      "   ...\n",
      "   [0.24089637 0.40784314 0.54621845]\n",
      "   [0.24257705 0.40784314 0.53949577]\n",
      "   [0.24313726 0.40784314 0.5372549 ]]]\n",
      "\n",
      "\n",
      " [[[0.42745098 0.4117647  0.38039216]\n",
      "   [0.4302521  0.41344538 0.3815126 ]\n",
      "   [0.43865547 0.4184874  0.38487396]\n",
      "   ...\n",
      "   [0.4504202  0.42745098 0.40728295]\n",
      "   [0.45378155 0.42745098 0.4106443 ]\n",
      "   [0.45490196 0.42745098 0.4117647 ]]\n",
      "\n",
      "  [[0.43137255 0.41344538 0.38039216]\n",
      "   [0.43385354 0.41488597 0.38159263]\n",
      "   [0.44129652 0.4192077  0.3851941 ]\n",
      "   ...\n",
      "   [0.45138058 0.42617047 0.40432176]\n",
      "   [0.45402163 0.42545018 0.4069628 ]\n",
      "   [0.45490196 0.4252101  0.40784314]]\n",
      "\n",
      "  [[0.44313726 0.4184874  0.38039216]\n",
      "   [0.44465786 0.4192077  0.38183275]\n",
      "   [0.4492197  0.42136854 0.38615447]\n",
      "   ...\n",
      "   [0.45426172 0.42232892 0.3954382 ]\n",
      "   [0.4547419  0.41944775 0.39591837]\n",
      "   [0.45490196 0.4184874  0.39607844]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[0.26162452 0.3389354  0.2857142 ]\n",
      "   [0.26898745 0.340456   0.28987586]\n",
      "   [0.29107624 0.34501782 0.30236083]\n",
      "   ...\n",
      "   [0.58119255 0.58543426 0.62344944]\n",
      "   [0.5999201  0.6039217  0.64241713]\n",
      "   [0.6061624  0.610084   0.64873946]]\n",
      "\n",
      "  [[0.23305294 0.3053218  0.26554602]\n",
      "   [0.238255   0.30612212 0.2682671 ]\n",
      "   [0.2538612  0.30852306 0.2764303 ]\n",
      "   ...\n",
      "   [0.5696678  0.5719888  0.6104842 ]\n",
      "   [0.58695483 0.5904763  0.6316128 ]\n",
      "   [0.592717   0.59663856 0.63865536]]\n",
      "\n",
      "  [[0.22352941 0.29411766 0.25882354]\n",
      "   [0.2280112  0.29467788 0.26106444]\n",
      "   [0.2414566  0.29635856 0.26778713]\n",
      "   ...\n",
      "   [0.5658264  0.56750715 0.6061626 ]\n",
      "   [0.58263326 0.5859946  0.62801147]\n",
      "   [0.5882353  0.5921569  0.63529414]]]\n",
      "\n",
      "\n",
      " [[[0.44705883 0.28627452 0.2901961 ]\n",
      "   [0.45210084 0.2857143  0.2879552 ]\n",
      "   [0.4672269  0.28403363 0.2812325 ]\n",
      "   ...\n",
      "   [0.10868339 0.14677867 0.19271702]\n",
      "   [0.09187658 0.13669458 0.17759089]\n",
      "   [0.08627451 0.13333334 0.17254902]]\n",
      "\n",
      "  [[0.46778712 0.2767507  0.27731094]\n",
      "   [0.47290915 0.27587035 0.2746699 ]\n",
      "   [0.48827532 0.2732293  0.2667467 ]\n",
      "   ...\n",
      "   [0.12797107 0.14949976 0.19487788]\n",
      "   [0.10468163 0.13821517 0.18023196]\n",
      "   [0.09691877 0.13445379 0.17535014]]\n",
      "\n",
      "  [[0.529972   0.24817929 0.23865548]\n",
      "   [0.5353341  0.24633855 0.23481393]\n",
      "   [0.55142057 0.24081634 0.22328933]\n",
      "   ...\n",
      "   [0.18583411 0.157663   0.20136048]\n",
      "   [0.1430968  0.14277697 0.18815513]\n",
      "   [0.12885153 0.13781513 0.1837535 ]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[0.86274517 0.5971989  0.46106443]\n",
      "   [0.8605843  0.59583837 0.45842338]\n",
      "   [0.8541017  0.59175676 0.45050025]\n",
      "   ...\n",
      "   [0.56614655 0.53069234 0.46834734]\n",
      "   [0.5726292  0.53141266 0.46834734]\n",
      "   [0.57479    0.53165275 0.46834734]]\n",
      "\n",
      "  [[0.87450993 0.602241   0.45938373]\n",
      "   [0.8735496  0.602321   0.45914367]\n",
      "   [0.8706685  0.6025612  0.45842347]\n",
      "   ...\n",
      "   [0.5743099  0.539816   0.47002804]\n",
      "   [0.5822331  0.5412566  0.47002804]\n",
      "   [0.5848741  0.54173684 0.47002804]]\n",
      "\n",
      "  [[0.8784314  0.6039216  0.45882353]\n",
      "   [0.87787116 0.6044818  0.45938376]\n",
      "   [0.8761905  0.6061625  0.46106443]\n",
      "   ...\n",
      "   [0.5770309  0.54285717 0.47058824]\n",
      "   [0.58543426 0.54453784 0.47058824]\n",
      "   [0.5882353  0.54509807 0.47058824]]]\n",
      "\n",
      "\n",
      " ...\n",
      "\n",
      "\n",
      " [[[0.23921569 0.22745098 0.19607843]\n",
      "   [0.23193277 0.2207283  0.19103642]\n",
      "   [0.21008404 0.20056023 0.17591037]\n",
      "   ...\n",
      "   [0.2661065  0.2481793  0.1389356 ]\n",
      "   [0.26946783 0.25322136 0.14061627]\n",
      "   [0.27058825 0.25490198 0.14117648]]\n",
      "\n",
      "  [[0.24593838 0.23361345 0.20112045]\n",
      "   [0.24033614 0.2284914  0.19687876]\n",
      "   [0.22352941 0.21312526 0.18415366]\n",
      "   ...\n",
      "   [0.26298523 0.24433775 0.13933575]\n",
      "   [0.264906   0.24721894 0.14029613]\n",
      "   [0.26554623 0.24817929 0.14061625]]\n",
      "\n",
      "  [[0.26610646 0.25210086 0.2162465 ]\n",
      "   [0.26554623 0.25178072 0.21440576]\n",
      "   [0.26386556 0.25082034 0.20888355]\n",
      "   ...\n",
      "   [0.25362146 0.23281312 0.14053622]\n",
      "   [0.25122046 0.22921166 0.13933574]\n",
      "   [0.25042018 0.22801122 0.13893558]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[0.16022405 0.16806719 0.1282913 ]\n",
      "   [0.1680672  0.17535011 0.13573427]\n",
      "   [0.19159667 0.19719891 0.15806325]\n",
      "   ...\n",
      "   [0.10564233 0.08731499 0.07747105]\n",
      "   [0.09531815 0.08275315 0.07146862]\n",
      "   [0.09187689 0.08123259 0.06946788]]\n",
      "\n",
      "  [[0.15182064 0.15966378 0.12324925]\n",
      "   [0.16302517 0.17030808 0.13309321]\n",
      "   [0.1966387  0.20224094 0.16262509]\n",
      "   ...\n",
      "   [0.12893176 0.10292131 0.09499815]\n",
      "   [0.12004818 0.10052037 0.08971602]\n",
      "   [0.1170871  0.09972008 0.08795537]]\n",
      "\n",
      "  [[0.14901961 0.15686275 0.12156863]\n",
      "   [0.16134454 0.16862746 0.13221288]\n",
      "   [0.19831933 0.20392157 0.16414565]\n",
      "   ...\n",
      "   [0.13669464 0.10812324 0.10084032]\n",
      "   [0.12829123 0.10644256 0.09579827]\n",
      "   [0.1254902  0.10588235 0.09411765]]]\n",
      "\n",
      "\n",
      " [[[0.07450981 0.08235294 0.06666667]\n",
      "   [0.07787115 0.08347339 0.0627451 ]\n",
      "   [0.08795518 0.08683474 0.0509804 ]\n",
      "   ...\n",
      "   [0.15686245 0.16414532 0.14733857]\n",
      "   [0.09803863 0.09691809 0.07506929]\n",
      "   [0.07843138 0.07450981 0.05098039]]\n",
      "\n",
      "  [[0.06890757 0.07563026 0.05994398]\n",
      "   [0.07362945 0.07779112 0.05746299]\n",
      "   [0.08779512 0.08427371 0.05002001]\n",
      "   ...\n",
      "   [0.14869921 0.15382122 0.13781479]\n",
      "   [0.09347684 0.09139593 0.07226824]\n",
      "   [0.07507003 0.07058824 0.05042017]]\n",
      "\n",
      "  [[0.05210084 0.05546219 0.03977592]\n",
      "   [0.06090437 0.0607443  0.04161665]\n",
      "   [0.08731493 0.07659063 0.04713886]\n",
      "   ...\n",
      "   [0.12420946 0.1228489  0.10924347]\n",
      "   [0.07979147 0.07482944 0.06386509]\n",
      "   [0.064986   0.05882353 0.0487395 ]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[0.6481791  0.5619046  0.387675  ]\n",
      "   [0.6431371  0.55814314 0.38487387]\n",
      "   [0.62801105 0.5468586  0.3764705 ]\n",
      "   ...\n",
      "   [0.12180878 0.11556626 0.08811522]\n",
      "   [0.13045228 0.11964792 0.08547416]\n",
      "   [0.13333334 0.12100843 0.08459383]]\n",
      "\n",
      "  [[0.6179269  0.5316524  0.3675068 ]\n",
      "   [0.6128849  0.5286112  0.36470568]\n",
      "   [0.5977588  0.51948756 0.35630232]\n",
      "   ...\n",
      "   [0.12372955 0.11796724 0.08547416]\n",
      "   [0.13093247 0.1227692  0.08355339]\n",
      "   [0.13333334 0.12436979 0.08291315]]\n",
      "\n",
      "  [[0.60784316 0.52156866 0.36078432]\n",
      "   [0.60280114 0.51876754 0.3579832 ]\n",
      "   [0.5876751  0.5103642  0.34957984]\n",
      "   ...\n",
      "   [0.12436979 0.11876754 0.08459383]\n",
      "   [0.13109252 0.12380958 0.08291315]\n",
      "   [0.13333334 0.1254902  0.08235294]]]\n",
      "\n",
      "\n",
      " [[[0.14509805 0.14117648 0.10980392]\n",
      "   [0.14005603 0.13893558 0.10868347]\n",
      "   [0.12492998 0.13221289 0.10532213]\n",
      "   ...\n",
      "   [0.6761903  0.7899158  0.382633  ]\n",
      "   [0.6425767  0.7563022  0.36918753]\n",
      "   [0.6313726  0.74509805 0.3647059 ]]\n",
      "\n",
      "  [[0.13837536 0.13613446 0.1070028 ]\n",
      "   [0.13405363 0.13437375 0.10612245]\n",
      "   [0.12108845 0.12909165 0.1034814 ]\n",
      "   ...\n",
      "   [0.6644256  0.7799118  0.3788715 ]\n",
      "   [0.63585407 0.75086004 0.36782703]\n",
      "   [0.62633055 0.7411765  0.36414567]]\n",
      "\n",
      "  [[0.11820729 0.12100841 0.09859944]\n",
      "   [0.11604642 0.12068828 0.09843938]\n",
      "   [0.10956383 0.11972789 0.09795918]\n",
      "   ...\n",
      "   [0.6291316  0.7498999  0.36758703]\n",
      "   [0.6156861  0.73453367 0.36374545]\n",
      "   [0.6112045  0.7294118  0.362465  ]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[0.15574227 0.26890764 0.1254902 ]\n",
      "   [0.15334132 0.26346543 0.1239696 ]\n",
      "   [0.14613846 0.2471389  0.11940778]\n",
      "   ...\n",
      "   [0.2995599  0.45122057 0.26258522]\n",
      "   [0.31732717 0.46994823 0.29379797]\n",
      "   [0.32324937 0.47619054 0.30420187]]\n",
      "\n",
      "  [[0.15070024 0.2789917  0.1254902 ]\n",
      "   [0.14925967 0.27258915 0.12468989]\n",
      "   [0.14493796 0.25338143 0.12228894]\n",
      "   ...\n",
      "   [0.29379764 0.44641867 0.27026844]\n",
      "   [0.32597083 0.47883198 0.32092917]\n",
      "   [0.33669484 0.489636   0.33781546]]\n",
      "\n",
      "  [[0.14901961 0.28235295 0.1254902 ]\n",
      "   [0.14789917 0.27563027 0.12492998]\n",
      "   [0.14453782 0.2554622  0.1232493 ]\n",
      "   ...\n",
      "   [0.29187694 0.4448181  0.2728294 ]\n",
      "   [0.32885194 0.4817931  0.32997257]\n",
      "   [0.34117648 0.49411765 0.34901962]]]], shape=(128, 224, 224, 3), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "import tensorflow_datasets as tfds\n",
    "ds, ds_info = tfds.load(\n",
    "    'stl10', split='unlabelled', with_info=True, as_supervised=True)\n",
    "\n",
    "def normalize_img(image, label):\n",
    "  \"\"\"Normalizes images: `uint8` -> `float32`.\"\"\"\n",
    "  return tf.cast(image, tf.float32) / 255., label\n",
    "\n",
    "\n",
    "def resize_to_resnet_input(image, label):\n",
    "    \"\"\"Resizes images to resnet compatible size (224x224).\"\"\"\n",
    "    return tf.image.resize(image, [224, 224]), label\n",
    "\n",
    "ds = ds.map(normalize_img,  num_parallel_calls=tf.data.AUTOTUNE)\n",
    "ds = ds.map(resize_to_resnet_input,  num_parallel_calls=tf.data.AUTOTUNE)\n",
    "# TODO: for now that's only for pretraining.\n",
    "# ds = ds.map(lambda img, _: img,  num_parallel_calls=tf.data.AUTOTUNE)\n",
    "\n",
    "# ds = ds.cache()\n",
    "# For true randomness, set the shuffle buffer to the full dataset size.\n",
    "ds = ds.shuffle(1000)\n",
    "ds = ds.batch(128)\n",
    "\n",
    "ds = ds.prefetch(tf.data.AUTOTUNE)\n",
    "\n",
    "for a, b in ds.take(10):\n",
    "    print(a)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "b95296a527a698334e08c33ad27f38adda0cc9d7ac330df83bf5727d27d5b2d0"
  },
  "kernelspec": {
   "display_name": "new_ml_stuff:pyenv",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
